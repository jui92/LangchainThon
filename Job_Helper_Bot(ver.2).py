###################################################################################################################
#  1. ì±„ìš© í¬í„¸ ì‚¬ì´íŠ¸ URLë¡œ ì¡°íšŒí•œ íšŒì‚¬ ì •ë³´ì™€ ë“±ë¡í•œ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì†Œì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´ì¤ë‹ˆë‹¤                  #
#  2. ì±„ìš© í¬í„¸ ì‚¬ì´íŠ¸ URL / ê¸°ì—… í™ˆí˜ì´ì§€ URL / ë‰´ìŠ¤ ê¸°ì‚¬ ë¥¼ ì°¸ê³ í•˜ì—¬ ëª¨ì˜ ë©´ì ‘ì„ ì‹¤ì‹œí•˜ê³  ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì„ í•´ì¤ë‹ˆë‹¤.#
#  [ìˆ˜ì •ì‚¬í•­] ì›¹ í¬ë¡¤ë§ì„ Selenium(ë™ì ) ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ JavaScript ë Œë”ë§ ì½˜í…ì¸ ë„ ìˆ˜ì§‘ ê°€ëŠ¥                         #
###################################################################################################################

# Library Import ( coding: utf-8 )
import os, re, json, urllib.parse, time, io, random
from typing import Optional, Tuple, Dict, List

# ì›¹ ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (API/RSSìš©ìœ¼ë¡œ ì¼ë¶€ ìœ ì§€)
import requests
# HTML íŒŒì‹±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from bs4 import BeautifulSoup
# HTMLì„ ê¹¨ë—í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import html2text
# ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ (UI êµ¬ì„±)
import streamlit as st
# ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import numpy as np

# ================== SELENIUM Library ==================
try:
    # Selenium Library for dynamic scraping
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service as ChromeService
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    # WebDriver ìë™ ê´€ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Streamlit Cloud í™˜ê²½ì—ì„œëŠ” í•„ìš”ì— ë”°ë¼ ìˆ˜ë™ ì„¤ì • í•„ìš”)
    from webdriver_manager.chrome import ChromeDriverManager 
except ImportError:
    st.error("`selenium` ë° `webdriver-manager` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip installì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()


# ================== ê¸°ë³¸ ì„¤ì • ==================
# Streamlit í˜ì´ì§€ ì„¤ì •: ì œëª©, ì•„ì´ì½˜, ë ˆì´ì•„ì›ƒì„ 'wide'ë¡œ ì„¤ì •
st.set_page_config(page_title="Job Helper Bot", page_icon="ğŸ¤–", layout="wide")
# ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ì œëª© í‘œì‹œ
st.title("Job Helper Bot : ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘ (Selenium)")

# ================== OpenAI ==================
# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„
try:
    from openai import OpenAI
except ImportError:
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ í›„ ì¢…ë£Œ
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜, Streamlit secrets, ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥ì°½ì—ì„œ ê°€ì ¸ì˜´
API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì…ë ¥ ìš”ì²­ (ë³´ì•ˆì„ ìœ„í•´ password íƒ€ì…ìœ¼ë¡œ)
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    # API í‚¤ ì…ë ¥ì´ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ ì•± ì‹¤í–‰ ì¤‘ë‹¨
    st.stop()
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=API_KEY)

# Streamlit ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„¤ì • ì„¹ì…˜ ì¶”ê°€
with st.sidebar:
    st.subheader("ëª¨ë¸ ì„¤ì •")
    # ëŒ€í™”/ìƒì„± ëª¨ë¸ ì„ íƒ ë°•ìŠ¤ (ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•¨)
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    # ì„ë² ë”© ëª¨ë¸ ì„ íƒ ë°•ìŠ¤ (RAGì— ì‚¬ìš©ë  ì„ë² ë”© ëª¨ë¸ ì„ íƒ)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸(ë‚´ë¶€ìš©)", ["text-embedding-3-small","text-embedding-3-large"], index=0)

# ================== SELENIUM WebDriver ì´ˆê¸°í™” ==================
@st.cache_resource
def get_webdriver():
    """Streamlit í™˜ê²½ì— ì í•©í•œ Headless Chrome WebDriverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    options = Options()
    # Headless ëª¨ë“œ ì„¤ì • (ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ)
    options.add_argument("--headless")
    # ë´‡ ê°ì§€ë¥¼ í”¼í•˜ê¸° ìœ„í•œ User-Agent ì„¤ì •
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36")
    # ì°½ í¬ê¸° ì„¤ì •
    options.add_argument("--window-size=1920,1080")
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë° ì•ˆì •í™” ì˜µì…˜
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-features=NetworkService")
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--disable-logging")
    # ì–¸ì–´ ì„¤ì •
    options.add_argument("--lang=ko")

    try:
        # WebDriver Managerë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ë¡¬ ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜ ë° ë¡œë“œ
        service = ChromeService(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
    except Exception as e:
        # ë“œë¼ì´ë²„ ì„¤ì¹˜ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ í›„ ì•± ì¤‘ë‹¨
        st.error(f"Selenium WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. `webdriver-manager`ì™€ Chrome ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
        
    return driver

# ì „ì—­ ë“œë¼ì´ë²„ ë³€ìˆ˜ ì´ˆê¸°í™” (st.cache_resourceë¡œ ìºì‹œë˜ì–´ ì•±ì´ ì¬ì‹¤í–‰ë˜ì–´ë„ ë“œë¼ì´ë²„ëŠ” ìœ ì§€ë¨)
DRIVER = get_webdriver()


# ================== HTTP ìœ í‹¸ (URL ì •ê·œí™”) ==================
def normalize_url(u: str) -> Optional[str]:
    """URL ë¬¸ìì—´ì„ ì •ê·œí™”í•˜ê³  HTTPS ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    if not u: return None
    u = u.strip()
    # URLì— http ë˜ëŠ” https ìŠ¤í‚¤ë§ˆê°€ ì—†ìœ¼ë©´ https://ë¥¼ ë¶™ì„
    if not re.match(r"^https?://", u): u = "https://" + u
    # URLì„ íŒŒì‹±í•˜ì—¬ ì¿¼ë¦¬ë‚˜ í”„ë˜ê·¸ë¨¼íŠ¸ ì—†ì´ ê¸°ë³¸ ê²½ë¡œë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))


# ================== ë™ì  ì›ë¬¸ ìˆ˜ì§‘ (SELENIUM ê¸°ë°˜) ==================
def selenium_get_page_source(url: str, wait_selector: Optional[str] = None, timeout: int = 15) -> Optional[str]:
    """Seleniumì„ ì‚¬ìš©í•˜ì—¬ URLì— ì ‘ì†í•˜ê³ , ë™ì  ë¡œë”©ì„ ê¸°ë‹¤ë¦° í›„ í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    url = normalize_url(url)
    if not url: return None
    try:
        # 1. í˜ì´ì§€ ë¡œë“œ
        DRIVER.get(url)
        
        # 2. ë™ì  ì½˜í…ì¸ ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼ (ì˜µì…˜)
        # ì±„ìš© ê³µê³ ë‚˜ íšŒì‚¬ ì†Œê°œ í˜ì´ì§€ì˜ ë©”ì¸ ì½˜í…ì¸ ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”í•œ ì„ íƒìë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        # body ë˜ëŠ” ì£¼ìš” ì˜ì—­(article, section)ì´ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        wait_selector = wait_selector or "body, article, section, h1, .post, #contents"
        
        WebDriverWait(DRIVER, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, wait_selector))
        )
        
        # 3. ìµœì¢… ë Œë”ë§ëœ í˜ì´ì§€ ì†ŒìŠ¤ ë°˜í™˜
        return DRIVER.page_source
        
    except Exception as e:
        # íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        print(f"Selenium get error for {url}: {e}")
        return None

def fetch_all_text(url: str):
    """ìµœì¢… ì›¹ ì½˜í…ì¸  ì¶”ì¶œ í•¨ìˆ˜: Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë Œë”ë§ëœ HTMLì„ ê°€ì ¸ì™€ BS4ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤."""
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None

    # 1. Seleniumìœ¼ë¡œ í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
    html_source = selenium_get_page_source(url)
        
    if not html_source:
        return "", {"source":"selenium_fail","error":"fail_to_get_source","url_final":url}, None

    # 2. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹± ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    soup = BeautifulSoup(html_source, "lxml")
    blocks = []
    # ê¸°ì‚¬, ì„¹ì…˜, ë©”ì¸ ë“± ì£¼ìš” ì½˜í…ì¸  íƒœê·¸ë¥¼ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True)
            # ê¸¸ì´ê°€ 300ì ì´ìƒì¸ ìœ ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ ìˆ˜ì§‘
            if txt and len(txt) > 300:
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    
    # 3. í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ë°˜í™˜
    if not blocks:
        # ìœ ì˜ë¯¸í•œ ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì œí•œ ê¸¸ì´(120000)ë§Œí¼ ë°˜í™˜
        raw_text = soup.get_text(" ", strip=True)[:120000]
    else:
        # ì¤‘ë³µ ë¸”ë¡ ì œê±° í›„ í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ë°˜í™˜
        seen, out = set(), []
        for b in blocks:
            if b not in seen:
                seen.add(b); out.append(b)
        raw_text = ("\n\n".join(out)[:120000])

    return raw_text, {"source":"selenium_bs4","len":len(raw_text),"url_final":url}, soup


# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    """HTML Soup ê°ì²´ì—ì„œ íšŒì‚¬ëª…, íšŒì‚¬ ì†Œê°œ, ì§ë¬´ëª… í›„ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    
    # 1. íšŒì‚¬ëª… í›„ë³´ ì¶”ì¶œ (og:site_name, application-name, title íƒœê·¸ì—ì„œ)
    cand = []
    og = soup.find("meta", {"property":"og:site_name"})
    if og and og.get("content"): cand.append(og["content"])
    app = soup.find("meta", {"name":"application-name"})
    if app and app.get("content"): cand.append(app["content"])
    if soup.title and soup.title.string: cand.append(soup.title.string)
    
    # íŠ¹ìˆ˜ ë¬¸ì(í•˜ì´í”ˆ, íŒŒì´í”„ ë“±)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íšŒì‚¬ëª…ì„ ë¶„ë¦¬í•˜ê³  ì •ë¦¬
    cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
    cand = [c for c in cand if 2 <= len(c) <= 40]
    meta["company_name"] = cand[0] if cand else ""
    
    # 2. íšŒì‚¬ ì†Œê°œ/ì„¤ëª… ì¶”ì¶œ (description, og:description ë©”íƒ€ íƒœê·¸ì—ì„œ)
    md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
    if md and md.get("content"):
        meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
        
    # 3. ì§ë¬´ëª… ì¶”ì¶œ (og:title, H1, H2 íƒœê·¸ì—ì„œ)
    jt = ""
    ogt = soup.find("meta", {"property":"og:title"})
    if ogt and ogt.get("content"): jt = ogt["content"]
    if not jt:
        h1 = soup.find("h1")
        if h1 and h1.get_text(): jt = h1.get_text(strip=True)
    if not jt:
        h2 = soup.find("h2")
        if h2 and h2.get_text(): jt = h2.get_text(strip=True)
    meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    return meta

# ================== ê·œì¹™ íŒŒì„œ ==================
def rule_based_sections(raw_text: str) -> dict:
    """ì •ê·œ í‘œí˜„ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì›ë¬¸ì—ì„œ ì£¼ìš” ì—…ë¬´, ìê²© ìš”ê±´, ìš°ëŒ€ ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. (LLM ë³´ì¡°ìš©)"""
    txt = re.sub(r"\r", "", raw_text or "").strip()
    # ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ê³µë°± ì •ë¦¬
    lines = [re.sub(r"\s+", " ", l).strip(" -â€¢Â·â–¶â–ªï¸") for l in txt.split("\n")]
    lines = [l for l in lines if l]

    # ê° ì„¹ì…˜ì˜ í—¤ë” ì •ê·œ í‘œí˜„ì‹ ì •ì˜
    hdr_resp = re.compile(r"(ì£¼ìš”\s*ì—…ë¬´|ë‹´ë‹¹\s*ì—…ë¬´|Role|Responsibilities?)", re.I)
    hdr_qual = re.compile(r"(ìê²©\s*ìš”ê±´|ì§€ì›\s*ìê²©|Requirements?|Qualifications?)", re.I)
    hdr_pref = re.compile(r"(ìš°ëŒ€\s*ì‚¬í•­|ìš°ëŒ€|ì„ í˜¸|Preferred|Nice\s*to\s*have|Plus)", re.I)

    bucket = None
    out = {"responsibilities": [], "qualifications": [], "preferences": []}

    def push(line, b):
        """ì¶”ì¶œëœ í•­ëª©ì„ ë²„í‚·ì— ì¶”ê°€í•˜ê³  ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤."""
        if line and len(line) > 1 and line not in out[b]:
            out[b].append(line[:180])

    # ê° ì¤„ì„ ìˆœíšŒí•˜ë©° í—¤ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë²„í‚·(ì„¹ì…˜)ì„ ì§€ì •
    for l in lines:
        if hdr_resp.search(l): bucket = "responsibilities"; continue
        if hdr_qual.search(l): bucket = "qualifications"; continue
        if hdr_pref.search(l): bucket = "preferences"; continue
        
        # í—¤ë”ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°, í‚¤ì›Œë“œë¡œ ì„¹ì…˜ì„ ì¶”ì •í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë¶€í„° í•´ë‹¹ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¥˜
        if bucket is None:
            if hdr_pref.search(l):
                bucket = "preferences"
            elif any(k in l.lower() for k in ["java","python","spark","airflow","kafka","ml","sql"]):
                bucket = "responsibilities" # ê¸°ìˆ  ìŠ¤íƒì´ ì–¸ê¸‰ë˜ë©´ ì£¼ìš” ì—…ë¬´ë¡œ ê°„ì£¼
            else:
                continue # ê´€ë ¨ ì—†ëŠ” í•­ëª©ì€ ë¬´ì‹œ
        push(l, bucket)
    
    # 2ë‹¨ê³„ ì •ë¦¬: 'ìê²© ìš”ê±´'ì— í¬í•¨ëœ ìš°ëŒ€ í‚¤ì›Œë“œ í•­ëª©ì„ 'ìš°ëŒ€ ì‚¬í•­'ìœ¼ë¡œ ì´ë™
    kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
    remain_qual = []
    for q in out["qualifications"]:
        if kw_pref.search(q):
            out["preferences"].append(q)
        else:
            remain_qual.append(q)
    out["qualifications"] = remain_qual

    # ìµœì¢… ì •ë¦¬: ê° ì„¹ì…˜ë³„ ì¤‘ë³µ ì œê±° ë° í•­ëª© ê¸¸ì´ ì œí•œ (ìµœëŒ€ 12ê°œ)
    for k in out:
        seen=set(); clean=[]
        for s in out[k]:
            s = re.sub(r"\s+", " ", s).strip(" -â€¢Â·â–¶â–ªï¸").strip()
            if s and s not in seen:
                seen.add(s); clean.append(s)
        out[k] = clean[:12]
    return out

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
# LLMì—ê²Œ ë¶€ì—¬í•  ì‹œìŠ¤í…œ ì—­í•  í”„ë¡¬í”„íŠ¸
PROMPT_SYSTEM_STRUCT = ("ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
                        "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
                        "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼.")

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš© ê³µê³  ì›ë¬¸ì„ JSON êµ¬ì¡°ë¡œ ì •ì œí•©ë‹ˆë‹¤."""
    ctx = (raw_text or "").strip()
    if len(ctx) > 14000: # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        ctx = ctx[:14000]

    # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±: ì›ë¬¸ê³¼ ë©”íƒ€ íŒíŠ¸ë¥¼ ì œê³µí•˜ê³  íŠ¹ì • JSON ìŠ¤í‚¤ë§ˆë¥¼ ìš”ì²­
    user_msg = {"role": "user",
                "content": ("ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
                            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
                            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
                            "--- ì›ë¬¸ ì‹œì‘ ---\n"
                            f"{ctx}\n"
                            "--- ì›ë¬¸ ë ---\n\n"
                            "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
                            "{"
                            "\"company_name\": str, "
                            "\"company_intro\": str, "
                            "\"job_title\": str, "
                            "\"responsibilities\": [str], "
                            "\"qualifications\": [str], "           
                            "\"preferences\": [str]"               
                            "}\n"
                            "- 'ìš°ëŒ€ ì‚¬í•­(preferences)'ì€ ë¹„ì›Œë‘ì§€ ë§ê³ , ì›ë¬¸ì—ì„œ 'ìš°ëŒ€/ì„ í˜¸/preferred/plus/ê°€ì‚°ì ' ë“± í‘œì‹œê°€ ìˆëŠ” í•­ëª©ì„ ê·¸ëŒ€ë¡œ ë‹´ì•„ë¼.\n"
                            "- ë¶ˆë¦¿/ë§ˆì»¤/ì´ëª¨ì§€ ì œê±°, ë¬¸ì¥ ê°„ê²°í™”, ì¤‘ë³µ ì œê±°."),}

    try:
        # LLM í˜¸ì¶œ: JSON ì¶œë ¥ í˜•ì‹ ê°•ì œ (response_format)
        resp = client.chat.completions.create(model=model, temperature=0.2,
                                              response_format={"type": "json_object"},
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg])
        data = json.loads(resp.choices[0].message.content)
    except Exception as e:
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ, íŒíŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ì±„ì›Œ ë°˜í™˜
        data = {"company_name": meta_hint.get("company_name",""),
                "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
                "job_title": meta_hint.get("job_title",""),
                "responsibilities": [],
                "qualifications": [],
                "preferences": [],
                "error": str(e)}

    # í›„ì²˜ë¦¬: LLMì´ ìƒì„±í•œ ë°°ì—´ í•­ëª©ë“¤ì„ ì •ë¦¬ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê¸¸ì´ ì œí•œ, ì¤‘ë³µ ì œê±°)
    for k in ["responsibilities","qualifications","preferences"]:
        arr = data.get(k, [])
        if not isinstance(arr, list): arr = []
        clean_list=[]; seen=set()
        for it in arr:
            t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·â–¶â–ªï¸").strip()
            if t and t not in seen:
                seen.add(t); clean_list.append(t[:180])
        data[k] = clean_list[:12]

    # í›„ì²˜ë¦¬: íšŒì‚¬ëª…/ì†Œê°œ/ì§ë¬´ëª… ë¬¸ìì—´ ì •ë¦¬
    for k in ["company_name","company_intro","job_title"]:
        if k in data and isinstance(data[k], str):
            data[k] = re.sub(r"\s+"," ", data[k]).strip()

    # ìš°ëŒ€ ì‚¬í•­(preferences)ì´ ë¹„ì–´ ìˆì„ ê²½ìš°, Rule-Based Parser ê²°ê³¼ë¥¼ ë³‘í•© ì‹œë„
    if len(data.get("preferences", [])) < 1:
        rb = rule_based_sections(ctx) # ê·œì¹™ ê¸°ë°˜ íŒŒì„œ ì¬ì‹¤í–‰
        if rb.get("preferences"):
            merged = data.get("preferences", []) + rb["preferences"]
            seen=set(); pref=[]
            for s in merged:
                s=s.strip()
                if s and s not in seen:
                    seen.add(s); pref.append(s)
            data["preferences"] = pref[:12]
        # ìµœì¢…ì ìœ¼ë¡œ ìš°ëŒ€ ì‚¬í•­ì´ ì—†ìœ¼ë©´, ìê²© ìš”ê±´ì—ì„œ 'ìš°ëŒ€' í‚¤ì›Œë“œê°€ í¬í•¨ëœ í•­ëª©ì„ ì´ë™
        if not data["preferences"]:
            kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
            remain=[]; moved=[]
            for q in data.get("qualifications", []):
                if kw_pref.search(q): moved.append(q)
                else: remain.append(q)
            if moved:
                data["preferences"] = moved[:12]
                data["qualifications"] = remain[:12]
    return data

# ================== íŒŒì¼ ë¦¬ë” (PDF/TXT/MD/DOCX) ==================
# PDF ì½ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬(pypdf) ë™ì  ì„í¬íŠ¸ ì‹œë„
try:
    import pypdf
except Exception:
    pypdf = None

def read_pdf(data: bytes) -> str:
    """PDF íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if pypdf is None: return ""
    try:
        reader = pypdf.PdfReader(io.BytesIO(data))
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ í•©ì¹¨
        return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
    except Exception:
        return ""

def read_docx(data: bytes) -> str:
    """DOCX íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        import docx2txt, tempfile
        # docx2txt ì‚¬ìš©ì„ ìœ„í•´ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì²˜ë¦¬
        with tempfile.NamedTemporaryFile(suffix=".docx", delete=True) as tmp:
            tmp.write(data); tmp.flush()
            text = docx2txt.process(tmp.name) or ""
            return text
    except Exception:
        return ""

def read_file_text(uploaded) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ MIME íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë¦¬ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md")):
        # í…ìŠ¤íŠ¸ íŒŒì¼: ì—¬ëŸ¬ ì¸ì½”ë”©(utf-8, cp949, euc-kr)ìœ¼ë¡œ ë””ì½”ë”© ì‹œë„
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    return ""

# ================== ê°„ë‹¨ ì²­í¬/ì„ë² ë”©(ë‚´ë¶€ ìë™) ==================
def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ì™€ ì˜¤ë²„ë©ìœ¼ë¡œ ì²­í¬(ì¡°ê°)ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    t = re.sub(r"\s+"," ", text).strip()
    if not t: return []
    out, start = [], 0
    # í…ìŠ¤íŠ¸ ëê¹Œì§€ ë°˜ë³µí•˜ë©° ì²­í¬ ìƒì„±
    while start < len(t):
        end = min(len(t), start+size)
        out.append(t[start:end])
        if end == len(t): break
        start = max(0, end-overlap) # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì ì„ ì˜¤ë²„ë©ë§Œí¼ ë’¤ë¡œ ì„¤ì •
    return out

def embed_texts(texts: List[str], model_name: str) -> np.ndarray:
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32) # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    # OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„ë² ë”© ìƒì„±
    resp = client.embeddings.create(model=model_name, input=texts)
    # NumPy ë°°ì—´ë¡œ ë³€í™˜
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ Kê°œ í•­ëª©ì˜ ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    # ì¿¼ë¦¬ ë²¡í„°ì™€ í–‰ë ¬ì„ ì •ê·œí™” (ê¸¸ì´ 1ë¡œ)
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    # í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    # ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìƒìœ„ Kê°œì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

def retrieve_resume_chunks(query: str, k: int = 4):
    """RAG (ê²€ìƒ‰ ì¦ê°• ìƒì„±)ë¥¼ ìœ„í•´ ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë ¥ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ì´ë ¥ì„œ ì²­í¬ì™€ ì„ë² ë”© ë²¡í„°ë¥¼ ê°€ì ¸ì˜´
    chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
    if not chs or embs is None:
        return []
    # ì¿¼ë¦¬ ë¬¸ì¥ ì„ë² ë”©
    qv = embed_texts([query], EMBED_MODEL)
    # ìƒìœ„ Kê°œ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
    scores, idxs = cosine_topk(embs, qv, k=k)
    # ì ìˆ˜ì™€ ì²­í¬ í…ìŠ¤íŠ¸ë¥¼ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ (SELENIUM ì ìš©) ==================
VISION_KEYS = ["ë¹„ì „","ë¯¸ì…˜","í•µì‹¬ê°€ì¹˜","ê°€ì¹˜","ì›ì¹™","ë¬¸í™”","í–‰ë™ê°•ë ¹","Talent","ì¸ì¬ìƒ","Our Mission","Vision","Values"]

def safe_get_text(el) -> str:
    """BeautifulSoup ìš”ì†Œì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        return el.get_text(" ", strip=True)
    except Exception:
        return ""

def fetch_company_pages(home_url: str) -> Dict[str, List[str]]:
    """í™ˆí˜ì´ì§€ ë° ëŒ€í‘œ ì„œë¸Œê²½ë¡œì—ì„œ ë¹„ì „/ì¸ì¬ìƒ í›„ë³´ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (Selenium ì‚¬ìš©)"""
    out = {"vision": [], "talent": []}
    if not home_url: return out
    base = normalize_url(home_url)
    if not base: return out
    # ì¼ë°˜ì ìœ¼ë¡œ ë¹„ì „/ì¸ì¬ìƒì´ ìˆëŠ” ì„œë¸Œ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    paths = ["","/","/about","/company","/about-us","/mission","/vision","/values","/culture","/careers","/talent","/people"]
    seen = set()
    for p in paths:
        url = (base.rstrip("/") + p) if p else base
        if url in seen: continue
        seen.add(url)
        
        # 1. Seleniumìœ¼ë¡œ í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
        html_source = selenium_get_page_source(url, timeout=8)
        if not html_source: continue
        
        soup = BeautifulSoup(html_source, "lxml") # HTML íŒŒì‹±
        texts=[]
        # H íƒœê·¸(ì œëª©)ì™€ P, LI íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for tag in soup.find_all(["h1","h2","h3","h4","p","li"]):
            t = safe_get_text(tag)
            if not t: continue
            t = re.sub(r"\s+"," ", t)
            if 6 <= len(t) <= 260:
                texts.append(t)
        # í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•´ vision ë˜ëŠ” talentë¡œ ë¶„ë¥˜
        for t in texts:
            if any(k.lower() in t.lower() for k in ["talent","ì¸ì¬ìƒ","ì¸ì¬","ì¸ì¬ìƒì€","people we","who we hire"]):
                out["talent"].append(t)
            if any(k.lower() in t.lower() for k in ["ë¹„ì „","ë¯¸ì…˜","í•µì‹¬ê°€ì¹˜","ê°€ì¹˜","ì›ì¹™","mission","vision","values","principle"]):
                out["vision"].append(t)
    # ê²°ê³¼ ì •ë¦¬/ì¤‘ë³µ ì œê±°/ê¸¸ì´ ì œí•œ
    for k in out:
        uniq=[]; s=set()
        for x in out[k]:
            x=x.strip()
            if x and x not in s:
                s.add(x); uniq.append(x[:200])
        out[k]=uniq[:12]
    return out

# NAVER NEWS â†’ Google News RSS í´ë°± (requests ì‚¬ìš©)
def _load_naver_keys():
    """ë„¤ì´ë²„ ê²€ìƒ‰ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” secretsì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    cid = os.getenv("NAVER_CLIENT_ID")
    csec = os.getenv("NAVER_CLIENT_SECRET")
    try:
        if hasattr(st, "secrets"):
            cid = cid or st.secrets.get("NAVER_CLIENT_ID", None)
            csec = csec or st.secrets.get("NAVER_CLIENT_SECRET", None)
    except Exception:
        pass
    return cid, csec

def naver_search_news(company: str, display: int = 5) -> List[Dict]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì‚¬ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (requests ì‚¬ìš©)"""
    cid, csec = _load_naver_keys()
    if not (cid and csec): return [] # API í‚¤ ì—†ìœ¼ë©´ ë°˜í™˜
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}
    try:
        # ì¿¼ë¦¬: íšŒì‚¬ëª…, ì •ë ¬: ë‚ ì§œìˆœ, í‘œì‹œ ê°œìˆ˜ ì œí•œ
        r = requests.get(url, headers=headers, params={"query": company, "display": display, "sort":"date"}, timeout=8)
        if r.status_code != 200: return []
        js=r.json()
        items=[]
        for it in js.get("items", []):
            # HTML íƒœê·¸ ë° ì—”í‹°í‹° ì œê±° í›„ ì œëª© ì •ë¦¬
            title = re.sub(r"</?b>|&quot;|&apos;|&amp;|&lt;|&gt;", "", it.get("title","")).strip()
            items.append({"title": title, "link": it.get("link"), "pubDate": it.get("pubDate")})
        return items
    except Exception:
        return []

def google_news_rss(company: str, max_items: int = 5) -> List[Dict]:
    """ë„¤ì´ë²„ API ì‹¤íŒ¨ ì‹œ, Google News RSS í”¼ë“œë¥¼ í´ë°±ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. (requests ì‚¬ìš©)"""
    q = urllib.parse.quote(company)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR:ko" # í•œêµ­ì–´, í•œêµ­ ê¸°ì¤€ RSS
    try:
        r = requests.get(url, timeout=8)
        if r.status_code != 200: return []
        soup = BeautifulSoup(r.text, "xml") # XML íŒŒì‹±
        out=[]
        # RSS <item> íƒœê·¸ì—ì„œ ì œëª©, ë§í¬, ë‚ ì§œ ì¶”ì¶œ
        for it in soup.find_all("item")[:max_items]:
            out.append({"title": (it.title.get_text() if it.title else "").strip(),
                        "link": (it.link.get_text() if it.link else "").strip(),
                        "pubDate": (it.pubDate.get_text() if it.pubDate else "").strip()})
        return out
    except Exception:
        return []

def fetch_latest_news(company: str, max_items: int = 5) -> List[Dict]:
    """ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ì„ ì‹œë„í•˜ê³ , ë„¤ì´ë²„ ì‹¤íŒ¨ ì‹œ Googleë¡œ í´ë°±í•©ë‹ˆë‹¤."""
    items = naver_search_news(company, display=max_items)
    if items: return items
    return google_news_rss(company, max_items=max_items)

# ================== ì§ˆë¬¸/ì´ˆì•ˆ/ì±„ì /íŒ”ë¡œì—… í”„ë¡¬í”„íŠ¸ ==================
# ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
PROMPT_SYSTEM_Q = ("ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´, ê·¸ë¦¬ê³  ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ í•¨ê»˜ ê³ ë ¤í•´ "
                   "ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. ì§ˆë¬¸ì€ ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , "
                   "ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ ë“±ë„ ì„ì–´ë¼.")
# ë‹µë³€ ì´ˆì•ˆ ìƒì„± ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (STAR ê¸°ë²• ê°•ì¡°)
PROMPT_SYSTEM_DRAFT = ("ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ ê²°í•©í•´ "
                       "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ **ì´ˆì•ˆ**ì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
                       "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼.")
# ì±„ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì—„ê²©í•œ ê¸°ì¤€, JSON ì¶œë ¥ ê°•ì œ)
PROMPT_SYSTEM_SCORE_STRICT = ("ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
                              "ê° ê¸°ì¤€ì€ 0~20 ì •ìˆ˜ì´ë©°, ì´ì ì€ ê¸°ì¤€ í•©ê³„(ìµœëŒ€ 100)ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•œë‹¤. "
                              "ê³¼ì¥/ëª¨í˜¸í•¨/ê·¼ê±° ë¶€ì¬/ìˆ«ì ì—†ëŠ” ì£¼ì¥/ì±…ì„ íšŒí”¼/ëª¨í˜¸í•œ ì£¼ì–´ ì‚¬ìš© ë“±ì„ ê°•í•˜ê²Œ ê°ì í•˜ë¼. "
                              "ê° ê¸°ì¤€ì— ëŒ€í•´ ì§§ì§€ë§Œ êµ¬ì²´ì  ì½”ë©˜íŠ¸(ê°•ì /ê°ì ìš”ì¸/ê°œì„ í¬ì¸íŠ¸)ë¥¼ ì œê³µí•˜ë¼.")
# ì±„ì  ê¸°ì¤€ í•­ëª©
CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_one_question_with_resume(clean: Dict, level: str, model: str) -> str:
    """RAGë¥¼ í™œìš©í•˜ì—¬ ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # RAG: ì´ë ¥ì„œì—ì„œ 'í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ' ê´€ë ¨ ì²­í¬ë¥¼ ê²€ìƒ‰
    hits = retrieve_resume_chunks("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", k=4)
    resume_snips = [t for _, t in hits]
    resume_context = "\n".join([f"- {s[:350]}" for s in resume_snips])[:1200]

    ctx = json.dumps(clean, ensure_ascii=False)
    # ì‚¬ìš©ì ë©”ì‹œì§€: íšŒì‚¬ ì •ë³´, ì´ë ¥ì„œ ë°œì·Œ ë‚´ìš©, ìš”ì²­ ì‚¬í•­ ì „ë‹¬
    user_msg = {"role": "user",
                "content": (f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
                            f"[ì§€ì›ì ì´ë ¥ì„œ ìš”ì•½(ë°œì·Œ)]\n{resume_context}\n\n"
                            f"[ìš”ì²­]\n- ë‚œì´ë„/ì—°ì°¨: {level}\n"
                            f"- ì¤‘ë³µ/ìœ ì‚¬ë„ ì§€ì–‘, íšŒì‚¬ ìš”ê±´ê³¼ ì´ë ¥ì„œì˜ êµì§‘í•© ë˜ëŠ” ê³µë°±ì˜ì—­ì„ ê²¨ëƒ¥\n"
                            f"- í•œêµ­ì–´ ë©´ì ‘ ì§ˆë¬¸ 1ê°œë§Œ í•œ ì¤„ë¡œ ì¶œë ¥"),}
    try:
        # LLM í˜¸ì¶œ: ë†’ì€ temperature(0.85)ë¡œ ì°½ì˜ì ì¸ ì§ˆë¬¸ ìœ ë„
        resp = client.chat.completions.create(model=model, temperature=0.85,
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_Q}, user_msg],)
        q = resp.choices[0].message.content.strip()
        # ë¶ˆí•„ìš”í•œ ë²ˆí˜¸ë‚˜ ì¤„ë°”ê¿ˆ ì œê±°
        q = re.sub(r"^\s*\d+[\).\s-]*","", q).strip()
        q = q.split("\n")[0].strip()
        return q
    except Exception:
        return ""

def llm_draft_answer(clean: Dict, question: str, model: str) -> str:
    """RAGë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ STAR ê¸°ë°˜ ë‹µë³€ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # RAG: ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì´ë ¥ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
    hits = retrieve_resume_chunks(question, k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    ctx = json.dumps(clean, ensure_ascii=False)
    # ì‚¬ìš©ì ë©”ì‹œì§€: íšŒì‚¬ ì •ë³´, ì´ë ¥ì„œ ë°œì·Œ, ì§ˆë¬¸ ì „ë‹¬, STAR ê¸°ë°˜ ì´ˆì•ˆ ìš”ì²­
    user_msg = {"role": "user",
                "content": (f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
                            f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
                            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
                            "ìœ„ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ STAR ê¸°ë°˜ í•œêµ­ì–´ ë‹µë³€ **ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì¤˜.")}
    try:
        # LLM í˜¸ì¶œ: ì¤‘ê°„ temperature(0.5)ë¡œ ì‚¬ì‹¤ ê¸°ë°˜ì˜ ë…¼ë¦¬ì  ë‹µë³€ ìœ ë„
        resp = client.chat.completions.create(model=model, temperature=0.5,
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_DRAFT}, user_msg],)
        return resp.choices[0].message.content.strip()
    except Exception:
        return ""

def llm_score_and_coach_strict(clean: Dict, question: str, answer: str, model: str) -> Dict:
    """ì§€ì›ìì˜ ë‹µë³€ì„ ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ê³  ìƒì„¸ ì½”ì¹­ì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # RAG: ì§ˆë¬¸ê³¼ ë‹µë³€ì— ê´€ë ¨ëœ ì´ë ¥ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê·¼ê±° í™•ì¸ì— í™œìš©
    hits = retrieve_resume_chunks(question + "\n" + answer[:800], k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    ctx = json.dumps(clean, ensure_ascii=False)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€: íšŒì‚¬ ì •ë³´, ì´ë ¥ì„œ ë°œì·Œ, ì§ˆë¬¸, ë‹µë³€ ì œê³µ, íŠ¹ì • JSON ìŠ¤í‚¤ë§ˆ ê°•ì œ ìš”ì²­
    user_msg = {"role":"user",
                "content": (f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
                            f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
                            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
                            f"[ì§€ì›ì ë‹µë³€]\n{answer}\n\n"
                            "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
                            "{"
                            "\"overall_score\": 0~100 ì •ìˆ˜,"
                            "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
                            "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
                            "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
                            "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
                            "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
                            "\"strengths\": [\"...\", \"...\"],"
                            "\"risks\": [\"...\", \"...\"],"
                            "\"improvements\": [\"...\", \"...\", \"...\"],"
                            "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
                            "}")}
    try:
        # LLM í˜¸ì¶œ: ë‚®ì€ temperature(0.2)ë¡œ ì •í•´ì§„ ê·œì¹™ì— ë”°ë¥¸ ë…¼ë¦¬ì ì´ê³  ì¼ê´€ì ì¸ ì±„ì  ìœ ë„, JSON ì¶œë ¥ ê°•ì œ
        resp = client.chat.completions.create(model=model, temperature=0.2, response_format={"type":"json_object"}, 
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_SCORE_STRICT}, user_msg])
        data = json.loads(resp.choices[0].message.content)
        
        # í›„ì²˜ë¦¬: JSON ë°ì´í„°ì˜ ë¬´ê²°ì„± ë° í˜•ì‹ ê²€ì‚¬/ìˆ˜ì •
        crit = data.get("criteria", [])
        fixed=[]
        for name in CRITERIA:
            found=None
            for it in crit:
                if str(it.get("name","")).strip()==name: found=it; break
            if not found: found={"name":name,"score":0,"comment":""}
            # ì ìˆ˜ ë²”ìœ„ ê°•ì œ (0~20)
            sc = int(found.get("score",0)); sc=max(0,min(20,sc))
            found["score"]=sc; found["comment"]=str(found.get("comment","")).strip()
            fixed.append(found)
        total=sum(x["score"] for x in fixed) # ì´ì  ì¬ê³„ì‚°
        data["criteria"]=fixed
        data["overall_score"]=total
        
        # ê°•ì , ë¦¬ìŠ¤í¬, ê°œì„ ì  í•­ëª© ì •ë¦¬
        for k in ["strengths","risks","improvements"]:
            arr=data.get(k,[]); 
            if not isinstance(arr,list): arr=[]
            data[k]=[str(x).strip() for x in arr if str(x).strip()][:5]
        data["revised_answer"]=str(data.get("revised_answer","")).strip()
        return data
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
        return {"overall_score": 0,
                "criteria": [{"name": n, "score": 0, "comment": ""} for n in CRITERIA],
                "strengths": [], "risks": [], "improvements": [], "revised_answer": "",
                "error": str(e),}

# ================== ì„¸ì…˜ ìƒíƒœ ==================
def _init_state():
    """Streamlit ì„¸ì…˜ ìƒíƒœ(st.session_state) ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    for k, v in {"clean_struct": None,         # LLMì´ ì •ì œí•œ ì±„ìš© ê³µê³  êµ¬ì¡°í™” JSON
                 "resume_raw": "",             # ì—…ë¡œë“œëœ ì´ë ¥ì„œì˜ ì›ë¬¸ í…ìŠ¤íŠ¸
                 "resume_chunks": [],          # ì´ë ¥ì„œ ì›ë¬¸ì´ ë¶„í• ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
                 "resume_embeds": None,        # ì´ë ¥ì„œ ì²­í¬ì˜ ì„ë² ë”© ë²¡í„° ë°°ì—´
                 "current_question": "",       # í˜„ì¬ ëª¨ì˜ ë©´ì ‘ ì§ˆë¬¸
                 "answer_text": "",            # ì‚¬ìš©ìê°€ ì…ë ¥/í¸ì§‘í•œ ë‹µë³€
                 "records": [],                # ë©´ì ‘ ê¸°ë¡ (íˆìŠ¤í† ë¦¬)
                 "followups": [],              # íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ ë¦¬ìŠ¤íŠ¸
                 "selected_followup": "",      # ì„ íƒëœ íŒ”ë¡œì—… ì§ˆë¬¸
                 "followup_answer": "",        # íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€
                 "last_result": None,          # ë©”ì¸ ì§ˆë¬¸ì˜ ë§ˆì§€ë§‰ ì±„ì  ê²°ê³¼
                 "last_followup_result": None, # íŒ”ë¡œì—… ì§ˆë¬¸ì˜ ë§ˆì§€ë§‰ ì±„ì  ê²°ê³¼
                 "company_home": "",           # íšŒì‚¬ í™ˆí˜ì´ì§€ URL
                 "company_vision": [],         # ìŠ¤í¬ë˜í•‘ëœ íšŒì‚¬ ë¹„ì „/ê°€ì¹˜
                 "company_talent": [],         # ìŠ¤í¬ë˜í•‘ëœ íšŒì‚¬ ì¸ì¬ìƒ
                 "company_news": [] }.items(): # ê²€ìƒ‰ëœ íšŒì‚¬ ìµœì‹  ë‰´ìŠ¤
        if k not in st.session_state: st.session_state[k] = v
_init_state()

# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ ==================
st.header("1) ì±„ìš© ê³µê³  URL")
# ì±„ìš© ê³µê³  URL ì…ë ¥ í•„ë“œ
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì·¨ì—… í¬í„¸ ì‚¬ì´íŠ¸ì˜ URLì„ ì…ë ¥í•˜ì„¸ìš”.")

# íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL ì…ë ¥ (ë¹„ì „/ì¸ì¬ìƒ ìŠ¤í¬ë˜í•‘ì— ì‚¬ìš©)
st.text_input("íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL (ì„ íƒ)", key="company_home", placeholder="íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
# ì •ì œ ì‹œì‘ ë²„íŠ¼
if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ (Selenium ì‹¤í–‰)", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        # 1ë‹¨ê³„: ì›ë¬¸ ìˆ˜ì§‘ (Selenium ê¸°ë°˜) ë° ë©”íƒ€ë°ì´í„° íŒíŠ¸ ì¶”ì¶œ
        with st.spinner("Seleniumìœ¼ë¡œ ì›ë¬¸ ìˆ˜ì§‘ ë° ë Œë”ë§ ì¤‘..."):
            # fetch_all_text í•¨ìˆ˜ëŠ” ì´ì œ Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            raw, meta, soup = fetch_all_text(url.strip()) 
            hint = extract_company_meta(soup)
        if not raw:
            st.error(f"ì›ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Selenium ë Œë”ë§ ì‹¤íŒ¨: {meta.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')})")
        else:
            # 2ë‹¨ê³„: LLMì„ ì‚¬ìš©í•œ êµ¬ì¡°í™” ì •ì œ
            with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
                clean = llm_structurize(raw, hint, CHAT_MODEL)
            # LLM ê²°ê³¼ì— ìš°ëŒ€ ì‚¬í•­ì´ ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ íŒŒì„œ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ë³´ì™„
            if not clean.get("preferences"):
                rb = rule_based_sections(raw)
                if rb.get("preferences"):
                    clean["preferences"] = rb["preferences"][:12]
            st.session_state.clean_struct = clean # ì •ì œ ê²°ê³¼ ì„¸ì…˜ ì €ì¥

            # 3ë‹¨ê³„: íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ ì¶”ê°€ ìˆ˜ì§‘ (Selenium ì‚¬ìš©)
            with st.spinner("íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ í™•ì¸ ì¤‘..."):
                # fetch_company_pages í•¨ìˆ˜ë„ Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                vis = []; tal = []
                if st.session_state.company_home.strip():
                    extra = fetch_company_pages(st.session_state.company_home.strip())
                    vis = extra.get("vision", [])
                    tal = extra.get("talent", [])
                # ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ (requests/API ì‚¬ìš©)
                cname = clean.get("company_name") or hint.get("company_name") or ""
                news_items = fetch_latest_news(cname, max_items=5) if cname else []

                st.session_state.company_vision = vis
                st.session_state.company_talent = tal
                st.session_state.company_news = news_items

            st.success("ì •ì œ ì™„ë£Œ!")

# ================== 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ==================
st.header("2) íšŒì‚¬ ìš”ì•½")
clean = st.session_state.clean_struct
if clean:
    # ì •ì œëœ íšŒì‚¬/ì§ë¬´ ì •ë³´ë¥¼ í‘œì‹œ
    st.markdown(f"**íšŒì‚¬ëª…:** {clean.get('company_name','-')}")
    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½):** {clean.get('company_intro','-')}")
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {clean.get('job_title','-')}")
    # ì—…ë¬´, ìê²©, ìš°ëŒ€ ì‚¬í•­ì„ 3ë‹¨ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("**ì£¼ìš” ì—…ë¬´**")
        for b in clean.get("responsibilities", []): st.markdown(f"- {b}")
    with c2:
        st.markdown("**ìê²© ìš”ê±´**")
        for b in clean.get("qualifications", []): st.markdown(f"- {b}")
    with c3:
        st.markdown("**ìš°ëŒ€ ì‚¬í•­**")
        prefs = clean.get("preferences", [])
        if prefs:
            for b in prefs: st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ì¶”ê°€ ì •ë³´ (ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤) í‘œì‹œ
    if st.session_state.company_vision or st.session_state.company_talent or st.session_state.company_news:
        st.divider()
        st.subheader("íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ & ìµœì‹  ì´ìŠˆ")  
        colv, colt = st.columns(2)
        with colv:
            st.markdown("**ë¹„ì „/í•µì‹¬ê°€ì¹˜ (Selenium ìŠ¤í¬ë˜í•‘)**")
            for v in st.session_state.company_vision[:8]:
                st.markdown(f"- {v}")
            if not st.session_state.company_vision:
                st.caption("ë¹„ì „/í•µì‹¬ê°€ì¹˜ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        with colt:
            st.markdown("**ì¸ì¬ìƒ (Selenium ìŠ¤í¬ë˜í•‘)**")
            for t in st.session_state.company_talent[:8]:
                st.markdown(f"- {t}")
            if not st.session_state.company_talent:
                st.caption("ì¸ì¬ìƒ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        if st.session_state.company_news:
            st.markdown("**ìµœì‹  ë‰´ìŠ¤(ìƒìœ„ 3~5ê±´)**")
            for n in st.session_state.company_news[:5]:
                # ë‰´ìŠ¤ ì œëª©ê³¼ ë§í¬ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
                st.markdown(f"- [{n.get('title','(ì œëª© ì—†ìŒ)')}]({n.get('link','#')})")

else:
    st.info("ë¨¼ì € URLì„ ì •ì œí•´ ì£¼ì„¸ìš”.")

st.divider()

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (PDF/TXT/MD/DOCX) ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
# ì´ë ¥ì„œ íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ (ë³µìˆ˜ íŒŒì¼ ì§€ì›)
uploads = st.file_uploader("ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ ê°€ëŠ¥", type=["pdf","txt","md","docx"], accept_multiple_files=True)
# RAG ì²­í¬ í¬ê¸° ë° ì˜¤ë²„ë© ì„¤ì •
_RESUME_CHUNK = 500
_RESUME_OVLP  = 100

cols_idx = st.columns(2)
with cols_idx[0]:
    # ì´ë ¥ì„œ ì¸ë±ì‹± ë²„íŠ¼ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì„ë² ë”© ë²¡í„° ìƒì„±)
    if st.button("ì´ë ¥ì„œ ì¸ë±ì‹±", type="secondary"):
        if not uploads:
            st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            all_text=[]
            # ê° íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for up in uploads:
                t = read_file_text(up)
                if t: all_text.append(t)
            resume_text = "\n\n".join(all_text)
            if not resume_text.strip():
                st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
                chunks = chunk(resume_text, size=_RESUME_CHUNK, overlap=_RESUME_OVLP)
                # ì²­í¬ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ (RAG ì¤€ë¹„)
                with st.spinner("ì´ë ¥ì„œ ë²¡í„°í™” ì¤‘..."):
                    embeds = embed_texts(chunks, EMBED_MODEL)
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.resume_raw = resume_text
                st.session_state.resume_chunks = chunks
                st.session_state.resume_embeds = embeds
                st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)")

st.divider()

# ================== 4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„± ==================
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
# ìì†Œì„œ ì£¼ì œ ì…ë ¥ í•„ë“œ (ì„ íƒ ì‚¬í•­)
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“±")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš© ê³µê³ , íšŒì‚¬ ë¹„ì „/ë‰´ìŠ¤, ì´ë ¥ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì†Œì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # LLM ì»¨í…ìŠ¤íŠ¸ì— íšŒì‚¬ ë¹„ì „, ì¸ì¬ìƒ, ë‰´ìŠ¤ ì •ë³´ë¥¼ ì¶”ê°€
    enrich = {"vision": st.session_state.company_vision[:6],
              "talent": st.session_state.company_talent[:6],
              "news": [n.get("title","") for n in st.session_state.company_news[:3]]}
    company = json.dumps({"clean":clean_struct, "extra":enrich}, ensure_ascii=False)
    
    # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    resume_snippet = resume_text.strip()
    if len(resume_snippet) > 9000:
        resume_snippet = resume_snippet[:9000]
        
    # ì‹œìŠ¤í…œ ì—­í•  í”„ë¡¬í”„íŠ¸
    system = ("ë„ˆëŠ” í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì „ë¬¸ê°€ë‹¤. ì±„ìš© ê³µê³ ì˜ íšŒì‚¬/ì§ë¬´ ìš”ê±´ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•´ "
              "íšŒì‚¬ íŠ¹í™” ìì†Œì„œë¥¼ ì‘ì„±í•œë‹¤. ê³¼ì¥/í—ˆìœ„ëŠ” ê¸ˆì§€í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´í™”í•œë‹¤. "
              "íšŒì‚¬ì˜ ë¹„ì „/ì¸ì¬ìƒ/ìµœê·¼ ì´ìŠˆê°€ ì œê³µë˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ë¼.")
              
    # ì£¼ì œ ìš”ì²­ì— ë”°ë¥¸ ì¡°ê±´ ë¶„ê¸°
    if topic_hint and topic_hint.strip():
        req = f"íšŒì‚¬ ì¸¡ ìš”ì²­ ì£¼ì œëŠ” '{topic_hint.strip()}' ì´ë‹¤. ì´ ì£¼ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•˜ë¼."
    else:
        req = "íŠ¹ì • ì£¼ì œ ìš”ì²­ì´ ì—†ìœ¼ë¯€ë¡œ, ì±„ìš© ê³µê³ ì™€ ë¹„ì „/ì¸ì¬ìƒì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§€ì›ë™ê¸°ì™€ ì§ë¬´ì í•©ì„±ì„ ê°•ì¡°í•˜ë¼."
        
    # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±: ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ê³  êµ¬ì²´ì ì¸ í˜•ì‹ ê°€ì´ë“œë¼ì¸ ì œì‹œ
    user = (f"[íšŒì‚¬/ì§ë¬´ ìš”ì•½(JSON)]\n{company}\n\n"
            f"[í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½ ê°€ëŠ¥)]\n{resume_snippet}\n\n"
            f"[ì‘ì„± ì§€ì‹œ]\n- {req}\n"
            "- ë¶„ëŸ‰: 600~900ì\n"
            "- êµ¬ì„±: 1) ì§€ì› ë™ê¸° 2) ì§ë¬´ ê´€ë ¨ í•µì‹¬ ì—­ëŸ‰Â·ê²½í—˜ 3) ì„±ê³¼/ì§€í‘œ 4) ì…ì‚¬ í›„ ê¸°ì—¬ ë°©ì•ˆ 5) ë§ˆë¬´ë¦¬\n"
            "- ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆëŠ” 1ì¸ì¹­ ì„œìˆ . ë¬¸ì¥ê³¼ ë¬¸ë‹¨ ê°€ë…ì„±ì„ ìœ ì§€.\n"
            "- ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬/ì¤‘ë³µ/ê´‘ê³  ë¬¸êµ¬ ì‚­ì œ.")
            
    try:
        # LLM í˜¸ì¶œ: ë‹µë³€ì˜ ì¼ê´€ì„±ê³¼ ì°½ì˜ì„± ì‚¬ì´ì—ì„œ ê· í˜• (temperature 0.4)
        resp = client.chat.completions.create(model=model, temperature=0.4,
                                              messages=[{"role":"system","content":system},{"role":"user","content":user}])
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(ìì†Œì„œ ìƒì„± ì‹¤íŒ¨: {e})"

# ìì†Œì„œ ìƒì„± ë²„íŠ¼
if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
    elif not st.session_state.resume_raw.strip():
        st.warning("ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  'ì´ë ¥ì„œ ì¸ë±ì‹±(ìë™)'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cover = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_raw, topic, CHAT_MODEL)
        st.subheader("ìì†Œì„œ (ìƒì„± ê²°ê³¼)")
        st.write(cover)
        # ìƒì„±ëœ ìì†Œì„œë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆëŠ” ë²„íŠ¼ ì œê³µ
        st.download_button("ìì†Œì„œ TXT ë‹¤ìš´ë¡œë“œ", data=cover.encode("utf-8"),file_name="cover_letter.txt", mime="text/plain")

st.divider()

# ================== 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©) ==================
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
# ë©´ì ‘ ì§ˆë¬¸ ë‚œì´ë„/ì—°ì°¨ ì„ íƒ
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

cols_q = st.columns(2)
with cols_q[0]:
    # ìƒˆ ì§ˆë¬¸ ë°›ê¸° ë²„íŠ¼
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct:
            st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
        else:
            # ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
            q = llm_generate_one_question_with_resume(st.session_state.clean_struct, level, CHAT_MODEL)
            if q:
                # ìƒˆë¡œìš´ ì§ˆë¬¸/ë‹µë³€/ê²°ê³¼ë¡œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë° ì§ˆë¬¸ ì €ì¥
                st.session_state.current_question = q
                st.session_state.answer_text = ""
                st.session_state.last_result = None
                st.session_state.followups = []
                st.session_state.selected_followup = ""
                st.session_state.followup_answer = ""
                st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
with cols_q[1]:
    # RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„± ë²„íŠ¼
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        else:
            # ë‹µë³€ ì´ˆì•ˆ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
            draft = llm_draft_answer(st.session_state.clean_struct, st.session_state.current_question, CHAT_MODEL)
            if draft:
                st.session_state.answer_text = draft # ì´ˆì•ˆì„ ë‹µë³€ í…ìŠ¤íŠ¸ ì˜ì—­ì— ìë™ ì…ë ¥
                st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")

# ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì˜ì—­ (ê°’ì€ ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´)
st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
# ë‹µë³€ í…ìŠ¤íŠ¸ ì˜ì—­ (keyë¥¼ 'answer_text'ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©ìì˜ í¸ì§‘ ë‚´ìš©ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥)
ans = st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# ================== 6) ì±„ì  & ì½”ì¹­ (ì—„ê²© ëª¨ë“œ) ==================
st.header("6) ì±„ì  & ì½”ì¹­")
# ì±„ì  ë° ì½”ì¹­ ì‹¤í–‰ ë²„íŠ¼
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì±„ì /ì½”ì¹­ ì¤‘..."):
            # ì±„ì  ë° ì½”ì¹­ í•¨ìˆ˜ í˜¸ì¶œ
            res = llm_score_and_coach_strict(st.session_state.clean_struct,
                                             st.session_state.current_question,
                                             st.session_state.answer_text,
                                             CHAT_MODEL)
        st.session_state.last_result = res # ìµœì¢… ê²°ê³¼ ì €ì¥
        # ë©´ì ‘ ê¸°ë¡(records)ì— í˜„ì¬ ê²°ê³¼ ì¶”ê°€
        st.session_state.records.append({"question": st.session_state.current_question,
                                         "answer": st.session_state.answer_text, 
                                         "overall": res.get("overall_score", 0),
                                         "criteria": res.get("criteria", []),
                                         "strengths": res.get("strengths", []),
                                         "risks": res.get("risks", []),
                                         "improvements": res.get("improvements", []),
                                         "revised_answer": res.get("revised_answer","")})
        st.success("ì±„ì /ì½”ì¹­ ì™„ë£Œ!")

# ================== 7) í”¼ë“œë°± ê²°ê³¼ (ì•„ë˜ì— íŒ”ë¡œì—… ì¸ë¼ì¸ ë°°ì¹˜) ==================
st.header("7) í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.last_result
if last:
    # ì´ì ê³¼ ìƒì„¸ ì½”ë©˜íŠ¸ë¥¼ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
    left, right = st.columns([1,3])
    with left:
        st.metric("ì´ì (/100)", last.get("overall_score", 0))
    with right:
        st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜ & ì½”ë©˜íŠ¸**")
        for it in last.get("criteria", []):
            st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
        # ê°•ì , ê°ì  ìš”ì¸, ê°œì„  í¬ì¸íŠ¸ë¥¼ ëª©ë¡ìœ¼ë¡œ í‘œì‹œ
        if last.get("strengths"):
            st.markdown("**ê°•ì **")
            for s in last["strengths"]: st.markdown(f"- {s}")
        if last.get("risks"):
            st.markdown("**ê°ì  ìš”ì¸/ë¦¬ìŠ¤í¬**")
            for r in last["risks"]: st.markdown(f"- {r}")
        if last.get("improvements"):
            st.markdown("**ê°œì„  í¬ì¸íŠ¸**")
            for im in last["improvements"]: st.markdown(f"- {im}")
        if last.get("revised_answer"):
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR)**")
            st.write(last["revised_answer"])
else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# ================== 8) íŒ”ë¡œì—… ì§ˆë¬¸ â†’ ë‹µë³€ â†’ íŒ”ë¡œì—… í”¼ë“œë°± ==================
st.subheader("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")
# ë©”ì¸ ì§ˆë¬¸ ì±„ì  ê²°ê³¼ê°€ ìˆê³ , íŒ”ë¡œì—… ì§ˆë¬¸ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ë‹¤ë©´ LLMì—ê²Œ íŒ”ë¡œì—… ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­
if last and not st.session_state.followups:
    try:
        # íšŒì‚¬/ì§ë¬´/ë¹„ì „/ì´ìŠˆ ë“± ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        ctx = json.dumps({"company": st.session_state.clean_struct,
                          "vision": st.session_state.company_vision[:6],
                          "talent": st.session_state.company_talent[:6],
                          "news": [n.get("title","") for n in st.session_state.company_news[:3]]}, ensure_ascii=False)
        # ì‚¬ìš©ì ë©”ì‹œì§€: ë‹µë³€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ê´€ ê´€ì ì—ì„œ 3ê°œì˜ íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ ìš”ì²­
        msg = {"role":"user",
               "content":(f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´/ë¹„ì „/ì´ìŠˆ]\n{ctx}\n\n"
                          f"[ì§€ì›ì ë‹µë³€]\n{st.session_state.answer_text}\n\n"
                          "ë©´ì ‘ê´€ ê´€ì ì—ì„œ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ í•œ ì¤„ì”© í•œêµ­ì–´ë¡œ ì œì•ˆí•´ì¤˜. "
                          "ê¸°ì¡´ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šê²Œ, ì§€í‘œ/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„/ì˜ì‚¬ê²°ì • ê·¼ê±°ë¥¼ ì„ì–´ì¤˜.")}
        r = client.chat.completions.create(model=CHAT_MODEL, temperature=0.7,
                                           messages=[{"role":"system","content":"ë©´ì ‘ íŒ”ë¡œì—… ìƒì„±ê¸°"}, msg])
        # ë‹µë³€ì—ì„œ ì¤„ë³„ë¡œ ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ê³  ë²ˆí˜¸/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        followups = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip()
                     for l in r.choices[0].message.content.splitlines() if l.strip()]
        st.session_state.followups = followups[:3]
    except Exception:
        st.session_state.followups = []

if last:
    if st.session_state.followups:
        st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
        for i, f in enumerate(st.session_state.followups, 1):
            st.markdown(f"- ({i}) {f}")

        # íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ ë° ë‹µë³€ ì…ë ¥ í•„ë“œ
        st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0, key="selected_followup")
        st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")
        
        # íŒ”ë¡œì—… ì±„ì  ë²„íŠ¼
        if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
            fu_q   = st.session_state.get("selected_followup", "")
            fu_ans = st.session_state.get("followup_answer", "")
            if not fu_q:
                st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif not fu_ans.strip():
                st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
            else:
                with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘..."):
                    # íŒ”ë¡œì—… ë‹µë³€ì— ëŒ€í•œ ì±„ì  ë° ì½”ì¹­ ì‹¤í–‰
                    res_fu = llm_score_and_coach_strict(st.session_state.clean_struct, fu_q, fu_ans, CHAT_MODEL)
                st.session_state.last_followup_result = res_fu # íŒ”ë¡œì—… ê²°ê³¼ ì €ì¥
                
                # íŒ”ë¡œì—… ì±„ì  ê²°ê³¼ í‘œì‹œ
                st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
                st.metric("ì´ì (/100)", res_fu.get("overall_score", 0))
                for it in res_fu.get("criteria", []):
                    st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
                if res_fu.get("revised_answer",""):
                    st.markdown("**íŒ”ë¡œì—… ìˆ˜ì •ë³¸ (STAR)**")
                    st.write(res_fu["revised_answer"])
    else:
        st.caption("íŒ”ë¡œì—… ì§ˆë¬¸ì€ ë©”ì¸ ì§ˆë¬¸ ì±„ì  ì§í›„ ìë™ ì œì•ˆë©ë‹ˆë‹¤.")