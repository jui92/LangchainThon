# -*- coding: utf-8 -*-
import os, io, re, textwrap, time, random, urllib.parse
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
import requests
from bs4 import BeautifulSoup

import streamlit as st

# ---------- Optional deps ----------
try:
    import pypdf
except Exception:
    pypdf = None

try:
    import docx  # python-docx
except Exception:
    docx = None

try:
    import plotly.graph_objects as go
    PLOTLY_OK = True
except Exception:
    PLOTLY_OK = False

# ---------- OpenAI SDK (>=1.x) ----------
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# ==========================
# Page config
# ==========================
st.set_page_config(page_title="íšŒì‚¬ íŠ¹í™” ë©´ì ‘ ì½”ì¹˜", page_icon="ğŸ¯", layout="wide")

# ==========================
# Helpers
# ==========================
def clean(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "").strip())

def snippet(t: str, n: int = 220) -> str:
    t = clean(t)
    return t if len(t) <= n else t[: n - 1] + "â€¦"

def get_api_key() -> Optional[str]:
    key = os.getenv("OPENAI_API_KEY")
    if key:
        return key
    try:
        return st.secrets.get("OPENAI_API_KEY", None)  # type: ignore
    except Exception:
        return None

def init_openai_client() -> Optional[OpenAI]:
    api_key = get_api_key()
    if not api_key or OpenAI is None:
        return None
    try:
        return OpenAI(api_key=api_key, timeout=30.0)
    except Exception:
        return None

# ---------- fetch page text ----------
def fetch_url_text(url: str, timeout: int = 12) -> str:
    """Fetch visible text from a static HTML page."""
    try:
        if not url.startswith("http"):
            url = "https://" + url
        r = requests.get(url, timeout=timeout, headers={"User-Agent": "Mozilla/5.0"})
        if r.status_code != 200:
            return ""
        soup = BeautifulSoup(r.text, "html.parser")
        # remove scripts/styles/nav
        for tag in soup(["script", "style", "noscript"]):
            tag.extract()
        text = soup.get_text("\n")
        # collapse whitespace
        text = re.sub(r"[ \t]+", " ", text)
        text = re.sub(r"\n{2,}", "\n", text)
        return text.strip()
    except Exception:
        return ""

# ---------- file readers ----------
def read_any_file(uploaded) -> str:
    name = uploaded.name.lower()
    raw = uploaded.read()

    if name.endswith((".txt", ".md")):
        for enc in ("utf-8", "cp949", "euc-kr"):
            try:
                return raw.decode(enc)
            except Exception:
                continue
        return raw.decode("utf-8", errors="ignore")

    if name.endswith(".pdf"):
        if pypdf is None:
            st.warning("PDF íŒŒì‹±: pypdf ë¯¸ì„¤ì¹˜")
            return ""
        try:
            reader = pypdf.PdfReader(io.BytesIO(raw))
            parts = []
            for i in range(len(reader.pages)):
                parts.append(reader.pages[i].extract_text() or "")
            return "\n".join(parts)
        except Exception as e:
            st.warning(f"PDF íŒŒì‹± ì‹¤íŒ¨: {e}")
            return ""

    if name.endswith(".docx"):
        if docx is None:
            st.warning("DOCX íŒŒì‹±: python-docx ë¯¸ì„¤ì¹˜")
            return ""
        try:
            f = io.BytesIO(raw)
            d = docx.Document(f)
            return "\n".join([p.text for p in d.paragraphs])
        except Exception as e:
            st.warning(f"DOCX íŒŒì‹± ì‹¤íŒ¨: {e}")
            return ""

    return ""

# ---------- LLM wrappers ----------
def llm_struct_from_job(client: OpenAI, model: str, url_text: str) -> Dict:
    """
    ì±„ìš© ê³µê³  ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”: íšŒì‚¬ëª…, íšŒì‚¬ì†Œê°œ(ìš”ì•½), ëª¨ì§‘ë¶„ì•¼, ì£¼ìš”ì—…ë¬´[], ìê²©ìš”ê±´[], ìš°ëŒ€ì‚¬í•­[]
    """
    sys = "ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ìë‹¤. í•œêµ­ì–´ë¡œë§Œ ë‹µí•˜ë¼."
    prompt = f"""ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì—ì„œ í•­ëª©ì„ êµ¬ì¡°í™”í•´ì¤˜.
ì›ë¬¸ì€ ì¡ë‹¤í•œ ë¬¸êµ¬(ë³µì§€, ê´‘ê³ , ë³´ìƒ ë“±)ë„ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë‹ˆ 'ì£¼ìš”ì—…ë¬´/ìê²©ìš”ê±´/ìš°ëŒ€ì‚¬í•­'ê³¼ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” í•­ëª©ì€ ì œì™¸í•˜ê³  ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´.

[ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
{{
  "company_name": "<ë¬¸ìì—´>",
  "company_intro": "<2~3ë¬¸ì¥ ìš”ì•½>",
  "role_title": "<ì§ë¬´ëª…/ëª¨ì§‘ë¶„ì•¼>",
  "responsibilities": ["ë¶ˆë¦¿", "..."],
  "qualifications": ["ë¶ˆë¦¿", "..."],
  "preferences": ["ë¶ˆë¦¿", "..."]
}}

[ì›ë¬¸]
{url_text[:6000]}
"""
    try:
        r = client.chat.completions.create(
            model=model,
            temperature=0.2,
            messages=[{"role": "system", "content": sys},
                      {"role": "user", "content": prompt}]
        )
        txt = r.choices[0].message.content.strip()
        # JSON ì¶”ì¶œ ëŠìŠ¨í•˜ê²Œ
        m = re.search(r"\{.*\}", txt, re.S)
        if not m:
            return {}
        import json
        data = json.loads(m.group(0))
        # ë³´ì •
        for k in ["responsibilities", "qualifications", "preferences"]:
            v = data.get(k)
            if isinstance(v, str):
                # ì¤„ë°”ê¿ˆ/ë¶ˆë¦¿ ë¶„í•´
                items = [clean(x) for x in re.split(r"[\n;â€¢\-Â·â–¶â–ªï¸]+", v) if len(clean(x)) > 1]
                data[k] = items[:12]
            elif isinstance(v, list):
                data[k] = [clean(x) for x in v if len(clean(x)) > 1][:12]
            else:
                data[k] = []
        data["company_intro"] = snippet(data.get("company_intro", ""), 400)
        return data
    except Exception:
        return {}

def llm_generate_questions(client: OpenAI, model: str, ctx: str, n: int = 5) -> List[str]:
    sys = "ë„ˆëŠ” ë©´ì ‘ê´€ì´ë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ë³´ê³  ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•œë‹¤. í•œêµ­ì–´ë¡œë§Œ ë‹µí•´ë¼."
    prompt = f"""[ì»¨í…ìŠ¤íŠ¸]
{ctx}

í˜•ì‹: ë²ˆí˜¸) ì§ˆë¬¸ í•œ ì¤„
ê°œìˆ˜: {n}ê°œ
ì¡°ê±´:
- ì„œë¡œ ê´€ì , í‚¤ì›Œë“œ, ê²€ì¦ í¬ì¸íŠ¸ê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í•˜ê²Œ
- ì§€í‘œ/ìˆ˜ì¹˜/ê·œëª¨/ê¸°ê°„/íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ë“œëŸ¬ë‚˜ê²Œ
- ì‹¤ë¬´ì—ì„œ ì‹¤ì œë¡œ ê²€ì¦í•˜ê³  ì‹¶ì€ í¬ì¸íŠ¸ë¥¼ ë°˜ì˜
"""
    r = client.chat.completions.create(
        model=model, temperature=0.9,
        messages=[{"role":"system","content":sys},{"role":"user","content":prompt}]
    )
    raw = r.choices[0].message.content.strip()
    qs = [re.sub(r"^\s*\d+\)\s*","",line).strip() for line in raw.splitlines() if re.match(r"^\s*\d+\)", line)]
    if not qs:
        qs = [l.strip("- ").strip() for l in raw.splitlines() if len(l.strip())>0][:n]
    return qs[:n]

def parse_scores_from_text(txt: str) -> Tuple[Optional[int], Optional[List[int]]]:
    # overall
    overall = None
    m = re.search(r'(\d{1,3})\s*(?:/100|ì )\b', txt)
    if m:
        overall = max(0, min(100, int(m.group(1))))
    if overall is None:
        m2 = re.search(r'\b(\d{1,2})/10\b', txt)
        if m2:
            overall = int(m2.group(1)) * 10

    # five criteria 0~20
    last_line = txt.splitlines()[-1]
    nums = re.findall(r'\b(\d{1,2})\b', last_line)
    if len(nums) < 5:
        nums = re.findall(r'\b(\d{1,2})\b', txt)
    comp = None
    if len(nums) >= 5:
        cand = [int(x) for x in nums[:5]]
        if all(0 <= x <= 5 for x in cand):
            cand = [x*4 for x in cand]
        elif all(0 <= x <= 10 for x in cand) and any(x>5 for x in cand):
            cand = [x*2 for x in cand]
        comp = [max(0, min(20, x)) for x in cand]
    return overall, comp

def llm_score_and_coach_strict(client: OpenAI, model: str, company_ctx: str,
                               question: str, answer: str) -> Dict:
    sys = """ë„ˆëŠ” ê¹ê¹í•œ ë©´ì ‘ ì½”ì¹˜ë‹¤. í•œêµ­ì–´. ë‹¤ìŒ í˜•ì‹ì„ ì² ì €íˆ ì§€ì¼œë¼:
1) ì´ì : 0~100 ì •ìˆ˜ 1ê°œ
2) ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ):
   - ë¬¸ì œì •ì˜(x/20): ...
   - ë°ì´í„°/ì§€í‘œ(x/20): ...
   - ì‹¤í–‰ë ¥/ì£¼ë„ì„±(x/20): ...
   - í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜(x/20): ...
   - ê³ ê°ê°€ì¹˜(x/20): ...
3) ìˆ˜ì •ë³¸ ë‹µë³€(STAR)
4) ì—­ëŸ‰ ì ìˆ˜(ì‰¼í‘œë¡œ 5ê°œë§Œ): a,b,c,d,e
"""
    user = f"""[íšŒì‚¬/ì§ë¬´ ì»¨í…ìŠ¤íŠ¸]
{company_ctx}

[ë©´ì ‘ ì§ˆë¬¸]
{question}

[í›„ë³´ì ë‹µë³€]
{answer}
"""
    r = client.chat.completions.create(
        model=model, temperature=0.3,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    content = r.choices[0].message.content.strip()
    overall, comp = parse_scores_from_text(content)
    # ì„¹ì…˜ íŒŒì‹±(ê°„ë‹¨)
    revised = ""
    m = re.search(r"ìˆ˜ì •ë³¸\s*ë‹µë³€.*?\n(.+)", content, re.S)
    if m:
        revised = m.group(1).strip()
    crit = []
    for key in ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]:
        m2 = re.search(rf"{key}\s*\((\d+)\s*/\s*20\)\s*:\s*(.+)", content)
        if m2:
            crit.append({"name": key, "score": int(m2.group(1)), "comment": m2.group(2)})
    return {
        "raw": content,
        "overall": overall if overall is not None else 0,
        "competencies": comp if comp else None,
        "revised": revised,
        "criteria": crit
    }

# ==========================
# Sidebar (settings)
# ==========================
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ì±— ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    st.caption("OpenAI í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜/Secretsì—ì„œ ìë™ ì½ê¸°")
client = init_openai_client()
if client is None:
    st.error("OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨. OPENAI_API_KEY ì„¤ì • í•„ìš”.")
    st.stop()

# ==========================
# Session init
# ==========================
for k, v in {
    "job_raw_text": "",
    "clean_struct": {},
    "questions": [],
    "current_question": "",
    "answer_text": "",
    "history": [],
    # íŒ”ë¡œì—…
    "followups": [],
    "selected_followup": "",
    "followup_answer": "",
    "last_followup_result": None,
}.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ============================================================
# 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ (ì›ë¬¸ ìˆ˜ì§‘ & êµ¬ì¡°í™”)
# ============================================================
st.header("1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ")
job_url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="https://.../wd/xxxxx")
colb1, colb2 = st.columns([1, 3])
with colb1:
    if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
        if not job_url.strip():
            st.warning("ì±„ìš© ê³µê³  URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
                raw = fetch_url_text(job_url.strip())
                st.session_state.job_raw_text = raw
            if not raw:
                st.warning("ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸/JS ë Œë”ë§ ë“±)")
            else:
                with st.spinner("êµ¬ì¡°í™”/ì •ì œ ì¤‘..."):
                    data = llm_struct_from_job(client, CHAT_MODEL, raw)
                if not data:
                    st.warning("ì •ì œ ê²°ê³¼ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    data["job_url"] = job_url.strip()
                    st.session_state.clean_struct = data
with colb2:
    st.caption("íŒ: ë¡œê·¸ì¸ í˜ì´ì§€/ë™ì  ë Œë”ë§ ì‚¬ì´íŠ¸ëŠ” í…ìŠ¤íŠ¸ê°€ ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ============================================================
# 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)
# ============================================================
st.header("2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")
c = st.session_state.clean_struct
if c:
    cc1, cc2 = st.columns([2, 1])
    with cc1:
        st.markdown(f"**íšŒì‚¬ëª…:** {c.get('company_name','-')}")
        st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {c.get('role_title','-')}")
        st.markdown("**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½)**")
        st.write(c.get("company_intro","-"))

    with cc2:
        if c.get("job_url"):
            st.link_button("ì±„ìš© ê³µê³  ì—´ê¸°", c["job_url"])
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("### ì£¼ìš” ì—…ë¬´")
        if c.get("responsibilities"):
            for b in c["responsibilities"]:
                st.markdown(f"- {b}")
        else:
            st.caption("ì£¼ìš” ì—…ë¬´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    with col2:
        st.markdown("### ìê²© ìš”ê±´")
        if c.get("qualifications"):
            for b in c["qualifications"]:
                st.markdown(f"- {b}")
        else:
            st.caption("ìê²© ìš”ê±´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    with col3:
        st.markdown("### ìš°ëŒ€ ì‚¬í•­")
        if c.get("preferences"):
            for b in c["preferences"]:
                st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
else:
    st.info("ìƒë‹¨ URLì„ ìˆ˜ì§‘/ì •ì œí•˜ë©´ ì´ê³³ì— ìš”ì•½ì´ í‘œì‹œë©ë‹ˆë‹¤.")

# ============================================================
# 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ
# ============================================================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploads = st.file_uploader("PDF/TXT/MD/DOCX", type=["pdf","txt","md","docx"], accept_multiple_files=True)
resume_corpus = ""
if uploads:
    bodies=[]
    for f in uploads:
        txt = read_any_file(f)
        if txt: bodies.append(txt)
    resume_corpus = "\n\n".join(bodies)
    st.success(f"ë¬¸ì„œ {len(uploads)}ê°œ ë¡œë“œ ì™„ë£Œ (ì´ {len(resume_corpus)}ì)")
else:
    st.caption("ì´ë ¥ì„œë¥¼ ì˜¬ë¦¬ë©´ ì´í›„ ë‹¨ê³„(ìì†Œì„œ/ì§ˆë¬¸)ê°€ ë” ì •êµí•´ì§‘ë‹ˆë‹¤.")

# ============================================================
# 4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±
# ============================================================
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
cl_topic = st.text_input("íšŒì‚¬ì—ì„œ ìš”êµ¬í•œ ìì†Œì„œ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§€ì› ë™ê¸° / ì„±ì¥ ìŠ¤í† ë¦¬ / ë¬¸ì œ í•´ê²° ì‚¬ë¡€ ë“±")
if st.button("ìì†Œì„œ ìƒì„±", type="secondary"):
    if not c:
        st.warning("ë¨¼ì € 1~2ë‹¨ê³„ë¥¼ í†µí•´ íšŒì‚¬ ìš”ì•½ì„ ìƒì„±í•˜ì„¸ìš”.")
    else:
        sys = "ë„ˆëŠ” ì±„ìš© ë‹´ë‹¹ìì—ê²Œ ì–´í•„í•  ìì†Œì„œë¥¼ ì‘ì„±í•˜ëŠ” ë³´ì¡°ìë‹¤. í•œêµ­ì–´, 600~900ì."
        ctx = textwrap.dedent(f"""
        [íšŒì‚¬ ìš”ì•½]
        íšŒì‚¬ëª…: {c.get('company_name','')}
        ì§ë¬´: {c.get('role_title','')}
        ì£¼ìš”ì—…ë¬´: {', '.join(c.get('responsibilities',[])[:6])}
        ìê²©ìš”ê±´: {', '.join(c.get('qualifications',[])[:6])}
        ìš°ëŒ€ì‚¬í•­: {', '.join(c.get('preferences',[])[:6])}

        [í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½)]
        {snippet(resume_corpus, 2000)}
        """)
        goal = cl_topic.strip() if cl_topic.strip() else "ì§€ì› íšŒì‚¬/ì§ë¬´ì— íŠ¹í™”ëœ ìê¸°ì†Œê°œì„œ"
        prompt = f"ìœ„ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ '{goal}'ë¥¼ ì£¼ì œë¡œ, STAR ê´€ì ê³¼ ì§€í‘œë¥¼ í¬í•¨í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±."
        r = client.chat.completions.create(
            model=CHAT_MODEL, temperature=0.5,
            messages=[{"role":"system","content":sys},{"role":"user","content":ctx+"\n\n"+prompt}]
        )
        st.text_area("ìƒì„±ëœ ìì†Œì„œ", r.choices[0].message.content.strip(), height=280)

# ============================================================
# 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ
# ============================================================
st.header("5) ì§ˆë¬¸ ìƒì„± Â· ë‹µë³€ ì´ˆì•ˆ")
colq1, colq2 = st.columns([1,1])
if colq1.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
    if not c:
        st.warning("ë¨¼ì € íšŒì‚¬ ìš”ì•½ì„ ë§Œë“œì„¸ìš”.")
    else:
        ctx = textwrap.dedent(f"""
        íšŒì‚¬ëª…: {c.get('company_name','')}
        ì§ë¬´: {c.get('role_title','')}
        ì£¼ìš”ì—…ë¬´: {', '.join(c.get('responsibilities',[])[:6])}
        ìê²©ìš”ê±´: {', '.join(c.get('qualifications',[])[:6])}
        ìš°ëŒ€ì‚¬í•­: {', '.join(c.get('preferences',[])[:6])}
        í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½): {snippet(resume_corpus, 1200)}
        """)
        qs = llm_generate_questions(client, CHAT_MODEL, ctx, n=5)
        st.session_state.questions = qs
        st.session_state.current_question = qs[0] if qs else ""
        # íŒ”ë¡œì—… ì´ˆê¸°í™”
        st.session_state.followups = []
        st.session_state.selected_followup = ""
        st.session_state.followup_answer = ""
        st.session_state.last_followup_result = None

if colq2.button("ì§ˆë¬¸ ë¹„ìš°ê¸°", type="secondary"):
    st.session_state.questions = []
    st.session_state.current_question = ""
    st.session_state.answer_text = ""
    st.session_state.followups = []
    st.session_state.selected_followup = ""
    st.session_state.followup_answer = ""
    st.session_state.last_followup_result = None

if st.session_state.questions:
    st.markdown("**ìƒì„±ëœ ì§ˆë¬¸:**")
    for i, q in enumerate(st.session_state.questions, 1):
        st.markdown(f"{i}. {q}")

st.text_area("ë‹µë³€ ì…ë ¥\n(ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”: STAR ê¶Œì¥)", key="answer_text", height=160)

# ============================================================
# 6) ì±„ì  & ì½”ì¹­
# ============================================================
st.header("6) ì±„ì  & ì½”ì¹­")
# ì±„ì  ëŒ€ìƒ ì„ íƒ
if st.session_state.questions:
    st.session_state.current_question = st.selectbox("ì±„ì  ë°›ì„ ì§ˆë¬¸ ì„ íƒ",
                                                     st.session_state.questions,
                                                     index=0, key="current_question_select")
if st.button("ì±„ì  ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ì„ íƒí•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
    else:
        company_ctx = textwrap.dedent(f"""
        íšŒì‚¬ëª…: {c.get('company_name','')}
        ì§ë¬´: {c.get('role_title','')}
        ì£¼ìš”ì—…ë¬´: {', '.join(c.get('responsibilities',[])[:6])}
        ìê²©ìš”ê±´: {', '.join(c.get('qualifications',[])[:6])}
        ìš°ëŒ€ì‚¬í•­: {', '.join(c.get('preferences',[])[:6])}
        """)
        with st.spinner("ì±„ì /ì½”ì¹­ ì¤‘..."):
            res = llm_score_and_coach_strict(client, CHAT_MODEL, company_ctx,
                                             st.session_state.current_question,
                                             st.session_state.answer_text)
        # ê¸°ë¡
        st.session_state.history.append({
            "ts": pd.Timestamp.now(),
            "question": st.session_state.current_question,
            "answer": st.session_state.answer_text,
            "result": res,
        })
        # íŒ”ë¡œì—… ì œì•ˆ ìƒì„±
        sys_fu = "ë„ˆëŠ” ë©´ì ‘ê´€ì´ë‹¤. ì•„ë˜ ë‹µë³€ì˜ ë¹ˆí‹ˆì„ íŒŒê³ ë“œëŠ” íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ë¼. í•œêµ­ì–´, í•œ ì¤„ì”©."
        fu_prompt = f"""[ì§ˆë¬¸]
{st.session_state.current_question}

[ë‹µë³€]
{st.session_state.answer_text}

ì¡°ê±´: ì§€í‘œ/ìˆ˜ì¹˜/ê·¼ê±°/ë¦¬ìŠ¤í¬/ì˜ì‚¬ê²°ì • íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ìºë¬»ëŠ” ë°©í–¥ìœ¼ë¡œ.
"""
        rfu = client.chat.completions.create(
            model=CHAT_MODEL, temperature=0.8,
            messages=[{"role":"system","content":sys_fu},{"role":"user","content":fu_prompt}]
        )
        lines = [re.sub(r"^\s*\d+\)\s*","",x).strip() for x in rfu.choices[0].message.content.strip().splitlines() if len(x.strip())>3]
        st.session_state.followups = lines[:3]

# ê²°ê³¼ ì¶œë ¥
if st.session_state.history:
    last = st.session_state.history[-1]["result"]
    st.subheader("í”¼ë“œë°± ê²°ê³¼")
    mcol1, mcol2 = st.columns([1,3])
    with mcol1:
        st.metric("ì´ì (/100)", last.get("overall", 0))
    with mcol2:
        st.markdown("**ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ):**")
        for it in last.get("criteria", []):
            st.markdown(f"- **{it['name']}({it['score']}/20)**: {it.get('comment','')}")
        if last.get("revised"):
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€(STAR)**")
            st.write(last["revised"])

# ëˆ„ì  ë ˆì´ë”
st.subheader("ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")
def comp_frame(hist):
    rows=[]
    for h in hist:
        comp = h["result"].get("competencies")
        if comp and len(comp)==5:
            rows.append(comp)
    if not rows: return None
    return pd.DataFrame(rows, columns=["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"])
cdf = comp_frame(st.session_state.history)
if cdf is not None:
    avg = cdf.mean().tolist()
    if PLOTLY_OK:
        fig = go.Figure()
        labels = list(cdf.columns)
        fig.add_trace(go.Scatterpolar(r=avg+[avg[0]], theta=labels+[labels[0]], fill='toself', name="ì„¸ì…˜ í‰ê· "))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,20])), showlegend=True, height=420)
        st.plotly_chart(fig, use_container_width=True)
    st.dataframe(pd.concat([cdf, pd.DataFrame({"í•©ê³„": cdf.sum(axis=1)})], axis=1), use_container_width=True)
else:
    st.caption("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ============================================================
# 7) íŒ”ë¡œì—… ì§ˆë¬¸ & ë‹µë³€
# ============================================================
st.header("7) íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€")
if st.session_state.followups:
    st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
    for i, q in enumerate(st.session_state.followups, 1):
        st.markdown(f"{i}) {q}")

    # âœ… ìœ„ì ¯ë“¤ì€ keyë§Œ ì‚¬ìš©í•˜ê³ , ì„¸ì…˜ì— 'ëŒ€ì…'í•˜ì§€ ì•ŠìŒ (ì¶©ëŒ ë°©ì§€)
    st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ",
                 st.session_state.followups,
                 index=0,
                 key="selected_followup")

    st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")

    if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
        fu_q   = st.session_state.get("selected_followup", "")
        fu_ans = st.session_state.get("followup_answer", "")
        if not fu_q:
            st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
        elif not fu_ans.strip():
            st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
        else:
            company_ctx = textwrap.dedent(f"""
            íšŒì‚¬ëª…: {c.get('company_name','')}
            ì§ë¬´: {c.get('role_title','')}
            ì£¼ìš”ì—…ë¬´: {', '.join(c.get('responsibilities',[])[:6])}
            ìê²©ìš”ê±´: {', '.join(c.get('qualifications',[])[:6])}
            ìš°ëŒ€ì‚¬í•­: {', '.join(c.get('preferences',[])[:6])}
            """)
            with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘..."):
                res_fu = llm_score_and_coach_strict(client, CHAT_MODEL, company_ctx, fu_q, fu_ans)
            st.session_state.last_followup_result = res_fu

# ============================================================
# 8) íŒ”ë¡œì—… í”¼ë“œë°±
# ============================================================
st.header("8) íŒ”ë¡œì—… í”¼ë“œë°±")
fu = st.session_state.get("last_followup_result")
if fu:
    fc1, fc2 = st.columns([1,3])
    with fc1:
        st.metric("ì´ì (/100)", fu.get("overall", 0))
    with fc2:
        st.markdown("**ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ):**")
        for it in fu.get("criteria", []):
            st.markdown(f"- **{it['name']}({it['score']}/20)**: {it.get('comment','')}")
        if fu.get("revised"):
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€(STAR)**")
            st.write(fu["revised"])
else:
    st.caption("ìœ„ 7ë‹¨ê³„ì—ì„œ íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ê³  ë‹µë³€ì„ ì‘ì„±í•œ ë’¤ 'íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
