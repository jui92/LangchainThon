import os, re, io, json, time, shutil, urllib.parse, tempfile, traceback
from typing import Optional, Tuple, Dict, List
from concurrent.futures import ThreadPoolExecutor

import streamlit as st
import numpy as np
import pandas as pd
import requests
import html2text
from bs4 import BeautifulSoup

# OpenAI
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

with st.sidebar:
    st.subheader("ëª¨ë¸ / í¬ë¡¤ë§ ì˜µì…˜")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small","text-embedding-3-large"], index=0)
    SELENIUM_TIMEOUT = st.slider("Selenium ëŒ€ê¸°(ì´ˆ)", 6, 30, 14)
    FAST_MODE = st.toggle("Fast ëª¨ë“œ(ë¹ ë¥´ê²Œ)", value=True)

# -----------------------------------------------------------------------------
# html2text
# -----------------------------------------------------------------------------
def _get_html2text():
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    return conv
HTML2TEXT = _get_html2text()

def html_to_text(html_str: str) -> str:
    txt = HTML2TEXT.handle(html_str or "")
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return re.sub(r"\s+", " ", txt).strip()

# -----------------------------------------------------------------------------
# Utils
# -----------------------------------------------------------------------------
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def clean_text(s: str, max_len: int = 16000) -> str:
    if not s: return ""
    s = re.sub(r"\r", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s[:max_len] if len(s) > max_len else s

# -----------------------------------------------------------------------------
# Selenium driver
# -----------------------------------------------------------------------------
from selenium import webdriver
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

def _pick_chrome_binary() -> Optional[str]:
    cands = [
        os.getenv("CHROME_BIN"), os.getenv("GOOGLE_CHROME_BIN"),
        shutil.which("chromium"), shutil.which("chromium-browser"),
        shutil.which("google-chrome"),
        "/usr/bin/chromium","/usr/bin/chromium-browser",
        "/usr/bin/google-chrome","/usr/bin/google-chrome-stable",
    ]
    for p in cands:
        if p and os.path.exists(p): return p
    return None

def _build_chrome(headless: bool = True):
    opts = ChromeOptions()
    if headless: opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1440,2400")
    opts.add_argument("--lang=ko-KR")
    binpath = _pick_chrome_binary()
    if binpath: opts.binary_location = binpath
    # ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹œ Selenium Managerê°€ ìë™ìœ¼ë¡œ ì„¤ì¹˜/ê´€ë¦¬í•˜ë„ë¡ í•¨
    driver = webdriver.Chrome(options=opts)
    return driver

# -----------------------------------------------------------------------------
# Domain expand helpers (ì±„ìš© í¬í„¸ìš© í™•ì¥ ë²„íŠ¼ë“¤)
# -----------------------------------------------------------------------------
def _click_by_text_candidates(driver, texts: List[str], per=12):
    for t in texts:
        try:
            xp1 = f"//*[normalize-space(text())='{t}']"
            xp2 = f"//*[contains(normalize-space(text()), '{t}')]"
            for xp in (xp1, xp2):
                els = driver.find_elements(By.XPATH, xp)
                for el in els[:per]:
                    try:
                        driver.execute_script("arguments[0].click();", el)
                        time.sleep(0.12 if FAST_MODE else 0.25)
                    except Exception:
                        continue
        except Exception:
            continue

def _click_many_css(driver, selectors: List[str], per=12):
    for sel in selectors:
        try:
            els = driver.find_elements(By.CSS_SELECTOR, sel)
            for el in els[:per]:
                try:
                    driver.execute_script("arguments[0].click();", el)
                    time.sleep(0.1 if FAST_MODE else 0.2)
                except Exception:
                    continue
        except Exception:
            continue

def _expand_wanted(driver):
    sel = [
        "[data-qa='btn-read-more']","[data-qa='job-header__more']",
        "button[aria-expanded='false']","[role='button'][class*='More']",
        "div[aria-expanded='false']",
    ]
    _click_many_css(driver, sel, per=(8 if FAST_MODE else 12))
    _click_by_text_candidates(driver, [
        "ë”ë³´ê¸°","ì „ì²´ë³´ê¸°","ìì„¸íˆ","ìƒì„¸ë³´ê¸°","ëª¨ë‘ ë³´ê¸°",
        "ì£¼ìš”ì—…ë¬´","ìê²©ìš”ê±´","ìš°ëŒ€ì‚¬í•­","ê¸°ì—…/íŒ€ ì†Œê°œ",
        "ë‚˜ì¤‘ì— í•˜ê¸°","ë‹«ê¸°","í™•ì¸"
    ], per=(6 if FAST_MODE else 12))

def _expand_saramin(driver):
    sel = [".btn_more",".btnMore",".btn-detail",".btn_toggle",
           "[aria-expanded='false']","[role='button']","button[class*='more'], a[class*='more']"]
    _click_many_css(driver, sel, per=(6 if FAST_MODE else 12))
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ì •ë³´"], per=(6 if FAST_MODE else 12))

def _expand_jobkorea(driver):
    sel = [".btnFold",".btnToggleRead",".btn_more",
           "[aria-expanded='false']","[role='button']","button[class*='More'], a[class*='More']"]
    _click_many_css(driver, sel, per=(6 if FAST_MODE else 12))
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ë³´ê¸°"], per=(6 if FAST_MODE else 12))

# -----------------------------------------------------------------------------
# Wanted __NEXT_DATA__ â†’ text
# -----------------------------------------------------------------------------
def extract_wanted_from_next_html(html: str) -> str:
    try:
        soup = BeautifulSoup(html or "", "html.parser")
        tag = soup.select_one("script#__NEXT_DATA__")
        if not tag: return ""
        raw = (tag.string or tag.text or "").strip()
        data = json.loads(raw)
    except Exception:
        return ""
    key_whitelist = [
        "job","position","title","desc","description",
        "responsibilit","duty","role","skill","stack",
        "require","qualification","prefer","plus","nice"
    ]
    def _safe(x): return re.sub(r"\s+"," ", (x or "")).strip()
    def _walk(d, out):
        if isinstance(d, dict):
            for k, v in d.items():
                if any(t in str(k).lower() for t in key_whitelist):
                    if isinstance(v, str): out.append(v)
                    elif isinstance(v, list):
                        for it in v:
                            if isinstance(it, str): out.append(it)
                            elif isinstance(it, dict):
                                for _, subv in it.items():
                                    if isinstance(subv, str): out.append(subv)
                    elif isinstance(v, dict):
                        for _, subv in v.items():
                            if isinstance(subv, str): out.append(subv)
                _walk(v, out)
        elif isinstance(d, list):
            for it in d: _walk(it, out)
    bucket=[]; _walk(data, bucket)
    seen=set(); lines=[]
    for t in bucket:
        s=_safe(t)
        if len(s)>2 and s not in seen:
            seen.add(s); lines.append(s)
    return "\n".join(lines[:900])

# -----------------------------------------------------------------------------
# Selenium fetch (DOM + NEXT_DATA)
# -----------------------------------------------------------------------------
def selenium_get_html(url: str, timeout: int = 14) -> str:
    driver = _build_chrome(headless=True)
    try:
        driver.set_page_load_timeout(timeout)
        driver.get(url)
        try:
            WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, "//*")))
        except TimeoutException:
            pass

        host = urllib.parse.urlsplit(url).netloc.lower()
        _click_by_text_candidates(driver, ["ë”ë³´ê¸°","ìƒì„¸ë³´ê¸°","ìì„¸íˆ ë³´ê¸°","ì „ì²´ë³´ê¸°","Read more","More"],
                                  per=(6 if FAST_MODE else 10))
        _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","Requirements","Responsibilities","Preferred"],
                                  per=(6 if FAST_MODE else 10))

        if "wanted.co.kr" in host: _expand_wanted(driver)
        if "saramin" in host:     _expand_saramin(driver)
        if "jobkorea" in host:    _expand_jobkorea(driver)

        loops = 5 if FAST_MODE else 8
        for _ in range(loops):
            try:
                # ìŠ¤í¬ë¡¤ì„ í†µí•´ ë™ì  ë¡œë”©ë˜ëŠ” ì½˜í…ì¸  ë¡œë“œ ì‹œë„
                driver.execute_script("window.scrollBy(0, 1200);"); time.sleep(0.12 if FAST_MODE else 0.25)
            except Exception:
                break

        html = driver.page_source or ""
        if "wanted.co.kr" in host:
            try:
                txt_next = extract_wanted_from_next_html(html)
                if txt_next:
                    html += "\n<div id='__WANTED_NEXT_EXTRACT__'>" + \
                            "".join([f"<p>{line}</p>" for line in txt_next.split("\n")]) + "</div>"
            except Exception:
                pass
        return html
    finally:
        try: driver.quit()
        except Exception: pass

# -----------------------------------------------------------------------------
# MODIFIED: Robust fetch function (requests primary, selenium fallback)
# -----------------------------------------------------------------------------
def fetch_all_text_selenium(url: str, timeout: int = 14) -> Tuple[str, Dict, Optional[str]]:
    url_n = normalize_url(url)
    if not url_n: return "", {"error":"invalid_url"}, None
    
    # --- 1. Requests (Fast/Static) Attempt ---
    # ì¼ë°˜ì ì¸ ê¸°ì—… í™ˆí˜ì´ì§€ì˜ ê²½ìš° requestsê°€ ë¹ ë¥´ê³  ì•ˆì •ì ì…ë‹ˆë‹¤.
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì§§ì€ íƒ€ì„ì•„ì›ƒ ì„¤ì • (5ì´ˆ)
        response = requests.get(url_n, headers=headers, timeout=5) 
        response.raise_for_status() 
        html_req = response.text

        soup_req = BeautifulSoup(html_req, "html.parser")
        # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼, ë„¤ë¹„ê²Œì´ì…˜ ë“± ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±° (ì •ì  í˜ì´ì§€ í¬ë¡¤ë§ í’ˆì§ˆ í–¥ìƒ)
        for tag in soup_req(["script", "style", "header", "footer", "nav", ".menu", "#menu", "[class*='sidebar']"]):
            tag.decompose()
        
        # main, article ë“± ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ì„ ì°¾ì•„ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        main_content_candidates = soup_req.select("main, .main, #main, article, .content, #content, [role='main'], body")
        
        text_to_convert = html_req
        if main_content_candidates:
            # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ ì½˜í…ì¸  í›„ë³´ ì„ íƒ
            best_candidate = max(main_content_candidates, key=lambda tag: len(tag.get_text()))
            if best_candidate:
                text_to_convert = best_candidate.prettify()

        txt_req = html_to_text(text_to_convert)

        # í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ 300ì ì´ìƒì´ë©´ ìœ ì˜ë¯¸í•œ ì •ë³´ë¡œ íŒë‹¨í•˜ê³  ì¦‰ì‹œ ë°˜í™˜ (requests ì„±ê³µ)
        if len(txt_req) > 300: 
            return txt_req, {"source":"requests","len":len(txt_req),"url_final":url_n}, html_req

    except requests.exceptions.RequestException:
        # requests ì‹¤íŒ¨ ì‹œ Seleniumìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í´ë°±
        pass
    except Exception:
        # ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ Seleniumìœ¼ë¡œ í´ë°±
        pass

    # --- 2. Selenium (Slow/Dynamic) Fallback (ê¸°ì¡´ ë¡œì§) ---
    # requestsê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜, ë™ì  ë¡œë”©ì´ í•„ìš”í•œ ì±„ìš© ê³µê³  í˜ì´ì§€ì¼ ê²½ìš° Selenium ì‹œë„
    try:
        html_sel = selenium_get_html(url_n, timeout=timeout)
    except Exception as e:
        # Selenium ë¡œë“œ ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë§Œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        st.error(f"Selenium ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.code("".join(traceback.format_exc()))
        return "", {"source":"selenium_error","len":0,"url_final":url_n}, None

    if not html_sel or len(html_sel) < 200:
        return "", {"source":"selenium_failed","len":0,"url_final":url_n}, None

    txt_sel = html_to_text(html_sel)
    return txt_sel, {"source":"selenium","len":len(txt_sel),"url_final":url_n}, html_sel

# -----------------------------------------------------------------------------
# Meta & rule-based sections (ONLY 3 buckets)
# -----------------------------------------------------------------------------
def extract_company_meta_from_html(html: Optional[str]) -> Dict[str, str]:
    meta = {"company_name": "", "company_intro": "", "job_title": ""}
    if not html: return meta
    try:
        soup = BeautifulSoup(html, "html.parser")
        cand=[]
        og = soup.find("meta", {"property":"og:site_name"})
        if og and og.get("content"): cand.append(og["content"])
        app = soup.find("meta", {"name":"application-name"})
        if app and app.get("content"): cand.append(app["content"])
        if soup.title and soup.title.string: cand.append(soup.title.string)
        cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
        cand = [c for c in cand if 2 <= len(c) <= 40]
        meta["company_name"] = cand[0] if cand else ""
        md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
        if md and md.get("content"):
            meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
        jt=""
        ogt = soup.find("meta", {"property":"og:title"})
        if ogt and ogt.get("content"): jt = ogt["content"]
        if not jt:
            h1 = soup.find("h1")
            if h1 and h1.get_text(): jt = h1.get_text(strip=True)
        if not jt:
            h2 = soup.find("h2")
            if h2 and h2.get_text(): jt = h2.get_text(strip=True)
        meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    except Exception:
        pass
    return meta

def rule_based_sections(raw_text: str) -> dict:
    txt = clean_text(raw_text, 16000)
    lines = [re.sub(r"\s+"," ", l).strip(" -â€¢Â·â–¶â–ªï¸") for l in txt.split("\n") if l.strip()]
    
    # ì •ê·œí‘œí˜„ì‹ ì •ì˜
    hdr_resp = re.compile(r"(ì£¼ìš”\s*ì—…ë¬´|ë‹´ë‹¹\s*ì—…ë¬´|Role|Responsibilities?)", re.I)
    hdr_qual = re.compile(r"(ìê²©\s*ìš”ê±´|ì§€ì›\s*ìê²©|Requirements?|Qualifications?)", re.I)
    hdr_pref = re.compile(r"(ìš°ëŒ€\s*ì‚¬í•­|ìš°ëŒ€|ì„ í˜¸|Preferred|Nice\s*to\s*have|Plus)", re.I)
    kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
    
    out = {"responsibilities": [], "qualifications": [], "preferences": []}
    bucket=None
    
    def push(line,b):
        if line and len(line)>1 and line not in out[b]:
            out[b].append(line[:180])

    # ë¼ì¸ì„ ëŒë©´ì„œ ì„¹ì…˜ì„ ë¶„ë¥˜
    for l in lines:
        if hdr_resp.search(l):
            bucket="responsibilities"; continue
        if hdr_qual.search(l):
            bucket="qualifications"; continue
        if hdr_pref.search(l):
            bucket="preferences"; continue
        
        # í—¤ë”ê°€ ì—†ëŠ” ê²½ìš°: í‚¤ì›Œë“œë¡œ ë¶„ë¥˜ ì‹œë„
        if bucket is None:
            low = l.lower()
            if hdr_pref.search(l):
                bucket = "preferences"
            elif any(k in low for k in ["java","python","spring","kotlin","react","next","kafka","sql","ml","cloud","aws","gcp"]):
                bucket = "responsibilities"
            else:
                continue

        push(l,bucket)

    # ìê²©ìš”ê±´ì— ìˆì§€ë§Œ ìš°ëŒ€ì‚¬í•­ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸êµ¬ëŠ” ìš°ëŒ€ì‚¬í•­ìœ¼ë¡œ ì´ë™
    remain=[]
    for q in out["qualifications"]:
        (out["preferences"] if kw_pref.search(q) else remain).append(q)
    out["qualifications"]=remain

    # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
    for k in out:
        seen=set(); clean=[]
        for s in out[k]:
            s=re.sub(r"\s+"," ", s).strip(" -â€¢Â·â–¶â–ªï¸").strip()
            if s and s not in seen:
                seen.add(s); clean.append(s)
        out[k]=clean[:14] # ê° ì„¹ì…˜ë³„ ìµœëŒ€ 14ê°œ í•­ëª©

    return out

# -----------------------------------------------------------------------------
# LLM structure / Q&A / scoring
# -----------------------------------------------------------------------------
PROMPT_SYSTEM_STRUCT = ("ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼.")
PROMPT_FORMAT_STRUCT = """
--- JSON ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ê·¸ëŒ€ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”) ---
{
  "company_name": "íšŒì‚¬ëª…",
  "job_title": "ì§ë¬´/í¬ì§€ì…˜ ëª…",
  "responsibilities": ["í•µì‹¬ ì£¼ìš” ì—…ë¬´ 1", "í•µì‹¬ ì£¼ìš” ì—…ë¬´ 2", ...],
  "qualifications": ["í•„ìˆ˜ ìê²© ìš”ê±´ 1", "í•„ìˆ˜ ìê²© ìš”ê±´ 2", ...],
  "preferences": ["ìš°ëŒ€ ì‚¬í•­ 1", "ìš°ëŒ€ ì‚¬í•­ 2", ...],
  "company_intro": "íšŒì‚¬ ì†Œê°œ (100ì ë‚´ë¡œ ê°„ê²°í•˜ê²Œ)"
}
---
"""
def llm_structurize(raw_text: str, meta_hint: Dict[str, str], model: str) -> Dict:
    ctx = clean_text(raw_text, 14000)
    user_msg = {"role": "user", "content": (
        "ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
        f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name', '')}, ì§ë¬´ í›„ë³´: {meta_hint.get('job_title', '')}\n"
        f"[íšŒì‚¬ ì†Œê°œ íŒíŠ¸]: {meta_hint.get('company_intro', '')}\n\n"
        f"[ì±„ìš© ê³µê³  ì›ë¬¸]\n{ctx}"
    )}
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": PROMPT_SYSTEM_STRUCT + PROMPT_FORMAT_STRUCT},
                user_msg
            ],
            response_format={"type": "json_object"},
            temperature=0.0
        )
        data = json.loads(res.choices[0].message.content)
        return data
    except Exception as e:
        st.warning(f"êµ¬ì¡°í™” ì‹¤íŒ¨ (LLM ì˜¤ë¥˜): {e}")
        return {}

def structurize_and_refine(raw_text: str, meta_hint: Dict[str, str], model: str) -> Dict:
    # 1. Rule-based extraction (Fast fallback)
    rule_sections = rule_based_sections(raw_text)
    
    # 2. LLM structure (Accurate)
    llm_data = llm_structurize(raw_text, meta_hint, model)

    # 3. Merge & Refine
    final_data = {
        "company_name": (llm_data.get("company_name") or meta_hint.get("company_name", "")).strip()[:80],
        "job_title": (llm_data.get("job_title") or meta_hint.get("job_title", "")).strip()[:120],
        "company_intro": (llm_data.get("company_intro") or meta_hint.get("company_intro", "")).strip()[:500],
    }
    
    # LLM ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ Rule-based ê²°ê³¼ ì‚¬ìš©
    def _merge_list(llm_list, rule_list):
        if llm_list and isinstance(llm_list, list) and len("".join(llm_list)) > 20:
            return llm_list[:20]
        return rule_list[:20]

    final_data["responsibilities"] = _merge_list(llm_data.get("responsibilities"), rule_sections["responsibilities"])
    final_data["qualifications"] = _merge_list(llm_data.get("qualifications"), rule_sections["qualifications"])
    final_data["preferences"] = _merge_list(llm_data.get("preferences"), rule_sections["preferences"])

    # Final validation
    if not final_data.get("company_name"): final_data["company_name"] = "íšŒì‚¬ëª…_ë¯¸í™•ì¸"
    if not final_data.get("job_title"): final_data["job_title"] = "ì§ë¬´ëª…_ë¯¸í™•ì¸"
    if not final_data.get("company_intro"): final_data["company_intro"] = "íšŒì‚¬_ì†Œê°œ_ë¯¸í™•ì¸"
    if not final_data.get("responsibilities"): final_data["responsibilities"] = ["ì£¼ìš” ì—…ë¬´ ë¯¸í™•ì¸"]
    
    return final_data

# -----------------------------------------------------------------------------
# Document Chunking / Embedding
# -----------------------------------------------------------------------------
def chunk_text(text: str, max_len=1800, min_len=100) -> List[str]:
    # ê°„ë‹¨í•œ ë‹¨ë½ ê¸°ë°˜ ì²­í‚¹
    if not text: return []
    text = clean_text(text, 65536)
    chunks = []
    current_chunk = ""
    for line in text.split("\n\n"):
        if len(current_chunk) + len(line) + 2 < max_len:
            current_chunk += line + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = line + "\n\n"
    if current_chunk:
        chunks.append(current_chunk.strip())
        
    # ë„ˆë¬´ ì§§ì€ ì²­í¬ ë³‘í•© ì‹œë„
    final_chunks = []
    temp_chunk = ""
    for chunk in chunks:
        if len(temp_chunk) + len(chunk) + 2 < max_len:
            temp_chunk += chunk + "\n\n"
        else:
            if temp_chunk:
                final_chunks.append(temp_chunk.strip())
            temp_chunk = chunk + "\n\n"
    if temp_chunk:
        final_chunks.append(temp_chunk.strip())

    return [c for c in final_chunks if len(c) > min_len]

def get_text_embedding(text_list: List[str], model: str) -> List[List[float]]:
    try:
        text_list = [t.replace("\n", " ") for t in text_list]
        response = client.embeddings.create(
            input=text_list,
            model=model
        )
        return [data.embedding for data in response.data]
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return [[]] * len(text_list)

# -----------------------------------------------------------------------------
# RAG (Retrieval)
# -----------------------------------------------------------------------------
def _find_best_chunks_by_embed(
    query_embed: List[float], 
    doc_embeds: List[List[float]], 
    doc_chunks: List[str], 
    top_k: int = 4
) -> List[str]:
    if not query_embed or not doc_embeds: return []
    query_vec = np.array(query_embed)
    doc_vecs = np.array(doc_embeds)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë²¡í„° ì •ê·œí™” ê°€ì •)
    # np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
    # ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ ë‹¨ìˆœíˆ ë‚´ì (dot product)ì´ ìœ ì‚¬ë„ì…ë‹ˆë‹¤.
    similarities = np.dot(doc_vecs, query_vec)
    
    # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œë¡œ ì¸ë±ìŠ¤ ì •ë ¬
    sorted_indices = np.argsort(similarities)[::-1]
    
    # Top-K ì²­í¬ ì„ íƒ
    selected_chunks = []
    for i in sorted_indices:
        if len(selected_chunks) >= top_k: break
        if similarities[i] > 0.6: # ìµœì†Œ ìœ ì‚¬ë„ ì»·ì˜¤í”„
            selected_chunks.append(doc_chunks[i])
            
    return selected_chunks[:top_k]

def retrieve_context(
    query: str, 
    resume_chunks: List[str], 
    resume_embeds: List[List[float]], 
    job_desc_chunks: List[str], 
    job_desc_embeds: List[List[float]], 
    embed_model: str
) -> Tuple[str, str]:
    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embed = get_text_embedding([query], embed_model)[0]
    if not query_embed:
        return "ì´ë ¥ì„œ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", "ì±„ìš© ê³µê³  ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
    
    # ì´ë ¥ì„œì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
    resume_context_list = _find_best_chunks_by_embed(query_embed, resume_embeds, resume_chunks, top_k=2)
    resume_context = "--- ì´ë ¥ì„œ ê´€ë ¨ ë‚´ìš© ---\n" + "\n\n".join(resume_context_list)
    
    # ì±„ìš© ê³µê³ ì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰ (RAG-Job-Descriptionì€ í•„ìš”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ, í¬í•¨)
    job_context_list = _find_best_chunks_by_embed(query_embed, job_desc_embeds, job_desc_chunks, top_k=2)
    job_context = "--- ì±„ìš© ê³µê³  ê´€ë ¨ ë‚´ìš© ---\n" + "\n\n".join(job_context_list)
    
    return resume_context, job_context

# -----------------------------------------------------------------------------
# LLM Generation
# -----------------------------------------------------------------------------

PROMPT_SYSTEM_JD_CV = (
    "ë„ˆëŠ” ìµœê³ ì˜ ì»¤ë¦¬ì–´ ì½”ì¹˜ì´ì ìê¸°ì†Œê°œì„œ ì‘ì„± ì „ë¬¸ê°€ì´ë‹¤. "
    "ì‚¬ìš©ìê°€ ì œê³µí•œ ì±„ìš© ê³µê³  ì •ë³´ì™€ ì´ë ¥ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ íšŒì‚¬ì™€ ì§ë¬´ì— ì™„ë²½í•˜ê²Œ ë§ì¶°ì§„ ì§€ì› ë™ê¸°ì™€ ì—­ëŸ‰ì„ ê°•ì¡°í•˜ëŠ” ìê¸°ì†Œê°œì„œ ì´ˆì•ˆì„ ì‘ì„±í•´ì¤˜ì•¼ í•œë‹¤. "
    "ê²°ê³¼ë¬¼ì€ **ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê¹”ë”í•œ í•œêµ­ì–´ ì—ì„¸ì´ í˜•íƒœ**ì—¬ì•¼ í•˜ë©°, **êµ¬ì¡°í™”ëœ ì±„ìš© ê³µê³ ì˜ ê° í•µì‹¬ ìš”ì†Œ(ì£¼ìš” ì—…ë¬´, ìê²© ìš”ê±´, ìš°ëŒ€ ì‚¬í•­)ë¥¼ ìì‹ ì˜ ê²½í—˜ìœ¼ë¡œ ì—°ê²°**í•˜ì—¬ ì„¤ë“ë ¥ì„ ë†’ì—¬ì•¼ í•œë‹¤."
)
PROMPT_SYSTEM_INTERVIEW = (
    "ë„ˆëŠ” ìµœê³ ì˜ ë©´ì ‘ê´€ì´ì ì»¤ë¦¬ì–´ ì½”ì¹˜ì´ë‹¤. "
    "ì œì‹œëœ ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´ì™€ ì´ë ¥ì„œ(í˜¹ì€ ìê¸°ì†Œê°œì„œ) ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ **ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±**í•˜ê³ , **ë‹µë³€ì— ëŒ€í•œ ì „ë¬¸ì ì¸ í”¼ë“œë°±ì„ ì œê³µ**í•´ì•¼ í•œë‹¤."
    "**ì§ˆë¬¸ì€ ì±„ìš© ê³µê³ ì™€ ì´ë ¥ì„œ ë‚´ìš©ì„ ìœµí•©**í•˜ì—¬ ì§€ì›ìì˜ **í•µì‹¬ ì—­ëŸ‰ê³¼ ì§ë¬´ ì í•©ì„±ì„ ê¹Šì´ ìˆê²Œ ê²€ì¦**í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¬ì¸µì ì´ì–´ì•¼ í•œë‹¤."
)

# 1. ìê¸°ì†Œê°œì„œ ìƒì„±
def llm_generate_cover_letter(
    job_struct: Dict, resume_text: str, model: str
) -> str:
    jd = json.dumps(job_struct, ensure_ascii=False, indent=2)
    
    user_msg = {"role": "user", "content": (
        "ë‹¤ìŒ ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´ì™€ ì´ë ¥ì„œ ì›ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§€ì› ë™ê¸° ë° ì—­ëŸ‰ ì¤‘ì‹¬ì˜ ìê¸°ì†Œê°œì„œ(ì—ì„¸ì´)ë¥¼ ì‘ì„±í•´ì¤˜.\n\n"
        "[ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´]\n" + jd + "\n\n"
        "[ì´ë ¥ì„œ ì›ë¬¸]\n" + resume_text
    )}
    
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": PROMPT_SYSTEM_JD_CV},
                user_msg
            ],
            temperature=0.6 # ì°½ì˜ì„±ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì•½ê°„ ë†’ì„
        )
        return res.choices[0].message.content
    except Exception as e:
        return f"ìê¸°ì†Œê°œì„œ ìƒì„± ì‹¤íŒ¨: {e}"

# 2. ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
PROMPT_FORMAT_QUESTION = """
--- JSON ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ê·¸ëŒ€ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”) ---
{
  "questions": [
    {
      "type": "jd_based",
      "question": "ì§€ì›í•œ ì§ë¬´ì˜ ì£¼ìš” ì—…ë¬´(ì˜ˆ: ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•)ì™€ ê´€ë ¨í•˜ì—¬ ë³¸ì¸ì˜ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
      "relevance": "ì£¼ìš” ì—…ë¬´/ìê²© ìš”ê±´/ìš°ëŒ€ ì‚¬í•­ ì¤‘ ê°€ì¥ ê´€ë ¨ ìˆëŠ” í•µì‹¬ ìš”ì†Œ"
    },
    {
      "type": "resume_based",
      "question": "ì´ë ¥ì„œì— ì–¸ê¸‰ëœ 'í”„ë¡œì íŠ¸ X'ì—ì„œ ë°œìƒí–ˆë˜ ê°€ì¥ í° ê¸°ìˆ ì  ì–´ë ¤ì›€ì€ ë¬´ì—‡ì´ì—ˆê³ , ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì‹­ì‹œì˜¤.",
      "relevance": "ì´ë ¥ì„œì˜ íŠ¹ì • ê²½í—˜/ê¸°ìˆ "
    },
    // ìµœì†Œ 5ê°œ ì´ìƒì˜ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
  ],
  "followup_questions": ["ì§ˆë¬¸1ì— ëŒ€í•œ íŒ”ë¡œì—… ì§ˆë¬¸", "ì§ˆë¬¸2ì— ëŒ€í•œ íŒ”ë¡œì—… ì§ˆë¬¸", ...],
}
---
"""
def llm_generate_questions(
    job_struct: Dict, resume_text: str, model: str
) -> Dict:
    jd = json.dumps(job_struct, ensure_ascii=False, indent=2)
    
    user_msg = {"role": "user", "content": (
        "ë‹¤ìŒ ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´ì™€ ì´ë ¥ì„œ ì›ë¬¸ì„ ì°¸ê³ í•˜ì—¬, ë©´ì ‘ ì§ˆë¬¸ (ìµœì†Œ 5ê°œ) ë° ê° ì§ˆë¬¸ì— ëŒ€í•œ íŒ”ë¡œì—… ì§ˆë¬¸ (ìµœì†Œ 3ê°œ)ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì¤˜.\n\n"
        "[ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´]\n" + jd + "\n\n"
        "[ì´ë ¥ì„œ ì›ë¬¸]\n" + resume_text
    )}
    
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": PROMPT_SYSTEM_INTERVIEW + PROMPT_FORMAT_QUESTION},
                user_msg
            ],
            response_format={"type": "json_object"},
            temperature=0.2
        )
        return json.loads(res.choices[0].message.content)
    except Exception as e:
        st.warning(f"ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"questions": [], "followup_questions": []}

# 3. ë©´ì ‘ ë‹µë³€ ì±„ì  ë° í”¼ë“œë°±
PROMPT_FORMAT_SCORE = """
--- JSON ì‘ë‹µ í˜•ì‹ (ì´ í˜•ì‹ ê·¸ëŒ€ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”) ---
{
  "overall_score": 85, // 0~100ì  ì‚¬ì´ì˜ ì ìˆ˜
  "feedback_kr": "ë‹µë³€ì— ëŒ€í•œ êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ í•œêµ­ì–´ í”¼ë“œë°±",
  "next_followup": ["ì§ˆë¬¸1ì— ëŒ€í•œ ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸", "ì§ˆë¬¸2ì— ëŒ€í•œ ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸"],
  "rag_used": {
    "resume": "ë‹µë³€ í‰ê°€ì— ì‚¬ìš©ëœ ì´ë ¥ì„œì˜ ì£¼ìš” ì¸ìš©êµ¬",
    "job_desc": "ë‹µë³€ í‰ê°€ì— ì‚¬ìš©ëœ ì±„ìš© ê³µê³ ì˜ ì£¼ìš” ì¸ìš©êµ¬"
  }
}
---
"""
def llm_score_and_coach_strict(
    job_struct: Dict,
    question: str,
    answer: str,
    model: str,
    resume_chunks: List[str],
    resume_embeds: List[List[float]],
    job_desc_chunks: List[str], # RAGì— ì‚¬ìš©ë  Job Description ì²­í¬
    job_desc_embeds: List[List[float]],
    embed_model: str = EMBED_MODEL
) -> Dict:
    
    # RAGë¥¼ í†µí•´ ê´€ë ¨ ì´ë ¥ì„œ ë‚´ìš©ê³¼ JD ë‚´ìš©ì„ ê°€ì ¸ì˜´
    res_ctx, jd_ctx = retrieve_context(
        f"{question}ì— ëŒ€í•œ ë‹µë³€: {answer}", 
        resume_chunks, resume_embeds, job_desc_chunks, job_desc_embeds, embed_model
    )

    jd = json.dumps(job_struct, ensure_ascii=False, indent=2)
    
    user_msg = {"role": "user", "content": (
        "ì•„ë˜ ì±„ìš© ê³µê³ , ì§ˆë¬¸, ë‹µë³€, ì´ë ¥ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ 100ì  ë§Œì ìœ¼ë¡œ ì±„ì í•˜ê³ , ìƒì„¸í•œ í”¼ë“œë°±ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì¤˜.\n"
        "í”¼ë“œë°±ì€ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íŒŒì•…í•˜ê³ , ì§ë¬´ ì í•©ì„±ê³¼ ê¹Šì´ ìˆëŠ” ì „ë¬¸ì„±ì„ ë³´ì—¬ì¤¬ëŠ”ì§€ì— ì´ˆì ì„ ë§ì¶°.\n\n"
        f"[ì±„ìš© ê³µê³  êµ¬ì¡°í™” ì •ë³´]\n{jd}\n\n"
        f"[ì§ˆë¬¸]\n{question}\n\n"
        f"[ë‹µë³€]\n{answer}\n\n"
        f"[RAG ì»¨í…ìŠ¤íŠ¸]\n{res_ctx}\n\n{jd_ctx}"
    )}
    
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": PROMPT_SYSTEM_INTERVIEW + "\n" + PROMPT_FORMAT_SCORE},
                user_msg
            ],
            response_format={"type": "json_object"},
            temperature=0.0
        )
        data = json.loads(res.choices[0].message.content)
        # ì ìˆ˜ì™€ í”¼ë“œë°± ìœ íš¨ì„± ê²€ì‚¬ ë° ê¸°ë³¸ê°’ ì„¤ì •
        data["overall_score"] = int(data.get("overall_score", 0))
        data["feedback_kr"] = data.get("feedback_kr", "í”¼ë“œë°±ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        data["next_followup"] = data.get("next_followup", [])
        return data
    except Exception as e:
        st.warning(f"ì±„ì  ë° í”¼ë“œë°± ì‹¤íŒ¨: {e}")
        return {"overall_score": 0, "feedback_kr": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì±„ì  ë° í”¼ë“œë°±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "next_followup": [], "rag_used": {}}

# -----------------------------------------------------------------------------
# Streamlit App
# -----------------------------------------------------------------------------
# ... (Streamlit UI/Logic - The full logic is not provided, but the parts that were)

# st.session_state ì´ˆê¸°í™”
if "clean_struct" not in st.session_state: st.session_state.clean_struct = {}
if "raw_text" not in st.session_state: st.session_state.raw_text = ""
if "resume_text" not in st.session_state: st.session_state.resume_text = ""
if "resume_chunks" not in st.session_state: st.session_state.resume_chunks = []
if "resume_embeds" not in st.session_state: st.session_state.resume_embeds = []
if "job_desc_chunks" not in st.session_state: st.session_state.job_desc_chunks = []
if "job_desc_embeds" not in st.session_state: st.session_state.job_desc_embeds = []
if "interview_questions" not in st.session_state: st.session_state.interview_questions = []
if "followups" not in st.session_state: st.session_state.followups = []

st.title("ì·¨ì—… ë„ìš°ë¯¸ ë´‡ ğŸ¤–")
st.markdown("ì±„ìš© ê³µê³  URLê³¼ ê¸°ì—… í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ë©´, ë§ì¶¤í˜• ìì†Œì„œ ìƒì„± ë° ëª¨ì˜ ë©´ì ‘ì„ ì œê³µí•©ë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# Input URLs and Fetching
# -----------------------------------------------------------------------------
job_url = st.text_input("**1. ì±„ìš© ê³µê³  URL**", key="job_url")
company_url = st.text_input("**2. ê¸°ì—… í™ˆí˜ì´ì§€ URL** (ì •ë³´ ë³´ê°•ìš©)", key="company_url")

def fetch_and_process(job_u, company_u):
    all_raw_text = ""
    job_html, company_html = None, None
    meta_hint = {}
    
    st.subheader("í¬ë¡¤ë§ ê²°ê³¼")
    
    # 1. ì±„ìš© ê³µê³  í¬ë¡¤ë§
    with st.spinner(f"ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì¤‘ ({job_u})..."):
        # ìˆ˜ì •ëœ fetch_all_text_selenium í•¨ìˆ˜ ì‚¬ìš©
        job_txt, job_meta, job_html = fetch_all_text_selenium(job_u, SELENIUM_TIMEOUT)
        if job_txt:
            all_raw_text += job_txt
            meta_hint.update(extract_company_meta_from_html(job_html))
            st.success(f"âœ… ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì„±ê³µ: {len(job_txt)}ì")
        else:
            st.warning("âš ï¸ ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±")
            
    # 2. ê¸°ì—… í™ˆí˜ì´ì§€ í¬ë¡¤ë§ (ë³´ê°•ìš©)
    if company_u and job_txt: # ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì„±ê³µ ì‹œì—ë§Œ ì‹œë„
        with st.spinner(f"ê¸°ì—… í™ˆí˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ({company_u})..."):
            # ìˆ˜ì •ëœ fetch_all_text_selenium í•¨ìˆ˜ ì‚¬ìš© (requests ìš°ì„  ì ìš©)
            company_txt, company_meta, company_html = fetch_all_text_selenium(company_u, SELENIUM_TIMEOUT)
            if company_txt and len(company_txt)>len(job_txt)*0.1: # ìœ ì˜ë¯¸í•œ ê¸¸ì´ì¸ ê²½ìš°ë§Œ
                all_raw_text += "\n\n" + company_txt
                # ê¸°ì—… ë©”íƒ€ ì •ë³´ ë³´ê°•
                company_meta_data = extract_company_meta_from_html(company_html)
                if not meta_hint.get("company_name") and company_meta_data.get("company_name"):
                     meta_hint["company_name"] = company_meta_data["company_name"]
                if not meta_hint.get("company_intro") and company_meta_data.get("company_intro"):
                     meta_hint["company_intro"] = company_meta_data["company_intro"]
                st.success(f"âœ… ê¸°ì—… í™ˆí˜ì´ì§€ í¬ë¡¤ë§ ì„±ê³µ: {len(company_txt)}ì (ì •ë³´ ë³´ê°• ì™„ë£Œ)")
            else:
                 st.info("â„¹ï¸ ê¸°ì—… í™ˆí˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨ ë˜ëŠ” ë³´ê°•í•  ë‚´ìš© ë¶€ì¡±")

    st.session_state.raw_text = all_raw_text
    
    if not all_raw_text.strip():
        st.error("âŒ í¬ë¡¤ë§ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. URLì„ ë‹¤ì‹œ í™•ì¸í•˜ê±°ë‚˜ Selenium ì˜µì…˜ì„ ì¡°ì •í•´ ë³´ì„¸ìš”.")
        return

    st.markdown("---")
    
    # 3. ì •ë³´ êµ¬ì¡°í™”
    with st.spinner("LLMì„ ì´ìš©í•œ ì •ë³´ êµ¬ì¡°í™” ë° ì •ì œ ì¤‘..."):
        clean_struct = structurize_and_refine(all_raw_text, meta_hint, CHAT_MODEL)
        st.session_state.clean_struct = clean_struct
        
        # JD ì²­í¬ ìƒì„± ë° ì„ë² ë”©
        jd_chunks = chunk_text(all_raw_text, max_len=1800)
        jd_embeds = get_text_embedding(jd_chunks, EMBED_MODEL)
        st.session_state.job_desc_chunks = jd_chunks
        st.session_state.job_desc_embeds = jd_embeds
        
        st.success("âœ… ì •ë³´ êµ¬ì¡°í™” ë° ì„ë² ë”© ì™„ë£Œ")

# 'ì •ë³´ ì¡°íšŒ ë° êµ¬ì¡°í™”' ë²„íŠ¼
if st.button("ğŸš€ ì •ë³´ ì¡°íšŒ ë° êµ¬ì¡°í™” ì‹œì‘", type="primary"):
    if not job_url:
        st.warning("ì±„ìš© ê³µê³  URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        fetch_and_process(job_url, company_url)

# êµ¬ì¡°í™”ëœ ì •ë³´ í‘œì‹œ
if st.session_state.clean_struct:
    struct = st.session_state.clean_struct
    
    st.markdown("---")
    st.subheader("ğŸ’¡ êµ¬ì¡°í™”ëœ ì±„ìš© ì •ë³´")
    col1, col2 = st.columns(2)
    col1.metric("íšŒì‚¬ëª…", struct.get("company_name", "-"))
    col2.metric("ì§ë¬´", struct.get("job_title", "-"))
    st.info(f"**íšŒì‚¬ ì†Œê°œ:** {struct.get('company_intro', '-')}")
    
    st.markdown("#### í•µì‹¬ ì§ë¬´ ìš”ê±´")
    st.columns(3)[0].markdown("##### ì£¼ìš” ì—…ë¬´")
    for item in struct.get("responsibilities", []): st.caption(f"- {item}")
    st.columns(3)[1].markdown("##### í•„ìˆ˜ ìê²©")
    for item in struct.get("qualifications", []): st.caption(f"- {item}")
    st.columns(3)[2].markdown("##### ìš°ëŒ€ ì‚¬í•­")
    for item in struct.get("preferences", []): st.caption(f"- {item}")

# -----------------------------------------------------------------------------
# Resume Upload and Processing
# -----------------------------------------------------------------------------
if st.session_state.clean_struct:
    st.markdown("---")
    st.subheader("ğŸ“ ì´ë ¥ì„œ ë“±ë¡ ë° ìì†Œì„œ ìƒì„±")
    
    uploaded_file = st.file_uploader("ì´ë ¥ì„œ íŒŒì¼ ë“±ë¡ (TXT, PDF, DOCX ë“± í…ìŠ¤íŠ¸ ì¶”ì¶œ ê°€ëŠ¥í•œ íŒŒì¼)", type=["txt", "pdf", "docx"])
    
    if uploaded_file:
        try:
            # íŒŒì¼ í˜•ì‹ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§ (ì—¬ê¸°ì— ì‹¤ì œ ë¡œì§ í•„ìš”: ì˜ˆ. PyPDF2, docx ë¼ì´ë¸ŒëŸ¬ë¦¬)
            # í˜„ì¬ëŠ” TXT íŒŒì¼ë§Œ ì§€ì›í•œë‹¤ê³  ê°€ì •
            if uploaded_file.type == "text/plain":
                 st.session_state.resume_text = uploaded_file.read().decode("utf-8")
                 st.success("âœ… ì´ë ¥ì„œ(TXT) ë‚´ìš© ë¡œë“œ ì™„ë£Œ")
            else:
                 st.warning("âš ï¸ í˜„ì¬ëŠ” TXT íŒŒì¼ë§Œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œì—ëŠ” PDF/DOCX íŒŒì‹± ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                 st.session_state.resume_text = ""
        except Exception as e:
            st.error(f"ì´ë ¥ì„œ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            st.session_state.resume_text = ""
            
    if st.session_state.resume_text:
        st.text_area("**ì´ë ¥ì„œ ì›ë¬¸ (í¸ì§‘ ê°€ëŠ¥)**", value=st.session_state.resume_text, height=300, key="current_resume_text")
        
        if st.button("ğŸŒŸ ì´ë ¥ì„œ ê¸°ë°˜ ë§ì¶¤ ìì†Œì„œ ìƒì„±", type="secondary"):
            if not st.session_state.current_resume_text.strip():
                st.warning("ì´ë ¥ì„œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.resume_text = st.session_state.current_resume_text # ì—…ë°ì´íŠ¸
                
                # RAGë¥¼ ìœ„í•œ ì´ë ¥ì„œ ì²­í¬/ì„ë² ë”© ìƒì„±
                with st.spinner("ì´ë ¥ì„œ ë¶„ì„ ë° ì„ë² ë”© ì¤‘..."):
                    resume_chunks = chunk_text(st.session_state.resume_text, max_len=1800)
                    resume_embeds = get_text_embedding(resume_chunks, EMBED_MODEL)
                    st.session_state.resume_chunks = resume_chunks
                    st.session_state.resume_embeds = resume_embeds
                    st.success("âœ… ì´ë ¥ì„œ ë¶„ì„ ì™„ë£Œ")
                
                with st.spinner("AI ìê¸°ì†Œê°œì„œ ìƒì„± ì¤‘..."):
                    cover_letter = llm_generate_cover_letter(
                        st.session_state.clean_struct, st.session_state.resume_text, CHAT_MODEL
                    )
                    st.session_state.cover_letter = cover_letter
                
                st.markdown("#### ğŸ‰ ìƒì„±ëœ ë§ì¶¤ ìê¸°ì†Œê°œì„œ ì´ˆì•ˆ")
                st.markdown(st.session_state.cover_letter)

# -----------------------------------------------------------------------------
# Interview Preparation
# -----------------------------------------------------------------------------
if st.session_state.get("cover_letter") or (st.session_state.resume_text and st.session_state.clean_struct):
    st.markdown("---")
    st.subheader("ğŸ¤ ë§ì¶¤í˜• ë©´ì ‘ ëŒ€ë¹„")
    
    interview_source = st.session_state.get("cover_letter") or st.session_state.resume_text
    
    if not st.session_state.interview_questions:
        if st.button("ğŸ” ë§ì¶¤ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±", type="primary"):
            if not st.session_state.resume_chunks:
                st.error("ì´ë ¥ì„œ ë¶„ì„(ì„ë² ë”©)ì´ í•„ìš”í•©ë‹ˆë‹¤. 'ì´ë ¥ì„œ ê¸°ë°˜ ë§ì¶¤ ìì†Œì„œ ìƒì„±' ë²„íŠ¼ì„ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë§ì¶¤ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    q_data = llm_generate_questions(
                        st.session_state.clean_struct, interview_source, CHAT_MODEL
                    )
                    st.session_state.interview_questions = q_data.get("questions", [])
                    st.session_state.followups = q_data.get("followup_questions", [])
                    st.success("âœ… ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")
    
    if st.session_state.interview_questions:
        st.markdown("#### ë©´ì ‘ ì§ˆë¬¸ ëª©ë¡")
        
        for i, q_item in enumerate(st.session_state.interview_questions, 1):
            q = q_item["question"]
            rel = q_item["relevance"]
            
            st.markdown(f"**({i}) {q}**")
            st.caption(f"ê´€ë ¨ í•­ëª©: {rel}")
            st.text_area(f"ì§ˆë¬¸ {i}ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", key=f"answer_{i}", height=100)
            
            # ë‹µë³€ ì±„ì /í”¼ë“œë°± ë²„íŠ¼
            if st.button(f"ì§ˆë¬¸ {i} ì±„ì  & í”¼ë“œë°± ë°›ê¸°", key=f"score_btn_{i}", type="secondary"):
                answer = st.session_state.get(f"answer_{i}", "").strip()
                if not answer:
                    st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
                else:
                    with st.spinner(f"ì§ˆë¬¸ {i} ë‹µë³€ ì±„ì  ì¤‘..."):
                        res_score = llm_score_and_coach_strict(
                            st.session_state.clean_struct, q, answer, CHAT_MODEL,
                            st.session_state.resume_chunks, st.session_state.resume_embeds,
                            st.session_state.job_desc_chunks, st.session_state.job_desc_embeds
                        )
                        st.session_state[f"feedback_{i}"] = res_score
                        st.session_state.followups.extend(res_score.get("next_followup", []))
                    
                    st.experimental_rerun() # í”¼ë“œë°± í‘œì‹œë¥¼ ìœ„í•´ ìƒˆë¡œê³ ì¹¨

            # í”¼ë“œë°± í‘œì‹œ
            feedback = st.session_state.get(f"feedback_{i}")
            if feedback:
                st.markdown(f"**[í”¼ë“œë°±] ì´ì : {feedback.get('overall_score', 0)}/100**")
                st.markdown(feedback.get("feedback_kr", "í”¼ë“œë°± ë‚´ìš© ì—†ìŒ"))
                if feedback.get("next_followup"):
                     st.info(f"ğŸ’¡ ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸: {', '.join(feedback['next_followup'])}")

        st.markdown("---")
        st.markdown("#### ğŸ”„ íŒ”ë¡œì—… ì§ˆë¬¸ ì—°ìŠµ")
        st.info("ì´ì „ì— ìƒì„±ëœ ë˜ëŠ” ì±„ì ì—ì„œ ì¶”ê°€ëœ íŒ”ë¡œì—… ì§ˆë¬¸ìœ¼ë¡œ ì‹¬ì¸µ ì—°ìŠµì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì¤‘ë³µ ì œê±°
        st.session_state.followups = list(set([f for f in st.session_state.followups if f])) 

        if st.session_state.followups:
            selected_followup = st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0, key="selected_followup")
            st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", key="followup_answer", height=160)
            
            if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
                fu_q = st.session_state.get("selected_followup", ""); fu_ans = st.session_state.get("followup_answer", "")
                if not fu_q: st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
                elif not fu_ans.strip(): st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
                else:
                    with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘..."):
                        res_fu = llm_score_and_coach_strict(
                            st.session_state.clean_struct, fu_q, fu_ans, CHAT_MODEL,
                            st.session_state.resume_chunks, st.session_state.resume_embeds,
                            st.session_state.job_desc_chunks, st.session_state.job_desc_embeds
                        )
                    st.markdown("---")
                    st.markdown(f"**[íŒ”ë¡œì—… ê²°ê³¼] ì§ˆë¬¸: {fu_q}**")
                    st.metric("ì´ì (/100)", res_fu.get("overall_score", 0))
                    st.markdown(res_fu.get("feedback_kr", "í”¼ë“œë°± ë‚´ìš© ì—†ìŒ"))
                    
                    # ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì„¸ì…˜ì— ì¶”ê°€
                    if res_fu.get("next_followup"):
                         st.info(f"ğŸ’¡ ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸: {', '.join(res_fu['next_followup'])}")
                         st.session_state.followups.extend(res_fu["next_followup"])

        else:
            st.info("í˜„ì¬ ì¶”ê°€ íŒ”ë¡œì—… ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§ˆë¬¸ì— ëŒ€í•œ ì±„ì ì„ ì§„í–‰í•˜ì‹œë©´ ìƒˆë¡œìš´ ì§ˆë¬¸ì´ ì¶”ê°€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")