# -*- coding: utf-8 -*-
################################################################################
# Job Helper Bot (Selenium-ONLY)
# - ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘
# - ì˜¤ì§ Seleniumìœ¼ë¡œë§Œ í˜ì´ì§€ ë¡œë“œ/í´ë¦­/ë³¸ë¬¸ ì¶”ì¶œ (í´ë°± ì—†ìŒ)
################################################################################

import os, re, json, urllib.parse, time, io, tempfile
from typing import Optional, Tuple, Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed

from bs4 import BeautifulSoup
import html2text
import streamlit as st
import numpy as np
import pandas as pd

# ==== OpenAI ====
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ==== Selenium (í•„ìˆ˜) ====
from selenium import webdriver
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
import shutil, pathlib

# -----------------------------------------------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(page_title="Job Helper Bot (Selenium-ONLY)", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” Job Helper Bot (Selenium-ONLY) : ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘")

# -----------------------------------------------------------------------------
# OpenAI í‚¤ ì…ë ¥/í™•ë³´
# -----------------------------------------------------------------------------
API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

# -----------------------------------------------------------------------------
# Sidebar ì˜µì…˜
# -----------------------------------------------------------------------------
with st.sidebar:
    st.subheader("ëª¨ë¸ & ì˜µì…˜")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small","text-embedding-3-large"], index=0)
    ENABLE_COMPANY_ENRICH = st.checkbox("íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ ìˆ˜ì§‘(í™ˆí˜ì´ì§€ë§Œ)", value=True)
    SELENIUM_TIMEOUT = st.slider("Selenium ëŒ€ê¸°(ì´ˆ)", 5, 25, 10)
    MAX_FETCH_PARALLEL = st.slider("ë³‘ë ¬ ìˆ˜ì§‘ ì“°ë ˆë“œ", 2, 8, 4)

# -----------------------------------------------------------------------------
# html2text
# -----------------------------------------------------------------------------
def _get_html2text():
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    return conv
HTML2TEXT = _get_html2text()

# -----------------------------------------------------------------------------
# ê³µí†µ ìœ í‹¸
# -----------------------------------------------------------------------------
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def clean_text(s: str, max_len: int = 16000) -> str:
    if not s: return ""
    s = re.sub(r"\r","", s)
    s = re.sub(r"\s+"," ", s).strip()
    return s[:max_len] if len(s) > max_len else s

def html_to_text(html_str: str) -> str:
    txt = HTML2TEXT.handle(html_str or "")
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return clean_text(txt)

# -----------------------------------------------------------------------------
# (1) Selenium ë¹Œë” & í™•ì¥ í´ë¦­(ë„ë©”ì¸ ìµœì í™” í¬í•¨)
# -----------------------------------------------------------------------------
def _build_chrome(headless: bool = True):
    opts = ChromeOptions()
    if headless:
        opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1440,2400")
    opts.add_argument("--lang=ko-KR")
    opts.add_argument("--disable-blink-features=AutomationControlled")

    # â–¶ í¬ë¡¬ ë°”ì´ë„ˆë¦¬ ìë™ íƒì§€ (Streamlit Cloud/ì„œë²„ í™˜ê²½ ëŒ€ë¹„)
    candidates = [
        os.getenv("GOOGLE_CHROME_BIN"),
        os.getenv("CHROME_BIN"),
        shutil.which("google-chrome"),
        shutil.which("google-chrome-stable"),
        shutil.which("chromium-browser"),
        shutil.which("chromium"),
        "/usr/bin/google-chrome",
        "/usr/bin/chromium-browser",
        "/usr/bin/chromium",
    ]
    for p in candidates:
        if p and os.path.exists(p):
            opts.binary_location = p
            break

    # â–¶ webdriver-manager + Service ì‚¬ìš© (Selenium 4 ê¶Œì¥ ë°©ì‹)
    try:
        driver_path = ChromeDriverManager().install()
        service = Service(driver_path)
        driver = webdriver.Chrome(service=service, options=opts)
    except WebDriverException:
        # ì…€ë ˆë‹ˆì›€ ë§¤ë‹ˆì €(ë‚´ì¥) ì‹œë„ â€” ë¡œì»¬ì— í¬ë¡¬ì´ ìˆì„ ë•Œë§Œ ì‘ë™
        driver = webdriver.Chrome(options=opts)

    # (ê°€ëŠ¥í•œ í™˜ê²½ì—ì„œ) í—¤ë“œë¦¬ìŠ¤ íƒì§€ íšŒí”¼
    try:
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        })
    except Exception:
        pass
    return driver


def _click_by_text_candidates(driver, texts: List[str]):
    for t in texts:
        try:
            xpath_exact = f"//*[normalize-space(text())='{t}']"
            xpath_contains = f"//*[contains(normalize-space(text()), '{t}')]"
            for xp in (xpath_exact, xpath_contains):
                els = driver.find_elements(By.XPATH, xp)
                for el in els[:8]:
                    try:
                        driver.execute_script("arguments[0].click();", el)
                        time.sleep(0.25)
                    except Exception:
                        continue
        except Exception:
            continue

def _click_many(driver, css_list, limit_per_selector=8):
    for css in css_list:
        try:
            els = driver.find_elements(By.CSS_SELECTOR, css)
            for el in els[:limit_per_selector]:
                try:
                    driver.execute_script("arguments[0].click();", el)
                    time.sleep(0.2)
                except Exception:
                    continue
        except Exception:
            continue

def _expand_wanted(driver):
    selectors = [
        "[data-qa='btn-read-more']",
        "[aria-expanded='false']",
        "[role='button']",
        "button[class*='Read'], a[class*='Read']",
        "button[class*='More'], a[class*='More']",
    ]
    _click_many(driver, selectors)
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´"])

def _expand_saramin(driver):
    selectors = [
        ".btn_more", ".btnMore", ".btn-detail", ".btn_toggle",
        "[aria-expanded='false']", "[role='button']",
        "button[class*='more'], a[class*='more']"
    ]
    _click_many(driver, selectors)
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ì •ë³´"])

def _expand_jobkorea(driver):
    selectors = [
        ".btnFold", ".btnToggleRead", ".btn_more",
        "[aria-expanded='false']", "[role='button']",
        "button[class*='More'], a[class*='More']"
    ]
    _click_many(driver, selectors)
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ë³´ê¸°"])

def selenium_only_get_html(url: str, timeout: int = 10) -> str:
    driver = _build_chrome(headless=True)
    try:
        driver.set_page_load_timeout(timeout)
        driver.get(url)
        try:
            WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, "//*")))
        except TimeoutException:
            pass

        host = urllib.parse.urlsplit(url).netloc.lower()

        # ê³µí†µ â€œë”ë³´ê¸°/ìš°ëŒ€â€ ì‹œë„
        _click_by_text_candidates(driver, ["ë”ë³´ê¸°","ìƒì„¸ë³´ê¸°","ìì„¸íˆ ë³´ê¸°","ìì„¸íˆ","ì „ì²´ë³´ê¸°","í¼ì¹˜ê¸°","ëª¨ë‘ ë³´ê¸°","Read more","More"])
        _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","Requirements","Responsibilities","Preferred"])

        # ë„ë©”ì¸ ì „ìš© í™•ì¥
        if "wanted.co.kr" in host:
            _expand_wanted(driver)
        if "saramin.co.kr" in host or "saramin" in host:
            _expand_saramin(driver)
        if "jobkorea.co.kr" in host:
            _expand_jobkorea(driver)

        # ì§€ì—° ë¡œë”© ë°©ì§€ ìŠ¤í¬ë¡¤
        for _ in range(6):
            try:
                driver.execute_script("window.scrollBy(0, 1000);"); time.sleep(0.25)
            except Exception:
                break

        return driver.page_source or ""
    finally:
        try: driver.quit()
        except Exception: pass

# -----------------------------------------------------------------------------
# (2) í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Selenium-ONLY)
# -----------------------------------------------------------------------------
def fetch_all_text_selenium_only(url: str, timeout: int = 10) -> Tuple[str, Dict, Optional[str]]:
    url = normalize_url(url)
    if not url:
        return "", {"error":"invalid_url"}, None

    html_dyn = selenium_only_get_html(url, timeout=timeout)
    if not html_dyn or len(html_dyn) < 200:
        return "", {"source":"selenium_failed","len":0,"url_final":url}, None

    txt = html_to_text(html_dyn)
    return txt, {"source":"selenium","len":len(txt),"url_final":url}, html_dyn

# -----------------------------------------------------------------------------
# (3) ë©”íƒ€/ì •ì œ/ê·œì¹™ ê¸°ë°˜ ë³´ì™„
# -----------------------------------------------------------------------------
def extract_company_meta(soup_html: Optional[str]) -> Dict[str,str]:
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup_html: return meta
    try:
        soup = BeautifulSoup(soup_html, "lxml")
        cand=[]
        og = soup.find("meta", {"property":"og:site_name"})
        if og and og.get("content"): cand.append(og["content"])
        app = soup.find("meta", {"name":"application-name"})
        if app and app.get("content"): cand.append(app["content"])
        if soup.title and soup.title.string: cand.append(soup.title.string)
        cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
        cand = [c for c in cand if 2 <= len(c) <= 40]
        meta["company_name"] = cand[0] if cand else ""
        md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
        if md and md.get("content"):
            meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
        jt = ""
        ogt = soup.find("meta", {"property":"og:title"})
        if ogt and ogt.get("content"): jt = ogt["content"]
        if not jt:
            h1 = soup.find("h1")
            if h1 and h1.get_text(): jt = h1.get_text(strip=True)
        if not jt:
            h2 = soup.find("h2")
            if h2 and h2.get_text(): jt = h2.get_text(strip=True)
        meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    except Exception:
        pass
    return meta

def clean_bullets(arr):
    clean=[]; seen=set()
    for it in arr:
        t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·â–¶â–ªï¸").strip()
        if t and t not in seen:
            seen.add(t); clean.append(t[:180])
    return clean[:12]

def rule_based_sections(raw_text: str) -> dict:
    txt = clean_text(raw_text, 16000)
    lines = [re.sub(r"\s+"," ", l).strip(" -â€¢Â·â–¶â–ªï¸") for l in txt.split("\n") if l.strip()]
    hdr_resp = re.compile(r"(ì£¼ìš”\s*ì—…ë¬´|ë‹´ë‹¹\s*ì—…ë¬´|Role|Responsibilities?)", re.I)
    hdr_qual = re.compile(r"(ìê²©\s*ìš”ê±´|ì§€ì›\s*ìê²©|Requirements?|Qualifications?)", re.I)
    hdr_pref = re.compile(r"(ìš°ëŒ€\s*ì‚¬í•­|ìš°ëŒ€|ì„ í˜¸|Preferred|Nice\s*to\s*have|Plus)", re.I)
    bucket = None
    out = {"responsibilities": [], "qualifications": [], "preferences": []}

    def push(line, b):
        if line and len(line) > 1 and line not in out[b]:
            out[b].append(line[:180])

    for l in lines:
        if hdr_resp.search(l): bucket="responsibilities"; continue
        if hdr_qual.search(l): bucket="qualifications"; continue
        if hdr_pref.search(l): bucket="preferences"; continue
        if bucket is None:
            if hdr_pref.search(l): bucket="preferences"
            elif any(k in l.lower() for k in ["java","python","spark","airflow","kafka","ml","sql"]):
                bucket="responsibilities"
            else:
                continue
        push(l, bucket)

    kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
    remain_qual=[]
    for q in out["qualifications"]:
        (out["preferences"] if kw_pref.search(q) else remain_qual).append(q)
    out["qualifications"]=remain_qual

    for k in out:
        out[k] = list(dict.fromkeys([re.sub(r"\s+"," ", s).strip(" -â€¢Â·â–¶â–ªï¸").strip() for s in out[k]]))[:12]
    return out

PROMPT_SYSTEM_STRUCT = (
    "ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
    "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” ì¡ë‹¤í•œ ê´‘ê³ /UIì”ì¬ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µ ì—†ì´ ì •ì œí•˜ë¼."
)

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    ctx = clean_text(raw_text, 14000)
    user_msg = {"role":"user","content":(
        "ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
        f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
        f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
        "--- ì›ë¬¸ ì‹œì‘ ---\n"
        f"{ctx}\n"
        "--- ì›ë¬¸ ë ---\n\n"
        "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
        "{"
        "\"company_name\": str, "
        "\"company_intro\": str, "
        "\"job_title\": str, "
        "\"responsibilities\": [str], "
        "\"qualifications\": [str], "
        "\"preferences\": [str]"
        "}\n"
        "- 'ìš°ëŒ€ ì‚¬í•­(preferences)'ì€ í‘œì‹œê°€ ìˆëŠ” í•­ëª©ë§Œ í¬í•¨.\n"
        "- ë¶ˆë¦¿/ì´ëª¨ì§€ ì œê±°, ê°„ê²°í™”, ì¤‘ë³µ ì œê±°."
    )}
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2, max_tokens=900,
            response_format={"type":"json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg]
        )
        data = json.loads(resp.choices[0].message.content)
    except Exception as e:
        data = {"company_name": meta_hint.get("company_name",""),
                "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
                "job_title": meta_hint.get("job_title",""),
                "responsibilities": [], "qualifications": [], "preferences": [], "error": str(e)}

    for k in ["responsibilities","qualifications","preferences"]:
        arr = data.get(k, [])
        if not isinstance(arr, list): arr=[]
        data[k] = clean_bullets(arr)

    if len(data.get("preferences", [])) < 1:
        rb = rule_based_sections(ctx)
        if rb.get("preferences"):
            data["preferences"] = clean_bullets(list(dict.fromkeys(data.get("preferences", []) + rb["preferences"])))
        else:
            kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
            remain=[]; moved=[]
            for q in data.get("qualifications", []):
                (moved if kw_pref.search(q) else remain).append(q)
            data["preferences"]=clean_bullets(moved); data["qualifications"]=clean_bullets(remain)

    for k in ["company_name","company_intro","job_title"]:
        if isinstance(data.get(k), str):
            data[k] = re.sub(r"\s+"," ", data[k]).strip()
    return data

# -----------------------------------------------------------------------------
# (4) íŒŒì¼/ì„ë² ë”©/RAG (ì´ì „ê³¼ ë™ì¼)
# -----------------------------------------------------------------------------
try:
    import pypdf
except Exception:
    pypdf = None

def read_pdf(data: bytes) -> str:
    if pypdf is None: return ""
    try:
        reader = pypdf.PdfReader(io.BytesIO(data))
        return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
    except Exception:
        return ""

def read_docx(data: bytes) -> str:
    try:
        import docx2txt
        with tempfile.NamedTemporaryFile(suffix=".docx", delete=True) as tmp:
            tmp.write(data); tmp.flush()
            return docx2txt.process(tmp.name) or ""
    except Exception:
        return ""

def read_file_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md")):
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    return ""

def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    t = re.sub(r"\s+"," ", text or "").strip()
    if not t: return []
    out, start = [], 0
    L = len(t)
    while start < L:
        end = min(L, start+size)
        out.append(t[start:end])
        if end == L: break
        start = max(0, end-overlap)
    return out

def embed_texts(texts: List[str], client: OpenAI, model_name: str) -> np.ndarray:
    if not texts: return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=model_name, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def l2_normalize(mat: np.ndarray) -> np.ndarray:
    if mat.size == 0: return mat
    n = np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12
    return mat / n

def cosine_topk(matrix_n: np.ndarray, query_vec_n: np.ndarray, k: int = 4):
    if matrix_n.size == 0: return np.array([]), np.array([], dtype=int)
    sims = matrix_n @ query_vec_n.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

def retrieve_resume_chunks(query: str, chunks: List[str], embeds_norm: np.ndarray, client: OpenAI, model_name: str, k: int = 4):
    if not chunks or embeds_norm is None or embeds_norm.size == 0:
        return []
    qv = embed_texts([query], client, model_name)
    qv_n = l2_normalize(qv)
    scores, idxs = cosine_topk(embeds_norm, qv_n, k=k)
    return [(float(s), chunks[int(i)]) for s, i in zip(scores, idxs)]

PROMPT_SYSTEM_Q = (
    "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´, ê·¸ë¦¬ê³  ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ í•¨ê»˜ ê³ ë ¤í•´ "
    "ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. ì§ˆë¬¸ì€ ì„œë¡œ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ë„ ì„ì–´ë¼."
)
PROMPT_SYSTEM_DRAFT = (
    "ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ ê²°í•©í•´ "
    "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
    "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼."
)
PROMPT_SYSTEM_SCORE_STRICT = (
    "ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
    "ê° ê¸°ì¤€ì€ 0~20 ì •ìˆ˜ì´ë©°, ì´ì ì€ ê¸°ì¤€ í•©ê³„(ìµœëŒ€ 100)ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•œë‹¤. "
    "ê³¼ì¥/ëª¨í˜¸í•¨/ê·¼ê±° ë¶€ì¬/ìˆ«ì ì—†ëŠ” ì£¼ì¥/ì±…ì„ íšŒí”¼ ë“±ì„ ê°•í•˜ê²Œ ê°ì í•˜ë¼."
)
CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_one_question_with_resume(clean: Dict, level: str, model: str,
                                          resume_chunks: List[str], resume_embeds_norm: np.ndarray) -> str:
    hits = retrieve_resume_chunks("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", resume_chunks, resume_embeds_norm, client, EMBED_MODEL, k=4)
    resume_context = "\n".join([f"- {t[:350]}" for _, t in hits])[:1200]
    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {"role":"user","content":(
        f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
        f"[ì§€ì›ì ì´ë ¥ì„œ ìš”ì•½(ë°œì·Œ)]\n{resume_context}\n\n"
        f"[ìš”ì²­]\n- ë‚œì´ë„/ì—°ì°¨: {level}\n"
        f"- ì¤‘ë³µ/ìœ ì‚¬ë„ ì§€ì–‘, êµì§‘í•© ë˜ëŠ” ê³µë°±ì˜ì—­ ê²¨ëƒ¥\n"
        f"- í•œêµ­ì–´ ë©´ì ‘ ì§ˆë¬¸ 1ê°œë§Œ í•œ ì¤„ë¡œ ì¶œë ¥"
    )}
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.7, max_tokens=120,
            messages=[{"role":"system","content":PROMPT_SYSTEM_Q}, user_msg]
        )
        q = resp.choices[0].message.content.strip()
        q = re.sub(r"^\s*\d+[\).\s-]*","", q).split("\n")[0].strip()
        return q
    except Exception:
        return ""

def llm_draft_answer(clean: Dict, question: str, model: str,
                     resume_chunks: List[str], resume_embeds_norm: np.ndarray) -> str:
    hits = retrieve_resume_chunks(question, resume_chunks, resume_embeds_norm, client, EMBED_MODEL, k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {"role":"user","content":(
        f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
        f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
        f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
        "ìœ„ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ STAR ê¸°ë°˜ í•œêµ­ì–´ ë‹µë³€ **ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì¤˜."
    )}
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.5, max_tokens=700,
            messages=[{"role":"system","content":PROMPT_SYSTEM_DRAFT}, user_msg]
        )
        return resp.choices[0].message.content.strip()
    except Exception:
        return ""

def llm_score_and_coach_strict(clean: Dict, question: str, answer: str, model: str,
                               resume_chunks: List[str], resume_embeds_norm: np.ndarray) -> Dict:
    hits = retrieve_resume_chunks(question + "\n" + answer[:800], resume_chunks, resume_embeds_norm, client, EMBED_MODEL, k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {"role":"user","content":(
        f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
        f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
        f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
        f"[ì§€ì›ì ë‹µë³€]\n{answer}\n\n"
        "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
        "{"
        "\"overall_score\": 0~100 ì •ìˆ˜,"
        "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
        "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
        "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
        "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
        "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
        "\"strengths\": [\"...\"],"
        "\"risks\": [\"...\"],"
        "\"improvements\": [\"...\",\"...\",\"...\"],"
        "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
        "}"
    )}
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2, max_tokens=900,
            response_format={"type":"json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_SCORE_STRICT}, user_msg]
        )
        data = json.loads(resp.choices[0].message.content)
        fixed=[]
        for name in CRITERIA:
            found=None
            for it in data.get("criteria", []):
                if str(it.get("name","")).strip()==name:
                    found=it; break
            if not found: found={"name":name,"score":0,"comment":""}
            sc = int(found.get("score",0)); sc=max(0,min(20,sc))
            found["score"]=sc; found["comment"]=str(found.get("comment","")).strip()
            fixed.append(found)
        total=sum(x["score"] for x in fixed)
        data["criteria"]=fixed
        data["overall_score"]=total
        for k in ["strengths","risks","improvements"]:
            arr=data.get(k,[]); 
            if not isinstance(arr,list): arr=[]
            data[k]=[str(x).strip() for x in arr if str(x).strip()][:5]
        data["revised_answer"]=str(data.get("revised_answer","")).strip()
        return data
    except Exception as e:
        return {"overall_score": 0,
                "criteria": [{"name": n, "score": 0, "comment": ""} for n in CRITERIA],
                "strengths": [], "risks": [], "improvements": [], "revised_answer": "",
                "error": str(e)}

# -----------------------------------------------------------------------------
# (5) ì„¸ì…˜ ìƒíƒœ
# -----------------------------------------------------------------------------
def _init_state():
    defaults = {
        "clean_struct": None,
        "resume_raw": "",
        "resume_chunks": [],
        "resume_embeds": None,
        "resume_embeds_norm": None,
        "current_question": "",
        "answer_text": "",
        "records": [],
        "followups": [],
        "selected_followup": "",
        "followup_answer": "",
        "last_result": None,
        "last_followup_result": None,
        "company_home": "",
    }
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v
_init_state()

# -----------------------------------------------------------------------------
# (6) UI: 1) ì±„ìš© ê³µê³  URL ì…ë ¥ â†’ (Selenium Only) ì›ë¬¸ ìˆ˜ì§‘Â·ì •ì œ
# -----------------------------------------------------------------------------
st.header("1) ì±„ìš© ê³µê³  URL (Selenium ì „ìš©)")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì·¨ì—… í¬í„¸/ê¸°ì—… ì±„ìš© í˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
st.text_input("íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL (ì„ íƒ)", key="company_home", placeholder="íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”.")

if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ (Selenium ONLY)", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("Seleniumìœ¼ë¡œ ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
            raw, meta, soup_html = fetch_all_text_selenium_only(url.strip(), timeout=SELENIUM_TIMEOUT)
            hint = extract_company_meta(soup_html)

        st.caption(f"ìˆ˜ì§‘ ì†ŒìŠ¤: {meta.get('source')} Â· ê¸¸ì´: {meta.get('len')}")
        if not raw:
            st.error("Selenium ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Chrome/Chromium ì„¤ì¹˜, íƒ€ì„ì•„ì›ƒ/ì…€ë ‰í„° í™•ì¸ í•„ìš”)")
        else:
            with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
                clean = llm_structurize(raw, hint, CHAT_MODEL)
            if not clean.get("preferences"):
                rb = rule_based_sections(raw)
                if rb.get("preferences"): clean["preferences"] = clean_bullets(rb["preferences"])
            st.session_state.clean_struct = clean
            try:
                kw_cnt = len(re.findall(r"(ìš°ëŒ€|ìš°ëŒ€ì‚¬í•­|Preferred)", raw, flags=re.I))
                st.caption(f"ì§„ë‹¨: ì›ë¬¸ ë‚´ 'ìš°ëŒ€' ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì • ë“±ì¥ ìˆ˜ â‰ˆ {kw_cnt}")
            except Exception:
                pass
            st.success("ì •ì œ ì™„ë£Œ!")

# -----------------------------------------------------------------------------
# (7) UI: 2) íšŒì‚¬ ìš”ì•½
# -----------------------------------------------------------------------------
st.header("2) íšŒì‚¬ ìš”ì•½")
clean = st.session_state.clean_struct
if clean:
    st.markdown(f"**íšŒì‚¬ëª…:** {clean.get('company_name','-')}")
    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½):** {clean.get('company_intro','-')}")
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {clean.get('job_title','-')}")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("**ì£¼ìš” ì—…ë¬´**")
        for b in clean.get("responsibilities", []): st.markdown(f"- {b}")
    with c2:
        st.markdown("**ìê²© ìš”ê±´**")
        for b in clean.get("qualifications", []): st.markdown(f"- {b}")
    with c3:
        st.markdown("**ìš°ëŒ€ ì‚¬í•­**")
        prefs = clean.get("preferences", [])
        if prefs:
            for b in prefs: st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € URLì„ ì •ì œí•´ ì£¼ì„¸ìš”.")

st.divider()

# -----------------------------------------------------------------------------
# (8) UI: 3) ì´ë ¥ì„œ ì—…ë¡œë“œ/ì¸ë±ì‹±
# -----------------------------------------------------------------------------
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploads = st.file_uploader("ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ ê°€ëŠ¥", type=["pdf","txt","md","docx"], accept_multiple_files=True)
_RESUME_CHUNK = 500; _RESUME_OVLP = 100

if st.button("ì´ë ¥ì„œ ì¸ë±ì‹±", type="secondary"):
    if not uploads:
        st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        all_text=[]
        for up in uploads:
            t = read_file_text(up)
            if t: all_text.append(t)
        resume_text = "\n\n".join(all_text)
        if not resume_text.strip():
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            chunks = chunk(resume_text, size=_RESUME_CHUNK, overlap=_RESUME_OVLP)
            with st.spinner("ì´ë ¥ì„œ ë²¡í„°í™” ì¤‘..."):
                embeds = embed_texts(chunks, client, EMBED_MODEL)
                embeds_norm = l2_normalize(embeds)
            st.session_state.resume_raw = resume_text
            st.session_state.resume_chunks = chunks
            st.session_state.resume_embeds = embeds
            st.session_state.resume_embeds_norm = embeds_norm
            st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)")

st.divider()

# -----------------------------------------------------------------------------
# (9) UI: 4) ìì†Œì„œ ìƒì„±
# -----------------------------------------------------------------------------
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“±")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    company = json.dumps({"clean":clean_struct}, ensure_ascii=False)
    resume_snippet = resume_text.strip()[:9000]
    system = ("ë„ˆëŠ” í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì „ë¬¸ê°€ë‹¤. ì±„ìš© ê³µê³ ì˜ íšŒì‚¬/ì§ë¬´ ìš”ê±´ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•´ "
              "íšŒì‚¬ íŠ¹í™” ìì†Œì„œë¥¼ ì‘ì„±í•œë‹¤. ê³¼ì¥/í—ˆìœ„ëŠ” ê¸ˆì§€í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´í™”í•œë‹¤.")
    req = (f"íšŒì‚¬ ì¸¡ ìš”ì²­ ì£¼ì œëŠ” '{topic_hint.strip()}' ì´ë‹¤. ì´ ì£¼ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•˜ë¼."
           if topic_hint and topic_hint.strip()
           else "íŠ¹ì • ì£¼ì œ ìš”ì²­ì´ ì—†ìœ¼ë¯€ë¡œ, ì±„ìš© ê³µê³ ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì§€ì›ë™ê¸°ì™€ ì§ë¬´ì í•©ì„±ì„ ê°•ì¡°í•˜ë¼.")
    user = (f"[íšŒì‚¬/ì§ë¬´ ìš”ì•½(JSON)]\n{company}\n\n"
            f"[í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½ ê°€ëŠ¥)]\n{resume_snippet}\n\n"
            f"[ì‘ì„± ì§€ì‹œ]\n- {req}\n"
            "- ë¶„ëŸ‰: 600~900ì\n"
            "- êµ¬ì„±: 1) ì§€ì› ë™ê¸° 2) ì§ë¬´ ê´€ë ¨ í•µì‹¬ ì—­ëŸ‰Â·ê²½í—˜ 3) ì„±ê³¼/ì§€í‘œ 4) ì…ì‚¬ í›„ ê¸°ì—¬ ë°©ì•ˆ 5) ë§ˆë¬´ë¦¬\n"
            "- ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆëŠ” 1ì¸ì¹­ ì„œìˆ . ë¬¸ì¥ê³¼ ë¬¸ë‹¨ ê°€ë…ì„±ì„ ìœ ì§€.\n"
            "- ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬/ì¤‘ë³µ/ê´‘ê³  ë¬¸êµ¬ ì‚­ì œ.")
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.4, max_tokens=800,
            messages=[{"role":"system","content":system},{"role":"user","content":user}]
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(ìì†Œì„œ ìƒì„± ì‹¤íŒ¨: {e})"

if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
    elif not st.session_state.resume_raw.strip():
        st.warning("ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  'ì´ë ¥ì„œ ì¸ë±ì‹±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cover = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_raw, topic, CHAT_MODEL)
        st.subheader("ìì†Œì„œ (ìƒì„± ê²°ê³¼)")
        st.write(cover)
        st.download_button("ìì†Œì„œ TXT ë‹¤ìš´ë¡œë“œ", data=cover.encode("utf-8"), file_name="cover_letter.txt", mime="text/plain")

st.divider()

# -----------------------------------------------------------------------------
# (10) UI: 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ
# -----------------------------------------------------------------------------
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

col1, col2 = st.columns(2)
with col1:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct:
            st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
        else:
            q = llm_generate_one_question_with_resume(
                st.session_state.clean_struct, level, CHAT_MODEL,
                st.session_state.resume_chunks, st.session_state.resume_embeds_norm
            )
            if q:
                st.session_state.current_question = q
                st.session_state.answer_text = ""
                st.session_state.last_result = None
                st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")

with col2:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        else:
            draft = llm_draft_answer(
                st.session_state.clean_struct, st.session_state.current_question, CHAT_MODEL,
                st.session_state.resume_chunks, st.session_state.resume_embeds_norm
            )
            if draft:
                st.session_state.answer_text = draft
                st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# -----------------------------------------------------------------------------
# (11) UI: 6) ì±„ì  & ì½”ì¹­
# -----------------------------------------------------------------------------
st.header("6) ì±„ì  & ì½”ì¹­")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì±„ì /ì½”ì¹­ ì¤‘..."):
            res = llm_score_and_coach_strict(
                st.session_state.clean_struct,
                st.session_state.current_question,
                st.session_state.answer_text,
                CHAT_MODEL,
                st.session_state.resume_chunks,
                st.session_state.resume_embeds_norm
            )
        st.session_state.last_result = res
        st.success("ì±„ì /ì½”ì¹­ ì™„ë£Œ!")

st.divider()
st.subheader("í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.last_result
if last:
    st.metric("ì´ì (/100)", last.get("overall_score", 0))
    st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜ & ì½”ë©˜íŠ¸**")
    for it in last.get("criteria", []):
        st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
    if last.get("strengths"):
        st.markdown("**ê°•ì **")
        for s in last["strengths"]: st.markdown(f"- {s}")
    if last.get("risks"):
        st.markdown("**ê°ì  ìš”ì¸/ë¦¬ìŠ¤í¬**")
        for r in last["risks"]: st.markdown(f"- {r}")
    if last.get("improvements"):
        st.markdown("**ê°œì„  í¬ì¸íŠ¸**")
        for im in last["improvements"]: st.markdown(f"- {im}")
    if last.get("revised_answer"):
        st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR)**")
        st.write(last["revised_answer"])
