# -*- coding: utf-8 -*-
################################################################################
# Job Helper Bot (Selenium ONLY for company summary + Speed-ups)
# - íšŒì‚¬ ìš”ì•½(íšŒì‚¬ëª…/ì†Œê°œ/ì§ë¬´ëª… + ì£¼ìš”ì—…ë¬´/ìê²©ìš”ê±´/ìš°ëŒ€ì‚¬í•­)ì„ Selenium ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘
# - Wanted __NEXT_DATA__ ë³‘í•©, FAST ëª¨ë“œ, ì ì ˆí•œ í´ë¦­/ìŠ¤í¬ë¡¤ ìµœì í™”
# - ê¸°ì¡´ UI/LLM/ë‰´ìŠ¤/íšŒì‚¬í™ˆí˜ì´ì§€/ì´ë ¥ì„œ-RAG/ì±„ì /íŒ”ë¡œì—… íë¦„ ìœ ì§€
################################################################################

import os, re, json, urllib.parse, time, io, random, shutil, tempfile, traceback
from typing import Optional, Tuple, Dict, List
from concurrent.futures import ThreadPoolExecutor

import requests
from bs4 import BeautifulSoup
import html2text
import streamlit as st
import pandas as pd
import numpy as np

# ================== ê¸°ë³¸ ì„¤ì • ==================
st.set_page_config(page_title="Job Helper Bot", page_icon="ğŸ¤–", layout="wide")
st.title("Job Helper Bot : ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘")

# ================== OpenAI ==================
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

with st.sidebar:
    st.subheader("ëª¨ë¸ / í¬ë¡¤ë§ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸(ë‚´ë¶€ìš©)", ["text-embedding-3-small","text-embedding-3-large"], index=0)
    SELENIUM_TIMEOUT = st.slider("Selenium ëŒ€ê¸°(ì´ˆ)", 6, 30, 14)
    FAST_MODE = st.toggle("FAST ëª¨ë“œ(í´ë¦­/ìŠ¤í¬ë¡¤ ì¶•ì†Œ)", value=True)

# ================== ê³µí†µ ìœ í‹¸ ==================
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def html_to_text(html_str: str) -> str:
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    txt = conv.handle(html_str or "")
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()

# ================== (NEW) Selenium ë¡œë” ==================
from selenium import webdriver
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

def _pick_chrome_binary() -> Optional[str]:
    cands = [
        os.getenv("CHROME_BIN"), os.getenv("GOOGLE_CHROME_BIN"),
        shutil.which("chromium"), shutil.which("chromium-browser"),
        shutil.which("google-chrome"),
        "/usr/bin/chromium","/usr/bin/chromium-browser",
        "/usr/bin/google-chrome","/usr/bin/google-chrome-stable",
    ]
    for p in cands:
        if p and os.path.exists(p):
            return p
    return None

def _build_chrome(headless: bool = True):
    opts = ChromeOptions()
    if headless: opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--window-size=1440,2400")
    opts.add_argument("--lang=ko-KR")
    binpath = _pick_chrome_binary()
    if binpath: opts.binary_location = binpath
    # Selenium Managerê°€ ë“œë¼ì´ë²„ë¥¼ ìë™ ì¤€ë¹„
    driver = webdriver.Chrome(options=opts)
    return driver

def _click_by_text_candidates(driver, texts: List[str], per=10):
    for t in texts:
        try:
            xp1 = f"//*[normalize-space(text())='{t}']"
            xp2 = f"//*[contains(normalize-space(text()), '{t}')]"
            for xp in (xp1, xp2):
                els = driver.find_elements(By.XPATH, xp)
                for el in els[:per]:
                    try:
                        driver.execute_script("arguments[0].click();", el)
                        time.sleep(0.1 if FAST_MODE else 0.2)
                    except Exception:
                        continue
        except Exception:
            continue

def _click_many_css(driver, selectors: List[str], per=10):
    for sel in selectors:
        try:
            els = driver.find_elements(By.CSS_SELECTOR, sel)
            for el in els[:per]:
                try:
                    driver.execute_script("arguments[0].click();", el)
                    time.sleep(0.08 if FAST_MODE else 0.18)
                except Exception:
                    continue
        except Exception:
            continue

def _expand_wanted(driver):
    sel = [
        "[data-qa='btn-read-more']","[data-qa='job-header__more']",
        "button[aria-expanded='false']","[role='button'][class*='More']",
        "div[aria-expanded='false']",
    ]
    _click_many_css(driver, sel, per=(6 if FAST_MODE else 10))
    _click_by_text_candidates(driver, [
        "ë”ë³´ê¸°","ì „ì²´ë³´ê¸°","ìƒì„¸ë³´ê¸°","ìì„¸íˆ","ëª¨ë‘ ë³´ê¸°",
        "ì£¼ìš”ì—…ë¬´","ìê²©ìš”ê±´","ìš°ëŒ€ì‚¬í•­","ê¸°ì—…/íŒ€ ì†Œê°œ"
    ], per=(5 if FAST_MODE else 10))

def _expand_saramin(driver):
    sel = [".btn_more",".btnMore",".btn-detail",".btn_toggle",
           "[aria-expanded='false']","[role='button']","button[class*='more'], a[class*='more']"]
    _click_many_css(driver, sel, per=(5 if FAST_MODE else 10))
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ì •ë³´"], per=(5 if FAST_MODE else 10))

def _expand_jobkorea(driver):
    sel = [".btnFold",".btnToggleRead",".btn_more",
           "[aria-expanded='false']","[role='button']","button[class*='More'], a[class*='More']"]
    _click_many_css(driver, sel, per=(5 if FAST_MODE else 10))
    _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","ê¸°ì—…ì •ë³´","ìƒì„¸ë³´ê¸°"], per=(5 if FAST_MODE else 10))

def extract_wanted_from_next_html(html: str) -> str:
    """Wantedì˜ __NEXT_DATA__ JSONì—ì„œ ì±„ìš© ë³¸ë¬¸ í‚¤ë§Œ ì¶”ì¶œí•´ í…ìŠ¤íŠ¸ë¡œ ë³‘í•©"""
    try:
        soup = BeautifulSoup(html or "", "html.parser")
        tag = soup.select_one("script#__NEXT_DATA__")
        if not tag: return ""
        raw = (tag.string or tag.text or "").strip()
        data = json.loads(raw)
    except Exception:
        return ""
    key_whitelist = ["job","position","title","desc","description",
                     "responsibilit","duty","role","skill","stack",
                     "require","qualification","prefer","plus","nice"]
    def _walk(d, out):
        if isinstance(d, dict):
            for k, v in d.items():
                if any(t in str(k).lower() for t in key_whitelist):
                    if isinstance(v, str): out.append(v)
                    elif isinstance(v, list):
                        for it in v:
                            if isinstance(it, str): out.append(it)
                            elif isinstance(it, dict):
                                for _, subv in it.items():
                                    if isinstance(subv, str): out.append(subv)
                    elif isinstance(v, dict):
                        for _, subv in v.items():
                            if isinstance(subv, str): out.append(subv)
                _walk(v, out)
        elif isinstance(d, list):
            for it in d: _walk(it, out)
    bucket=[]; _walk(data, bucket)
    seen=set(); lines=[]
    for t in bucket:
        s=re.sub(r"\s+"," ", (t or "")).strip()
        if len(s)>2 and s not in seen:
            seen.add(s); lines.append(s)
    return "\n".join(lines[:900])

def selenium_get_html(url: str, timeout: int = 14) -> str:
    driver = _build_chrome(headless=True)
    try:
        driver.set_page_load_timeout(timeout)
        driver.get(url)
        try:
            WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, "//*")))
        except TimeoutException:
            pass

        host = urllib.parse.urlsplit(url).netloc.lower()
        # ê³µí†µ: í¼ì¹˜ê¸° ë²„íŠ¼ í„°ì¹˜
        _click_by_text_candidates(driver, ["ë”ë³´ê¸°","ìƒì„¸ë³´ê¸°","ìì„¸íˆ ë³´ê¸°","ì „ì²´ë³´ê¸°","Read more","More"],
                                  per=(5 if FAST_MODE else 10))
        _click_by_text_candidates(driver, ["ìš°ëŒ€","ìš°ëŒ€ì‚¬í•­","ìê²©ìš”ê±´","ì£¼ìš”ì—…ë¬´","Requirements","Responsibilities","Preferred"],
                                  per=(5 if FAST_MODE else 10))
        # ì‚¬ì´íŠ¸ë³„ ì¶”ê°€ í™•ì¥
        if "wanted.co.kr" in host: _expand_wanted(driver)
        if "saramin" in host:     _expand_saramin(driver)
        if "jobkorea" in host:    _expand_jobkorea(driver)

        # ì§§ì€ ìŠ¤í¬ë¡¤ ì—¬ëŸ¬ ë²ˆ
        loops = 5 if FAST_MODE else 8
        for _ in range(loops):
            try:
                driver.execute_script("window.scrollBy(0, 1200);"); time.sleep(0.1 if FAST_MODE else 0.25)
            except Exception:
                break

        html = driver.page_source or ""
        # Wantedì˜ __NEXT_DATA__ ë³‘í•©
        if "wanted.co.kr" in host:
            try:
                extra = extract_wanted_from_next_html(html)
                if extra:
                    html += "\n<div id='__WANTED_NEXT_EXTRACT__'>" + \
                            "".join([f"<p>{line}</p>" for line in extra.split("\n")]) + "</div>"
            except Exception:
                pass
        return html
    finally:
        try: driver.quit()
        except Exception: pass

def fetch_all_text_selenium(url: str) -> Tuple[str, Dict, Optional[str]]:
    url_n = normalize_url(url)
    if not url_n: return "", {"error":"invalid_url"}, None
    try:
        html = selenium_get_html(url_n, timeout=SELENIUM_TIMEOUT)
    except Exception as e:
        st.error(f"Selenium ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.code("".join(traceback.format_exc()))
        return "", {"source":"selenium_error","len":0,"url_final":url_n}, None
    if not html or len(html) < 200:
        return "", {"source":"selenium_failed","len":0,"url_final":url_n}, None
    txt = html_to_text(html)
    return txt, {"source":"selenium","len":len(txt),"url_final":url_n}, html

# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta_from_html(html: Optional[str]) -> Dict[str,str]:
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not html: return meta
    try:
        soup = BeautifulSoup(html, "html.parser")
        cand=[]
        og = soup.find("meta", {"property":"og:site_name"})
        if og and og.get("content"): cand.append(og["content"])
        app = soup.find("meta", {"name":"application-name"})
        if app and app.get("content"): cand.append(app["content"])
        if soup.title and soup.title.string: cand.append(soup.title.string)
        cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
        cand = [c for c in cand if 2 <= len(c) <= 40]
        meta["company_name"] = cand[0] if cand else ""
        md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
        if md and md.get("content"):
            meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
        jt = ""
        ogt = soup.find("meta", {"property":"og:title"})
        if ogt and ogt.get("content"): jt = ogt["content"]
        if not jt:
            h1 = soup.find("h1")
            if h1 and h1.get_text(): jt = h1.get_text(strip=True)
        if not jt:
            h2 = soup.find("h2")
            if h2 and h2.get_text(): jt = h2.get_text(strip=True)
        meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    except Exception:
        pass
    return meta

def rule_based_sections(raw_text: str) -> dict:
    txt = re.sub(r"\r", "", raw_text or "").strip()
    lines = [re.sub(r"\s+", " ", l).strip(" -â€¢Â·â–¶â–ªï¸") for l in txt.split("\n")]
    lines = [l for l in lines if l]

    hdr_resp = re.compile(r"(ì£¼ìš”\s*ì—…ë¬´|ë‹´ë‹¹\s*ì—…ë¬´|Role|Responsibilities?)", re.I)
    hdr_qual = re.compile(r"(ìê²©\s*ìš”ê±´|ì§€ì›\s*ìê²©|Requirements?|Qualifications?)", re.I)
    hdr_pref = re.compile(r"(ìš°ëŒ€\s*ì‚¬í•­|ìš°ëŒ€|ì„ í˜¸|Preferred|Nice\s*to\s*have|Plus)", re.I)

    bucket = None
    out = {"responsibilities": [], "qualifications": [], "preferences": []}

    def push(line, b):
        if line and len(line) > 1 and line not in out[b]:
            out[b].append(line[:180])

    for l in lines:
        if hdr_resp.search(l): bucket = "responsibilities"; continue
        if hdr_qual.search(l): bucket = "qualifications"; continue
        if hdr_pref.search(l): bucket = "preferences"; continue
        if bucket is None:
            if hdr_pref.search(l):
                bucket = "preferences"
            elif any(k in l.lower() for k in ["java","python","spark","airflow","kafka","ml","sql"]):
                bucket = "responsibilities"
            else:
                continue
        push(l, bucket)

    kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
    remain_qual = []
    for q in out["qualifications"]:
        if kw_pref.search(q): out["preferences"].append(q)
        else: remain_qual.append(q)
    out["qualifications"] = remain_qual

    for k in out:
        seen=set(); clean=[]
        for s in out[k]:
            s = re.sub(r"\s+", " ", s).strip(" -â€¢Â·â–¶â–ªï¸").strip()
            if s and s not in seen:
                seen.add(s); clean.append(s)
        out[k] = clean[:12]
    return out

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
PROMPT_SYSTEM_STRUCT = ("ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
                        "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
                        "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼.")

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    ctx = (raw_text or "").strip()
    if len(ctx) > 14000: ctx = ctx[:14000]

    user_msg = {"role": "user",
                "content": ("ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
                            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
                            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
                            "--- ì›ë¬¸ ì‹œì‘ ---\n"
                            f"{ctx}\n"
                            "--- ì›ë¬¸ ë ---\n\n"
                            "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
                            "{"
                            "\"company_name\": str, "
                            "\"company_intro\": str, "
                            "\"job_title\": str, "
                            "\"responsibilities\": [str], "
                            "\"qualifications\": [str], "           
                            "\"preferences\": [str]"               
                            "}\n"
                            "- 'ìš°ëŒ€ ì‚¬í•­(preferences)'ì€ ì—­ëŸ‰/ê²½í—˜/ì§€ì‹ ì¡°ê±´ë§Œ í¬í•¨.\n"
                            "- ë¶ˆë¦¿/ë§ˆì»¤/ì´ëª¨ì§€ ì œê±°, ë¬¸ì¥ ê°„ê²°í™”, ì¤‘ë³µ ì œê±°."),}

    try:
        resp = client.chat.completions.create(model=model, temperature=0.2,
                                              response_format={"type": "json_object"},
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg])
        data = json.loads(resp.choices[0].message.content)
    except Exception as e:
        data = {"company_name": meta_hint.get("company_name",""),
                "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
                "job_title": meta_hint.get("job_title",""),
                "responsibilities": [],
                "qualifications": [],
                "preferences": [],
                "error": str(e)}

    for k in ["responsibilities","qualifications","preferences"]:
        arr = data.get(k, [])
        if not isinstance(arr, list): arr = []
        clean_list=[]; seen=set()
        for it in arr:
            t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·â–¶â–ªï¸").strip()
            if t and t not in seen:
                seen.add(t); clean_list.append(t[:180])
        data[k] = clean_list[:12]

    if len(data.get("preferences", [])) < 1:
        rb = rule_based_sections(ctx)
        if rb.get("preferences"):
            merged = data.get("preferences", []) + rb["preferences"]
            seen=set(); pref=[]
            for s in merged:
                s=s.strip()
                if s and s not in seen:
                    seen.add(s); pref.append(s)
            data["preferences"] = pref[:12]
        else:
            kw_pref = re.compile(r"(ìš°ëŒ€|ì„ í˜¸|preferred|plus|ê°€ì‚°ì |ìˆìœ¼ë©´\s*ì¢‹ìŒ)", re.I)
            remain=[]; moved=[]
            for q in data.get("qualifications", []):
                if kw_pref.search(q): moved.append(q)
                else: remain.append(q)
            if moved:
                data["preferences"] = moved[:12]
                data["qualifications"] = remain[:12]
    for k in ["company_name","company_intro","job_title"]:
        if k in data and isinstance(data[k], str):
            data[k] = re.sub(r"\s+"," ", data[k]).strip()
    return data

# ================== íŒŒì¼ ë¦¬ë”/ì„ë² ë”©/RAG ìœ í‹¸ ==================
try:
    import pypdf
except Exception:
    pypdf = None

def read_pdf(data: bytes) -> str:
    if pypdf is None: return ""
    try:
        reader = pypdf.PdfReader(io.BytesIO(data))
        return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
    except Exception:
        return ""

def read_docx(data: bytes) -> str:
    try:
        import docx2txt
        with tempfile.NamedTemporaryFile(suffix=".docx", delete=True) as tmp:
            tmp.write(data); tmp.flush()
            text = docx2txt.process(tmp.name) or ""
            return text
    except Exception:
        return ""

def read_file_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md")):
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    return ""

def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    t = re.sub(r"\s+"," ", text).strip()
    if not t: return []
    out, start = [], 0
    while start < len(t):
        end = min(len(t), start+size)
        out.append(t[start:end])
        if end == len(t): break
        start = max(0, end-overlap)
    return out

def embed_texts(texts: List[str], model_name: str) -> np.ndarray:
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=model_name, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

def retrieve_resume_chunks(query: str, k: int = 4):
    chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
    if not chs or embs is None:
        return []
    qv = embed_texts([query], EMBED_MODEL)
    scores, idxs = cosine_topk(embs, qv, k=k)
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ ==================
def http_get(url: str, timeout: int = 10) -> Optional[requests.Response]:
    try:
        r = requests.get(url,
                         headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                                  "Accept-Language": "ko, en;q=0.9"}, timeout=timeout)
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

@st.cache_data(show_spinner=False, ttl=3600)
def fetch_company_pages(home_url: str) -> Dict[str, List[str]]:
    out = {"vision": [], "talent": []}
    if not home_url: return out
    base = normalize_url(home_url)
    if not base: return out
    paths = ["","/","/about","/company","/about-us","/mission","/vision","/values","/culture","/careers","/talent","/people"]
    seen = set()
    for p in paths:
        url = (base.rstrip("/") + p) if p else base
        if url in seen: continue
        seen.add(url)
        r = http_get(url, timeout=8)
        if not r: continue
        soup = BeautifulSoup(r.text, "lxml")
        texts=[]
        for tag in soup.find_all(["h1","h2","h3","h4","p","li"]):
            try:
                t = tag.get_text(" ", strip=True)
            except Exception:
                continue
            if not t: continue
            t = re.sub(r"\s+"," ", t)
            if 6 <= len(t) <= 260:
                texts.append(t)
        for t in texts:
            low = t.lower()
            if any(k in low for k in ["talent","ì¸ì¬ìƒ","who we hire","people we"]):
                out["talent"].append(t)
            if any(k in low for k in ["ë¹„ì „","ë¯¸ì…˜","í•µì‹¬ê°€ì¹˜","ê°€ì¹˜","ì›ì¹™","mission","vision","values","principle"]):
                out["vision"].append(t)
    for k in out:
        uniq=[]; s=set()
        for x in out[k]:
            x=x.strip()
            if x and x not in s:
                s.add(x); uniq.append(x[:200])
        out[k]=uniq[:12]
    return out

def _load_naver_keys():
    cid = os.getenv("NAVER_CLIENT_ID")
    csec = os.getenv("NAVER_CLIENT_SECRET")
    try:
        if hasattr(st, "secrets"):
            cid = cid or st.secrets.get("NAVER_CLIENT_ID", None)
            csec = csec or st.secrets.get("NAVER_CLIENT_SECRET", None)
    except Exception:
        pass
    return cid, csec

def naver_search_news(company: str, display: int = 5) -> List[Dict]:
    cid, csec = _load_naver_keys()
    if not (cid and csec): return []
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}
    try:
        r = requests.get(url, headers=headers, params={"query": company, "display": display, "sort":"date"}, timeout=8)
        if r.status_code != 200: return []
        js=r.json()
        items=[]
        for it in js.get("items", []):
            title = re.sub(r"</?b>|&quot;|&apos;|&amp;|&lt;|&gt;", "", it.get("title","")).strip()
            items.append({"title": title, "link": it.get("link"), "pubDate": it.get("pubDate")})
        return items
    except Exception:
        return []

def google_news_rss(company: str, max_items: int = 5) -> List[Dict]:
    q = urllib.parse.quote(company)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR:ko"
    try:
        r = requests.get(url, timeout=8)
        if r.status_code != 200: return []
        soup = BeautifulSoup(r.text, "xml")
        out=[]
        for it in soup.find_all("item")[:max_items]:
            out.append({"title": (it.title.get_text() if it.title else "").strip(),
                        "link": (it.link.get_text() if it.link else "").strip(),
                        "pubDate": (it.pubDate.get_text() if it.pubDate else "").strip()})
        return out
    except Exception:
        return []

@st.cache_data(show_spinner=False, ttl=1200)
def fetch_latest_news(company: str, max_items: int = 5) -> List[Dict]:
    items = naver_search_news(company, display=max_items)
    if items: return items
    return google_news_rss(company, max_items=max_items)

# ================== ì„¸ì…˜ ìƒíƒœ ==================
def _init_state():
    for k, v in {"clean_struct": None,
                 "resume_raw": "",
                 "resume_chunks": [],
                 "resume_embeds": None,
                 "current_question": "",
                 "answer_text": "",
                 "records": [],
                 "followups": [],
                 "selected_followup": "",
                 "followup_answer": "",
                 "last_result": None,
                 "last_followup_result": None,
                 "company_home": "",
                 "company_vision": [],
                 "company_talent": [],
                 "company_news": [],
                 "last_html": None }.items():
        if k not in st.session_state: st.session_state[k] = v
_init_state()

# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ (Selenium) ==================
st.header("1) ì±„ìš© ê³µê³  URL (Selenium ì „ìš©)")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì·¨ì—… í¬í„¸ ì‚¬ì´íŠ¸ì˜ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
st.text_input("íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL (ì„ íƒ)", key="company_home", placeholder="íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
company_name_override = st.text_input("íšŒì‚¬ëª… ìˆ˜ë™ ì…ë ¥ (ì„ íƒ)", placeholder="ì˜ˆ: ì¹´ì¹´ì˜¤í—¬ìŠ¤ì¼€ì–´")

if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ (Selenium ONLY)", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("Seleniumìœ¼ë¡œ ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
            raw, meta, html = fetch_all_text_selenium(url.strip())
            hint = extract_company_meta_from_html(html)
            st.session_state.last_html = html

        st.caption(f"ìˆ˜ì§‘ ì†ŒìŠ¤: {meta.get('source')} Â· í…ìŠ¤íŠ¸ ê¸¸ì´: {meta.get('len')}")
        if not raw:
            st.error("ì›ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨(ë¡œê·¸ì¸/ë™ì  ë Œë”ë§/ë´‡ ì°¨ë‹¨ ê°€ëŠ¥).")
        else:
            with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
                clean = llm_structurize(raw, hint, CHAT_MODEL)
            if not clean.get("preferences"):
                rb = rule_based_sections(raw)
                if rb.get("preferences"):
                    clean["preferences"] = rb["preferences"][:12]
            st.session_state.clean_struct = clean

            # ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ (ë™ì‹œ ì²˜ë¦¬ + ìºì‹œ)
            with st.spinner("íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ í™•ì¸ ì¤‘..."):
                vis = []; tal = []; news_items = []
                def _do_pages():
                    if st.session_state.company_home.strip():
                        extra = fetch_company_pages(st.session_state.company_home.strip())
                        return extra.get("vision", []), extra.get("talent", [])
                    return [], []
                def _do_news():
                    cname = (company_name_override.strip() or
                             clean.get("company_name") or
                             hint.get("company_name") or "")
                    return fetch_latest_news(cname, max_items=5) if cname else []
                with ThreadPoolExecutor(max_workers=2) as ex:
                    fut_pages = ex.submit(_do_pages)
                    fut_news  = ex.submit(_do_news)
                    try: vis, tal = fut_pages.result()
                    except Exception: pass
                    try: news_items = fut_news.result()
                    except Exception: pass

                st.session_state.company_vision = vis
                st.session_state.company_talent = tal
                st.session_state.company_news = news_items

            st.success("ì •ì œ ì™„ë£Œ!")

# ================== 2) íšŒì‚¬ ìš”ì•½ ==================
st.header("2) íšŒì‚¬ ìš”ì•½")
clean = st.session_state.clean_struct
if clean:
    st.markdown(f"**íšŒì‚¬ëª…:** {clean.get('company_name','-')}")
    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½):** {clean.get('company_intro','-')}")
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {clean.get('job_title','-')}")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("**ì£¼ìš” ì—…ë¬´**")
        for b in clean.get("responsibilities", []): st.markdown(f"- {b}")
    with c2:
        st.markdown("**ìê²© ìš”ê±´**")
        for b in clean.get("qualifications", []): st.markdown(f"- {b}")
    with c3:
        st.markdown("**ìš°ëŒ€ ì‚¬í•­**")
        prefs = clean.get("preferences", [])
        if prefs:
            for b in prefs: st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € URLì„ ì •ì œí•´ ì£¼ì„¸ìš”.")

# ================== íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ & ìµœì‹  ì´ìŠˆ (ìˆìœ¼ë©´ í‘œì‹œ) ==================
if st.session_state.company_vision or st.session_state.company_talent or st.session_state.company_news:
    st.divider()
    st.subheader("íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ & ìµœì‹  ì´ìŠˆ")
    colv, colt = st.columns(2)
    with colv:
        st.markdown("**ë¹„ì „/í•µì‹¬ê°€ì¹˜ (ìŠ¤í¬ë˜í•‘)**")
        for v in st.session_state.company_vision[:8]:
            st.markdown(f"- {v}")
        if not st.session_state.company_vision:
            st.caption("ë¹„ì „/í•µì‹¬ê°€ì¹˜ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    with colt:
        st.markdown("**ì¸ì¬ìƒ (ìŠ¤í¬ë˜í•‘)**")
        for t in st.session_state.company_talent[:8]:
            st.markdown(f"- {t}")
        if not st.session_state.company_talent:
            st.caption("ì¸ì¬ìƒ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    if st.session_state.company_news:
        st.markdown("**ìµœì‹  ë‰´ìŠ¤(ìƒìœ„ 3~5ê±´)**")
        for n in st.session_state.company_news[:5]:
            st.markdown(f"- [{n.get('title','(ì œëª© ì—†ìŒ)')}]({n.get('link','#')})")

st.divider()

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploads = st.file_uploader("ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ ê°€ëŠ¥", type=["pdf","txt","md","docx"], accept_multiple_files=True)
_RESUME_CHUNK = 500
_RESUME_OVLP  = 100

if st.button("ì´ë ¥ì„œ ì¸ë±ì‹±", type="secondary"):
    if not uploads:
        st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        all_text=[]
        for up in uploads:
            t = read_file_text(up)
            if t: all_text.append(t)
        resume_text = "\n\n".join(all_text)
        if not resume_text.strip():
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            chunks = chunk(resume_text, size=_RESUME_CHUNK, overlap=_RESUME_OVLP)
            with st.spinner("ì´ë ¥ì„œ ë²¡í„°í™” ì¤‘..."):
                embeds = embed_texts(chunks, EMBED_MODEL)
            st.session_state.resume_raw = resume_text
            st.session_state.resume_chunks = chunks
            st.session_state.resume_embeds = embeds
            st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)")

st.divider()

# ================== 4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„± ==================
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“±")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    enrich = {"vision": st.session_state.company_vision[:6],
              "talent": st.session_state.company_talent[:6],
              "news": [n.get("title","") for n in st.session_state.company_news[:3]]}
    company = json.dumps({"clean":clean_struct, "extra":enrich}, ensure_ascii=False)
    resume_snippet = resume_text.strip()
    if len(resume_snippet) > 9000: resume_snippet = resume_snippet[:9000]
    system = ("ë„ˆëŠ” í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì „ë¬¸ê°€ë‹¤. ì±„ìš© ê³µê³ ì˜ íšŒì‚¬/ì§ë¬´ ìš”ê±´ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•´ "
              "íšŒì‚¬ íŠ¹í™” ìì†Œì„œë¥¼ ì‘ì„±í•œë‹¤. ê³¼ì¥/í—ˆìœ„ ê¸ˆì§€, ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ì„íŒ©íŠ¸ ì¤‘ì‹¬.")
    req = (f"íšŒì‚¬ ì¸¡ ìš”ì²­ ì£¼ì œëŠ” '{topic_hint.strip()}' ì´ë‹¤. ì´ ì£¼ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•˜ë¼."
           if topic_hint and topic_hint.strip()
           else "íŠ¹ì • ì£¼ì œ ìš”ì²­ì´ ì—†ìœ¼ë¯€ë¡œ ì±„ìš©ìš”ê±´ê³¼ ë¹„ì „/ì¸ì¬ìƒì˜ ì •í•©ì„±ì„ ê°•ì¡°í•˜ë¼.")
    user = (f"[íšŒì‚¬/ì§ë¬´ ìš”ì•½(JSON)]\n{company}\n\n"
            f"[í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½ ê°€ëŠ¥)]\n{resume_snippet}\n\n"
            f"[ì‘ì„± ì§€ì‹œ]\n- {req}\n- ë¶„ëŸ‰ 600~900ì\n"
            "- êµ¬ì„±: ì§€ì›ë™ê¸°â†’ì—­ëŸ‰/ê²½í—˜â†’ì„±ê³¼/ì§€í‘œâ†’ì…ì‚¬ í›„ ê¸°ì—¬â†’ë§ˆë¬´ë¦¬\n"
            "- ì¤‘ë³µ/ë¯¸ì‚¬ì—¬êµ¬ ì œê±°, ìì—°ìŠ¤ëŸ¬ìš´ 1ì¸ì¹­.")
    try:
        resp = client.chat.completions.create(model=model, temperature=0.4,
                                              messages=[{"role":"system","content":system},{"role":"user","content":user}])
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(ìì†Œì„œ ìƒì„± ì‹¤íŒ¨: {e})"

if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
    elif not st.session_state.resume_raw.strip():
        st.warning("ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  'ì´ë ¥ì„œ ì¸ë±ì‹±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cover = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_raw, topic, CHAT_MODEL)
        st.subheader("ìì†Œì„œ (ìƒì„± ê²°ê³¼)")
        st.write(cover)
        st.download_button("ìì†Œì„œ TXT ë‹¤ìš´ë¡œë“œ", data=cover.encode("utf-8"),
                           file_name="cover_letter.txt", mime="text/plain")

st.divider()

# ================== 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©) ==================
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

cols_q = st.columns(2)
with cols_q[0]:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct:
            st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
        else:
            def retrieve_resume_chunks_local(query: str, k: int = 4):
                chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
                if not chs or embs is None: return []
                qv = embed_texts([query], EMBED_MODEL)
                scores, idxs = cosine_topk(embs, qv, k=k)
                return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

            hits = retrieve_resume_chunks_local("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", k=4)
            resume_snips = [t for _, t in hits]
            resume_context = "\n".join([f"- {s[:350]}" for s in resume_snips])[:1200]
            ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
            user_msg = {"role": "user",
                        "content": (f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
                                    f"[ì§€ì›ì ì´ë ¥ì„œ ìš”ì•½(ë°œì·Œ)]\n{resume_context}\n\n"
                                    f"[ìš”ì²­]\n- ë‚œì´ë„/ì—°ì°¨: {level}\n"
                                    f"- ì¤‘ë³µ ì§€ì–‘, íšŒì‚¬ ìš”ê±´ê³¼ ì´ë ¥ì„œ êµì§‘í•© ë° ê³µë°±ì˜ì—­ ê²¨ëƒ¥\n"
                                    f"- í•œêµ­ì–´ ë©´ì ‘ ì§ˆë¬¸ 1ê°œë§Œ í•œ ì¤„ë¡œ ì¶œë ¥")}
            try:
                resp = client.chat.completions.create(model=CHAT_MODEL, temperature=0.85,
                                                      messages=[{"role":"system","content":"ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°"}, user_msg])
                q = resp.choices[0].message.content.strip()
                q = re.sub(r"^\s*\d+[\).\s-]*","", q).split("\n")[0].strip()
            except Exception:
                q = ""
            if q:
                st.session_state.current_question = q
                st.session_state.answer_text = ""
                st.session_state.last_result = None
                st.session_state.followups = []
                st.session_state.selected_followup = ""
                st.session_state.followup_answer = ""
                st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
with cols_q[1]:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        else:
            hits = retrieve_resume_chunks(st.session_state.current_question, k=4)
            resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
            ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
            user_msg = {"role": "user",
                        "content": (f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
                                    f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
                                    f"[ë©´ì ‘ ì§ˆë¬¸]\n{st.session_state.current_question}\n\n"
                                    "ìœ„ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ STAR ê¸°ë°˜ í•œêµ­ì–´ ë‹µë³€ **ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì¤˜.")}
            try:
                resp = client.chat.completions.create(model=CHAT_MODEL, temperature=0.5,
                                                      messages=[{"role":"system","content":"ë©´ì ‘ ë‹µë³€ ì½”ì¹˜"}, user_msg])
                draft = resp.choices[0].message.content.strip()
            except Exception:
                draft = ""
            if draft:
                st.session_state.answer_text = draft
                st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# ================== 6) ì±„ì  & ì½”ì¹­ ==================
st.header("6) ì±„ì  & ì½”ì¹­")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
        hits = retrieve_resume_chunks(st.session_state.current_question + "\n" + st.session_state.answer_text[:800], k=4)
        resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
        user_msg = {"role":"user",
                    "content": (f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
                                f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
                                f"[ë©´ì ‘ ì§ˆë¬¸]\n{st.session_state.current_question}\n\n"
                                f"[ì§€ì›ì ë‹µë³€]\n{st.session_state.answer_text}\n\n"
                                "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
                                "{"
                                "\"overall_score\": 0~100 ì •ìˆ˜,"
                                "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
                                "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
                                "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
                                "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
                                "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
                                "\"strengths\": [\"...\", \"...\"],"
                                "\"risks\": [\"...\", \"...\"],"
                                "\"improvements\": [\"...\", \"...\", \"...\"],"
                                "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
                                "}") }
        try:
            resp = client.chat.completions.create(model=CHAT_MODEL, temperature=0.2,
                                                  response_format={"type":"json_object"},
                                                  messages=[{"role":"system","content":"ì—„ê²© ì±„ì ê´€"}, user_msg])
            data = json.loads(resp.choices[0].message.content)
            crit_names = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]
            fixed=[]
            for name in crit_names:
                cand=None
                for it in data.get("criteria", []):
                    if str(it.get("name","")).strip()==name:
                        cand=it; break
                if not cand: cand={"name":name,"score":0,"comment":""}
                sc=int(cand.get("score",0)); sc=max(0,min(20,sc))
                cand["score"]=sc; cand["comment"]=str(cand.get("comment","")).strip()
                fixed.append(cand)
            total=sum(x["score"] for x in fixed)
            data["criteria"]=fixed; data["overall_score"]=total
        except Exception as e:
            data = {"overall_score":0,"criteria":[], "strengths":[], "risks":[], "improvements":[], "revised_answer":"", "error":str(e)}
        st.session_state.last_result = data
        st.success("ì±„ì /ì½”ì¹­ ì™„ë£Œ!")

st.divider()
st.subheader("í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.last_result
if last:
    st.metric("ì´ì (/100)", last.get("overall_score", 0))
    st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜ & ì½”ë©˜íŠ¸**")
    for it in last.get("criteria", []):
        st.markdown(f"- **{it.get('name','')}**: {it.get('score',0)}/20 â€” {it.get('comment','')}")
    if last.get("strengths"):
        st.markdown("**ê°•ì **"); 
        for s in last["strengths"]: st.markdown(f"- {s}")
    if last.get("risks"):
        st.markdown("**ê°ì  ìš”ì¸/ë¦¬ìŠ¤í¬**"); 
        for r in last["risks"]: st.markdown(f"- {r}")
    if last.get("improvements"):
        st.markdown("**ê°œì„  í¬ì¸íŠ¸**"); 
        for im in last["improvements"]: st.markdown(f"- {im}")
    if last.get("revised_answer"):
        st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR)**"); 
        st.write(last["revised_answer"])
else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# ================== 7) íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°± ==================
st.subheader("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")
if last and not st.session_state.get("followups"):
    try:
        ctx = json.dumps({"company": st.session_state.clean_struct,
                          "vision": st.session_state.company_vision[:6],
                          "talent": st.session_state.company_talent[:6],
                          "news": [n.get("title","") for n in st.session_state.company_news[:3]]}, ensure_ascii=False)
        msg = {"role":"user",
               "content":(f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´/ë¹„ì „/ì´ìŠˆ]\n{ctx}\n\n"
                          f"[ì§€ì›ì ë‹µë³€]\n{st.session_state.answer_text}\n\n"
                          "ë©´ì ‘ê´€ ê´€ì ì—ì„œ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ í•œ ì¤„ì”© í•œêµ­ì–´ë¡œ ì œì•ˆí•´ì¤˜. "
                          "ê¸°ì¡´ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šê²Œ, ì§€í‘œ/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„/ì˜ì‚¬ê²°ì • ê·¼ê±°ë¥¼ ì„ì–´ì¤˜.")}
        r = client.chat.completions.create(model=CHAT_MODEL, temperature=0.7,
                                           messages=[{"role":"system","content":"ë©´ì ‘ íŒ”ë¡œì—… ìƒì„±ê¸°"}, msg])
        followups = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip()
                     for l in r.choices[0].message.content.splitlines() if l.strip()]
        st.session_state.followups = followups[:3]
    except Exception:
        st.session_state.followups = []

if last:
    if st.session_state.followups:
        st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
        for i, f in enumerate(st.session_state.followups, 1):
            st.markdown(f"- ({i}) {f}")
        st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0, key="selected_followup")
        st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")
        if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
            fu_q   = st.session_state.get("selected_followup", "")
            fu_ans = st.session_state.get("followup_answer", "")
            if not fu_q:
                st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif not fu_ans.strip():
                st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
            else:
                ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
                hits = retrieve_resume_chunks(fu_q + "\n" + fu_ans[:800], k=4)
                resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
                user_msg = {"role":"user",
                            "content": (f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
                                        f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
                                        f"[ë©´ì ‘ ì§ˆë¬¸]\n{fu_q}\n\n"
                                        f"[ì§€ì›ì ë‹µë³€]\n{fu_ans}\n\n"
                                        "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
                                        "{"
                                        "\"overall_score\": 0~100 ì •ìˆ˜,"
                                        "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
                                        "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
                                        "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
                                        "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
                                        "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
                                        "\"strengths\": [\"...\"],\"risks\": [\"...\"],\"improvements\": [\"...\"],"
                                        "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
                                        "}") }
                try:
                    r2 = client.chat.completions.create(model=CHAT_MODEL, temperature=0.2,
                                                        response_format={"type":"json_object"},
                                                        messages=[{"role":"system","content":"ì—„ê²© ì±„ì ê´€"}, user_msg])
                    res_fu = json.loads(r2.choices[0].message.content)
                except Exception as e:
                    res_fu = {"overall_score":0,"criteria":[], "revised_answer":"", "error":str(e)}
                st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
                st.metric("ì´ì (/100)", res_fu.get("overall_score", 0))
                for it in res_fu.get("criteria", []):
                    st.markdown(f"- **{it.get('name','')}**: {it.get('score',0)}/20 â€” {it.get('comment','')}")
                if res_fu.get("revised_answer",""):
                    st.markdown("**íŒ”ë¡œì—… ìˆ˜ì •ë³¸ (STAR)**")
                    st.write(res_fu["revised_answer"])
    else:
        st.caption("íŒ”ë¡œì—… ì§ˆë¬¸ì€ ë©”ì¸ ì§ˆë¬¸ ì±„ì  ì§í›„ ìë™ ì œì•ˆë©ë‹ˆë‹¤.")
