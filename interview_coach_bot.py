# interview_coach_app.py
import os, io, re, json, textwrap, urllib.parse, difflib, random, time, tempfile
from typing import List, Dict, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st

# ============== Optional deps ==============
try:
    import pypdf
except Exception:
    pypdf = None

try:
    import plotly.graph_objects as go
    PLOTLY_OK = True
except Exception:
    PLOTLY_OK = False

try:
    import docx2txt
    DOCX_OK = True
except Exception:
    DOCX_OK = False

try:
    from bs4 import BeautifulSoup
except Exception:
    st.error("beautifulsoup4ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— beautifulsoup4ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

try:
    import requests
except Exception:
    st.error("requestsê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— requestsë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ============== OpenAI SDK (>=1.x) ==============
try:
    from openai import OpenAI
except Exception:
    st.error("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ============== Page config ==============
st.set_page_config(page_title="íšŒì‚¬ íŠ¹í™” ê°€ìƒ ë©´ì ‘ ì½”ì¹˜", page_icon="ğŸ¯", layout="wide")

# ============== Helpers ==============
def _clean_text(t: str) -> str:
    return re.sub(r"\s+", " ", t or "").strip()

def _snippetize(text: str, maxlen: int = 220) -> str:
    t = _clean_text(text)
    return t if len(t) <= maxlen else t[: maxlen - 1] + "â€¦"

def chunk_text(text: str, size: int = 900, overlap: int = 150):
    text = re.sub(r"\s+", " ", text).strip()
    if not text: return []
    out, start = [], 0
    while start < len(text):
        end = min(len(text), start + size)
        out.append(text[start:end])
        if end == len(text): break
        start = max(0, end - overlap)
    return out

def _domain(u: str|None) -> str|None:
    if not u: return None
    try:
        if not u.startswith("http"): u = "https://" + u
        return urllib.parse.urlparse(u).netloc.lower().replace("www.","")
    except Exception:
        return None

# ============== Secrets / API Key ==============
def _secrets_file_exists() -> bool:
    candidates = [
        os.path.join(os.path.expanduser("~"), ".streamlit", "secrets.toml"),
        os.path.join(os.getcwd(), ".streamlit", "secrets.toml"),
    ]
    return any(os.path.exists(p) for p in candidates)

def load_api_key_from_env_or_secrets() -> Optional[str]:
    key = os.getenv("OPENAI_API_KEY")
    if key: return key
    try:
        if _secrets_file_exists() or hasattr(st, "secrets"):
            return st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        pass
    return None

# ============== File readers (.txt/.md/.pdf/.docx) ==============
def read_file_to_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt", ".md")):
        for enc in ("utf-8", "cp949", "euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        if pypdf is None:
            st.warning("pypdfê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— pypdf ì¶”ê°€.")
            return ""
        try:
            reader = pypdf.PdfReader(io.BytesIO(data))
            return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
        except Exception as e:
            st.warning(f"PDF íŒŒì‹± ì‹¤íŒ¨({uploaded.name}): {e}")
            return ""
    elif name.endswith(".docx"):
        if not DOCX_OK:
            st.warning("docx2txtê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— docx2txt ì¶”ê°€.")
            return ""
        tmp = None
        try:
            with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tf:
                tf.write(data); tmp = tf.name
            return docx2txt.process(tmp) or ""
        except Exception as e:
            st.warning(f"DOCX íŒŒì‹± ì‹¤íŒ¨({uploaded.name}): {e}")
            return ""
        finally:
            if tmp:
                try: os.remove(tmp)
                except Exception: pass
    return ""

# ============== OpenAI client ==============
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    API_KEY = load_api_key_from_env_or_secrets()
    if not API_KEY:
        st.info("í™˜ê²½ë³€ìˆ˜/Secretsì—ì„œ í‚¤ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì— ì…ë ¥ í›„ ì—”í„°.")
        API_KEY = st.text_input("OPENAI_API_KEY", type="password")
    MODEL = st.selectbox("ì±— ëª¨ë¸", ["gpt-4o-mini","gpt-4o","gpt-4.1-mini"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small","text-embedding-3-large"], index=0)

    _openai_ver = None; _httpx_ver = None
    try:
        import openai as _openai_pkg; _openai_ver = getattr(_openai_pkg, "__version__", None)
    except Exception: pass
    try:
        import httpx as _httpx_pkg; _httpx_ver = getattr(_httpx_pkg, "__version__", None)
    except Exception: pass
    with st.expander("ë””ë²„ê·¸: ì‹œí¬ë¦¿/ë²„ì „ ìƒíƒœ"):
        st.write({
            "api_key_provided": bool(API_KEY),
            "openai_version": _openai_ver,
            "httpx_version": _httpx_ver,
        })

if not API_KEY:
    st.error("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()
try:
    client = OpenAI(api_key=API_KEY, timeout=30.0)
except Exception as e:
    st.error(f"OpenAI ì´ˆê¸°í™” ì˜¤ë¥˜: {e}"); st.stop()

# ============== Job posting parsing (HTML + LLM fallback) ==============
SECTION_KEYS = {
    "resp": ["ì£¼ìš” ì—…ë¬´","ë‹´ë‹¹ ì—…ë¬´","ì—…ë¬´","Responsibilities","What you will do","Role"],
    "qual": ["ìê²© ìš”ê±´","ì§€ì› ìê²©","Requirements","Qualifications","Must have"],
    "pref": ["ìš°ëŒ€ ì‚¬í•­","ìš°ëŒ€ì¡°ê±´","Preferred","Nice to have","Plus","ìš°ëŒ€"]
}

def _extract_json_ld_job(soup: BeautifulSoup) -> Optional[dict]:
    for s in soup.find_all("script", type="application/ld+json"):
        try:
            data = json.loads(s.string or "")
            seq = data if isinstance(data, list) else [data]
            for obj in seq:
                typ = obj.get("@type") if isinstance(obj, dict) else None
                if (isinstance(typ, list) and "JobPosting" in typ) or typ == "JobPosting":
                    return obj
        except Exception:
            continue
    return None

def pick_section(sections: Dict[str, str], keys: List[str]) -> Optional[str]:
    for head, body in sections.items():
        if any(kk.lower() in head.lower() for kk in keys):
            return body
    return None

def _split_bullets(txt: str) -> list:
    bullets = re.split(r"[â€¢\-\nâ€¢Â·â–ªï¸â–¶ï¸â—â– â–¡â—†â—‡\r]+", txt)
    return [ _clean_text(b) for b in bullets if len(_clean_text(b)) > 2 ]

def llm_split_jobtext(raw_text: str, client, model: str) -> dict:
    """ì›ë¬¸(raw_text)ì„ 3ì„¹ì…˜ìœ¼ë¡œ ì •ì œ: responsibilities / qualifications / preferred."""
    if not raw_text.strip():
        return {"responsibilities": [], "qualifications": [], "preferred": []}
    sys = ("ë„ˆëŠ” ì±„ìš©ê³µê³  ì •ë¦¬ ë„ìš°ë¯¸ë‹¤. í•œêµ­ì–´ ë¶ˆë¦¿ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ë‚˜ëˆ ì¤˜. "
           "ì¶œë ¥ì€ JSONìœ¼ë¡œë§Œ, í‚¤ëŠ” responsibilities/qualifications/preferred, ê°’ì€ ë¬¸ìì—´ ë°°ì—´. "
           "ì›ë¬¸ì— ì„¹ì…˜ ì´ë¦„ì´ ì—†ì–´ë„ ì˜ë¯¸ë¡œ ë¶„ë¥˜í•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ë‚¨ê²¨.")
    user = f"[ì±„ìš©ê³µê³  ì›ë¬¸]\n{raw_text}"
    try:
        r = client.chat.completions.create(
            model=model, temperature=0.0,
            messages=[{"role":"system","content":sys},{"role":"user","content":user}]
        )
        js = json.loads(r.choices[0].message.content)
        def _norm(lst):
            return [re.sub(r"\s+", " ", x).strip() for x in (lst or []) if len(re.sub(r'\s+',' ',x).strip())>1][:12]
        return {
            "responsibilities": _norm(js.get("responsibilities")),
            "qualifications":   _norm(js.get("qualifications")),
            "preferred":        _norm(js.get("preferred")),
        }
    except Exception:
        return {"responsibilities": [], "qualifications": [], "preferred": []}

def parse_job_posting(url: str) -> dict:
    out = {"title": None, "responsibilities": [], "qualifications": [], "preferred": [], "company_intro": None}
    try:
        r = requests.get(url, timeout=12, headers={"User-Agent":"Mozilla/5.0"})
        if r.status_code != 200 or "text/html" not in r.headers.get("content-type",""): return out
        soup = BeautifulSoup(r.text, "html.parser")

        # Title/meta
        jp = _extract_json_ld_job(soup)
        if jp:
            out["title"] = jp.get("title")
            desc = _clean_text(jp.get("description", ""))
            if desc:
                b = _split_bullets(desc)
                # ë‹¨ìˆœ ë¶„ë¥˜
                for x in b:
                    low = x.lower()
                    if any(k in low for k in ["ìê²©","ìš”ê±´","requirements","qualification","í•„ìˆ˜"]):
                        out["qualifications"].append(x)
                    elif any(k in low for k in ["ìš°ëŒ€","preferred","nice to have","plus"]):
                        out["preferred"].append(x)
                    else:
                        out["responsibilities"].append(x)

        # Headings scan
        sections = {}
        for h in soup.find_all(re.compile("^h[1-4]$")):
            head = _clean_text(h.get_text())
            if not head: continue
            nxt=[]; sib=h.find_next_sibling(); stop={"h1","h2","h3","h4"}
            while sib and sib.name not in stop:
                if sib.name in {"p","li","ul","ol","div"}:
                    txt=_clean_text(sib.get_text(" "))
                    if len(txt)>5: nxt.append(txt)
                sib=sib.find_next_sibling()
            if nxt: sections[head]=" ".join(nxt)

        resp = pick_section(sections, SECTION_KEYS["resp"])
        qual = pick_section(sections, SECTION_KEYS["qual"])
        pref = pick_section(sections, SECTION_KEYS["pref"])

        if resp and not out["responsibilities"]:
            out["responsibilities"]=_split_bullets(resp)[:12]
        if qual and not out["qualifications"]:
            out["qualifications"]=_split_bullets(qual)[:12]
        if pref and not out["preferred"]:
            out["preferred"]=_split_bullets(pref)[:12]

        meta_desc = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
        if meta_desc and meta_desc.get("content"): out["company_intro"]=_snippetize(meta_desc["content"], 220)

        # ---------- LLM í´ë°± (ëˆ„ë½ ë³´ì™„) ----------
        if (not out["responsibilities"]) or (not out["qualifications"]) or (not out["preferred"]):
            full_text = _clean_text(soup.get_text(" "))
            split = llm_split_jobtext(full_text, client, MODEL)
            if not out["responsibilities"]: out["responsibilities"] = split["responsibilities"]
            if not out["qualifications"]:   out["qualifications"]   = split["qualifications"]
            if not out["preferred"]:        out["preferred"]        = split["preferred"]

        # ìµœì¢… ë‹¤ë“¬ê¸°
        out["responsibilities"] = [_snippetize(x, 140) for x in out["responsibilities"]][:12]
        out["qualifications"]   = [_snippetize(x, 140) for x in out["qualifications"]][:12]
        out["preferred"]        = [_snippetize(x, 140) for x in out["preferred"]][:12]
        return out

    except Exception:
        return out

# ============== Embedding / RAG (ê°„ë‹¨) ==============
def embed_texts(client: OpenAI, embed_model: str, texts: list[str]) -> np.ndarray:
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=embed_model, input=texts)
    return np.array([d.embedding for d in resp.data], dtype=np.float32)

def cosine_topk(matrix: np.ndarray, query: np.ndarray, k: int = 4):
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    qn = query / (np.linalg.norm(query, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

# ============== Session init ==============
if "company" not in st.session_state:
    st.session_state.company = {
        "company_name": "(íšŒì‚¬ëª… ë¯¸ì„¤ì •)", "homepage": None, "values": [], "recent_projects": [],
        "company_intro_site": None, "role": "", "role_requirements": [], "role_qualifications": [],
        "role_preferred": [], "job_url": None, "news": []
    }
if "rag_store" not in st.session_state:
    st.session_state.rag_store = {"chunks": [], "embeds": None}
if "history" not in st.session_state:
    st.session_state.history = []
if "current_question" not in st.session_state:
    st.session_state.current_question = ""
if "answer_text" not in st.session_state:
    st.session_state.answer_text = ""

# ============== â‘  íšŒì‚¬/ì§ë¬´ ì…ë ¥ & ê³µê³  ì •ì œ ==============
st.subheader("â‘  ì±„ìš© ê³µê³  URL â†’ ì •ì œ")
job_url_input = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="https://...wanted.../wd/12345")
col_btn, col_blank = st.columns([1,5])
with col_btn:
    fetch_clicked = st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary", use_container_width=True)
if fetch_clicked:
    if not job_url_input.strip():
        st.warning("ì±„ìš© ê³µê³  URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì±„ìš© ê³µê³ ë¥¼ ìˆ˜ì§‘/ì •ì œ ì¤‘..."):
            parsed = parse_job_posting(job_url_input.strip())
            # íšŒì‚¬ ìƒíƒœ ê°±ì‹  (íšŒì‚¬ëª…/ì§ë¬´ëŠ” URLë§Œìœ¼ë¡œ ì•Œê¸° ì–´ë ¤ìš°ë¯€ë¡œ ì•„ë˜ UIì—ì„œ ë³„ë„ ì…ë ¥ ê°€ëŠ¥)
            st.session_state.company.update({
                "job_url": job_url_input.strip(),
                "role_requirements": parsed.get("responsibilities", []),
                "role_qualifications": parsed.get("qualifications", []),
                "role_preferred": parsed.get("preferred", []),
                "company_intro_site": parsed.get("company_intro"),
            })
        st.success("ì •ì œ ì™„ë£Œ!")

# íšŒì‚¬ëª…/ì§ë¬´ëª… ìˆ˜ë™ ì…ë ¥(ë˜ëŠ” ë‰´ìŠ¤/RAGì—ì„œ ì‚¬ìš©)
with st.expander("íšŒì‚¬ëª…/ì§ë¬´ëª… ì…ë ¥(ì„ íƒ)"):
    st.session_state.company["company_name"] = st.text_input("íšŒì‚¬ëª…", value=st.session_state.company.get("company_name",""))
    st.session_state.company["role"] = st.text_input("ì§ë¬´ëª…", value=st.session_state.company.get("role",""))

# ============== â‘¡ íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼ í‘œì‹œ) ==============
st.subheader("â‘¡ íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")
c = st.session_state.company
cols = st.columns(3)
with cols[0]:
    st.markdown(f"**íšŒì‚¬ëª…:** {c.get('company_name')}")
with cols[1]:
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {c.get('role') or 'N/A'}")
with cols[2]:
    if c.get("job_url"): st.link_button("ì±„ìš© ê³µê³  ì—´ê¸°", c["job_url"])

st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½)**\n\n{c.get('company_intro_site') or 'â€”'}")
st.divider()
colL, colM, colR = st.columns(3)
with colL:
    st.markdown("### ì£¼ìš” ì—…ë¬´")
    items = c.get("role_requirements", [])
    if items:
        st.markdown("\n".join([f"- {x}" for x in items]))
    else:
        st.caption("ìš”ì•½ ê°€ëŠ¥í•œ ì£¼ìš”ì—…ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.")
with colM:
    st.markdown("### ìê²© ìš”ê±´")
    items = c.get("role_qualifications", [])
    if items:
        st.markdown("\n".join([f"- {x}" for x in items]))
    else:
        st.caption("ìš”ì•½ ê°€ëŠ¥í•œ ìê²©ìš”ê±´ì´ ì—†ìŠµë‹ˆë‹¤.")
with colR:
    st.markdown("### ìš°ëŒ€ ì‚¬í•­")
    items = c.get("role_preferred", [])
    if items:
        st.markdown("\n".join([f"- {x}" for x in items]))
    else:
        st.caption("ìš”ì•½ ê°€ëŠ¥í•œ ìš°ëŒ€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

# ============== â‘¢ ì§ˆë¬¸ ìƒì„± ==============
st.subheader("â‘¢ ì§ˆë¬¸ ìƒì„±")

# ì§ˆë¬¸ ìœ í˜• ë³µì›
q_type = st.selectbox(
    "ì§ˆë¬¸ ìœ í˜•",
    ["í˜¼í•©", "í–‰ë™(STAR)", "ê¸°ìˆ  ì‹¬ì¸µ", "í•µì‹¬ê°€ì¹˜ ì í•©ì„±", "ì—­ì§ˆë¬¸"],
    index=0
)
TYPE_INSTRUCTIONS = {
    "í˜¼í•©": "í–‰ë™/ê¸°ìˆ /ê°€ì¹˜/ì—­ì§ˆë¬¸ì´ ê³ ë¥´ê²Œ ì„ì´ë˜ ì„œë¡œ í˜•íƒœÂ·ê´€ì ì´ ë‹¤ë¥´ê²Œ",
    "í–‰ë™(STAR)": "ê³¼ê±° ì‹¤ë¬´ ì‚¬ë¡€ë¥¼ ëŒì–´ë‚´ë„ë¡ S(ìƒí™©)-T(ê³¼ì œ)-A(í–‰ë™)-R(ì„±ê³¼)ë¥¼ ìœ ë„",
    "ê¸°ìˆ  ì‹¬ì¸µ": "í•µì‹¬ ê¸°ìˆ ì  ì˜ì‚¬ê²°ì •Â·íŠ¸ë ˆì´ë“œì˜¤í”„Â·ì„±ëŠ¥/ë¹„ìš©/í’ˆì§ˆ ì§€í‘œë¥¼ íŒŒê³ ë“œëŠ” ì‹¬ì¸µ",
    "í•µì‹¬ê°€ì¹˜ ì í•©ì„±": "í•µì‹¬ê°€ì¹˜ì™€ íƒœë„ë¥¼ ê²€ì¦í•˜ëŠ” ìƒí™©ê¸°ë°˜ í–‰ë™ ì§ˆë¬¸",
    "ì—­ì§ˆë¬¸": "ì§€ì›ìê°€ íšŒì‚¬ë¥¼ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ í†µì°°ë ¥ ìˆëŠ” ì—­ì§ˆë¬¸"
}
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"])
hint   = st.text_input("ì§ˆë¬¸ ìƒì„± íŒíŠ¸(ì„ íƒ)", placeholder="ì˜ˆ: í¼ë„ ì „í™˜/ ì„±ëŠ¥-ë¹„ìš© íŠ¸ë ˆì´ë“œì˜¤í”„ / í’ˆì§ˆ ì§€í‘œ")

def build_ctx(company: dict) -> str:
    return textwrap.dedent(f"""
    [íšŒì‚¬ëª…] {company.get('company_name','')}
    [ëª¨ì§‘ ë¶„ì•¼] {company.get('role','')}
    [ì£¼ìš” ì—…ë¬´] {", ".join(company.get('role_requirements', [])[:6])}
    [ìê²© ìš”ê±´] {", ".join(company.get('role_qualifications', [])[:6])}
    [ìš°ëŒ€ ì‚¬í•­] {", ".join(company.get('role_preferred', [])[:6])}
    """).strip()

def _similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, a, b).ratio()

def pick_diverse(cands: list[str], hist: list[str], gamma: float = 0.35) -> str:
    if not cands: return ""
    if not hist:  return random.choice(cands)
    best=None; best_score=1e9
    for q in cands:
        sims=[_similarity(q,h) for h in hist] or [0.0]
        score=(sum(sims)/len(sims)) + gamma*np.std(sims)
        if score < best_score:
            best_score=score; best=q
    return best

if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary", use_container_width=True):
    st.session_state.answer_text = ""  # ì´ì „ ë‹µë³€ ì´ˆê¸°í™”
    try:
        ctx = build_ctx(st.session_state.company)
        sys = f"""ë„ˆëŠ” '{c.get('company_name','')}'ì˜ '{c.get('role','')}' ë©´ì ‘ê´€ì´ë‹¤.
íšŒì‚¬/ì§ë¬´ ì»¨í…ìŠ¤íŠ¸ì™€ ì±„ìš©ê³µê³ (ì£¼ìš”ì—…ë¬´/ìê²©/ìš°ëŒ€)ë¥¼ ë°˜ì˜í•˜ì—¬ **{q_type}** ìœ í˜•({TYPE_INSTRUCTIONS[q_type]})ì˜ í•œêµ­ì–´ ì§ˆë¬¸ **6ê°œ í›„ë³´**ë¥¼ ìƒì„±í•˜ë¼.
ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ë‹¬ë¼ì•¼ í•˜ë©° ë‚œì´ë„ëŠ” {level}.
ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬ ìš”ì†Œë¥¼ ì ì ˆíˆ ì„ì–´ë¼.
í¬ë§·: 1) ... 2) ... 3) ... (í•œ ì¤„ì”©)"""
        user = f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n[íŒíŠ¸]\n{hint or 'ì—†ìŒ'}"
        resp = client.chat.completions.create(
            model=MODEL, temperature=0.8,
            messages=[{"role":"system","content":sys},{"role":"user","content":user}]
        )
        raw = resp.choices[0].message.content.strip()
        cands = [re.sub(r'^\s*\d+\)\s*','',line).strip() for line in raw.splitlines() if re.match(r'^\s*\d+\)', line)]
        if not cands:
            cands = [l.strip("- ").strip() for l in raw.splitlines() if len(l.strip())>0][:6]
        hist_qs = [h["question"] for h in st.session_state.get("history", [])][-10:]
        selected = pick_diverse(cands, hist_qs)
        st.session_state.current_question = selected or (cands[0] if cands else "ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")

st.text_area("ì§ˆë¬¸", height=110, value=st.session_state.get("current_question",""))

# ============== â‘£ ë‚˜ì˜ ë‹µë³€ / ì½”ì¹­(100ì ì œ) ==============
st.subheader("â‘£ ë‚˜ì˜ ë‹µë³€ / ì½”ì¹­")
ans = st.text_area("ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš” (STAR ê¶Œì¥: ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)", height=180, key="answer_text")

def coach_answer(company: dict, question: str, answer: str) -> dict:
    comp = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]
    ctx = build_ctx(company)
    sys = ("ë„ˆëŠ” í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. í•œêµ­ì–´ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ë‹µí•˜ë¼:\n"
           "1) ì´ì : 0~100 ì •ìˆ˜ 1ê°œ\n"
           "2) ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ): ë¬¸ì œì •ì˜/ë°ì´í„°ì§€í‘œ/ì‹¤í–‰ë ¥ì£¼ë„ì„±/í˜‘ì—…ì»¤ë®¤ë‹ˆì¼€ì´ì…˜/ê³ ê°ê°€ì¹˜\n"
           "3) ìˆ˜ì •ë³¸ ë‹µë³€: STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼) êµ¬ì¡°\n"
           "4) ì—­ëŸ‰ ì ìˆ˜(ê° 0~20 ì •ìˆ˜): [ë¬¸ì œì •ì˜, ë°ì´í„°/ì§€í‘œ, ì‹¤í–‰ë ¥/ì£¼ë„ì„±, í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ê³ ê°ê°€ì¹˜]\n"
           "í˜•ì‹/ìˆ«ì ë²”ìœ„ ì—„ìˆ˜.")
    user = f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n\n[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n[í›„ë³´ì ë‹µë³€]\n{answer}"
    r = client.chat.completions.create(model=MODEL, temperature=0.3,
                                       messages=[{"role":"system","content":sys},{"role":"user","content":user}])
    content = r.choices[0].message.content.strip()

    # ì´ì 
    score = None
    m = re.search(r'(\d{1,3})\s*(?:/100|ì |$)', content)
    if m: score = int(m.group(1))
    if score is None:
        m_any = re.search(r'\b(\d{1,3})\b', content)
        if m_any: score = max(0, min(100, int(m_any.group(1))))
    # ì—­ëŸ‰ 5ê°œ
    line = content.splitlines()[-1]
    nums = re.findall(r'\b(\d{1,2})\b', line)
    if len(nums) < 5:
        nums = re.findall(r'\b(\d{1,2})\b', content)
    comp_scores = None
    if len(nums) >= 5:
        cand = [int(x) for x in nums[:5]]
        # 5ì /10ì  ì²™ë„ ë³´ì •
        if all(0 <= x <= 5 for x in cand): cand = [x * 4 for x in cand]
        if all(0 <= x <= 10 for x in cand) and any(x > 5 for x in cand): cand = [x * 2 for x in cand]
        comp_scores = [max(0, min(20, x)) for x in cand]

    return {"raw": content, "score": score, "competencies": comp_scores}

if st.button("ì±„ì  & ì½”ì¹­", type="primary", use_container_width=True):
    if not st.session_state.get("current_question"):
        st.warning("ë¨¼ì € 'ìƒˆ ì§ˆë¬¸ ë°›ê¸°'ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì½”ì¹­ ì¤‘..."):
            res = coach_answer(st.session_state.company, st.session_state["current_question"], st.session_state.answer_text)
            st.session_state.history.append({
                "ts": pd.Timestamp.now(),
                "question": st.session_state["current_question"],
                "user_answer": st.session_state.answer_text,
                "score": res.get("score"),
                "feedback": res.get("raw"),
                "competencies": res.get("competencies")
            })

# ============== ê²°ê³¼ í‘œì‹œ ==============
st.divider()
st.subheader("í”¼ë“œë°± ê²°ê³¼")
if st.session_state.history:
    last = st.session_state.history[-1]
    c1,c2 = st.columns([1,3])
    with c1: st.metric("ì´ì (/100)", last.get("score","â€”"))
    with c2: st.markdown(last.get("feedback",""))
else:
    st.info("ì•„ì§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ============== ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì ) ==============
st.divider()
st.subheader("ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")
competencies = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def comp_df(hist):
    rows=[h["competencies"] for h in hist if h.get("competencies") and len(h["competencies"])==5]
    return pd.DataFrame(rows, columns=competencies) if rows else None

cdf = comp_df(st.session_state.history)
if cdf is not None and not cdf.empty:
    avg = cdf.mean().values.tolist()
    if PLOTLY_OK:
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=avg+[avg[0]], theta=competencies+[competencies[0]], fill='toself', name="ì„¸ì…˜ í‰ê· "
        ))
        last_row = cdf.iloc[-1].values.tolist()
        fig.add_trace(go.Scatterpolar(
            r=last_row+[last_row[0]], theta=competencies+[competencies[0]], fill='toself', name="ìµœì‹ "
        ))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,20])), showlegend=True, height=420)
        st.plotly_chart(fig, use_container_width=True)
    cdf_show = cdf.copy()
    cdf_show["í•©ê³„"] = cdf_show.sum(axis=1)
    st.dataframe(cdf_show, use_container_width=True)
else:
    st.caption("ì•„ì§ ì—­ëŸ‰ ì ìˆ˜ê°€ íŒŒì‹±ëœ ì½”ì¹­ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ============== íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°± ==============
st.divider()
st.subheader("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")

if "followup_suggestions" not in st.session_state:
    st.session_state.followup_suggestions = [
        "ë°ì´í„° ë¶„ì„ ê³¼ì •ì—ì„œ ë°œê²¬í•œ ìœ„í—˜ ìš”ì†ŒëŠ” ë¬´ì—‡ì´ì—ˆê³ , ì´ë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í–ˆë‚˜ìš”?",
        "ê³ ê° ìœ ì§€ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ì–´ë–¤ ì§€í‘œë¥¼ ìš°ì„  ê°œì„ í•˜ê² ìŠµë‹ˆê¹Œ? ì´ìœ ëŠ”?",
        "ëŒ€ì•ˆ ì¤‘ íŠ¸ë ˆì´ë“œì˜¤í”„ ì„ íƒ ê¸°ì¤€ì„ ìˆ˜ì¹˜ë¡œ ì œì‹œí•´ ë³´ì„¸ìš”."
    ]

st.selectbox("ì œì•ˆë°›ì€ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followup_suggestions, key="followup_pick")
st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", key="followup_answer", height=140)

if st.button("íŒ”ë¡œì—… ë‹µë³€ í”¼ë“œë°± ë°›ê¸°", use_container_width=True):
    fq = st.session_state.get("followup_pick", "")
    fa = st.session_state.get("followup_answer", "").strip()
    if not fq or not fa:
        st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ê³  ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        sys = ("ë„ˆëŠ” ê¹Œë‹¤ë¡œìš´ ë©´ì ‘ê´€ì´ë‹¤. ì•„ë˜ íŒ”ë¡œì—… Q&Aë¥¼ 100ì  ë§Œì ìœ¼ë¡œ ì§§ê²Œ ì±„ì í•˜ê³  "
               "ê°ì ìš”ì¸/ì•„ì‰¬ìš´ì /ê°œì„  í¬ì¸íŠ¸ë¥¼ ë¶ˆë¦¿ìœ¼ë¡œ ì œì‹œí•œ ë’¤, ë” ë‚˜ì€ ì˜ˆì‹œ ë¬¸ì¥ 3ê°œë¥¼ ì œì•ˆí•˜ë¼.")
        user = f"[íŒ”ë¡œì—… ì§ˆë¬¸]\n{fq}\n\n[í›„ë³´ì ë‹µë³€]\n{fa}"
        try:
            r = client.chat.completions.create(
                model=MODEL, temperature=0.2,
                messages=[{"role":"system","content":sys},{"role":"user","content":user}]
            )
            st.markdown(r.choices[0].message.content.strip())
        except Exception as e:
            st.error(f"íŒ”ë¡œì—… í”¼ë“œë°± ì˜¤ë¥˜: {e}")

# ============== íŒŒì¼ ì—…ë¡œë“œ(RAG ìë£Œ/ì´ë ¥ì„œ) ==============
st.divider()
st.subheader("ì´ë ¥ì„œ/íšŒì‚¬ ë¬¸ì„œ ì—…ë¡œë“œ (RAG ì†ŒìŠ¤)")
docs = st.file_uploader("PDF/TXT/MD/DOCX íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥)", type=["txt","md","pdf","docx"], accept_multiple_files=True)
if docs:
    with st.spinner("ë¬¸ì„œ ì¸ë±ì‹± ì¤‘..."):
        chunks=[]
        for up in docs:
            t = read_file_to_text(up)
            if t: chunks += chunk_text(t, 600, 120)  # ì´ë ¥ì„œ íŠ¹í™”: ë” ì´˜ì´˜íˆ
        if chunks:
            embs = embed_texts(client, EMBED_MODEL, chunks)
            st.session_state.rag_store["chunks"] += chunks
            if st.session_state.rag_store["embeds"] is None or st.session_state.rag_store["embeds"].size==0:
                st.session_state.rag_store["embeds"] = embs
            else:
                st.session_state.rag_store["embeds"] = np.vstack([st.session_state.rag_store["embeds"], embs])
            st.success(f"ì¶”ê°€ ì²­í¬ {len(chunks)}ê°œ")
