# -*- coding: utf-8 -*-
import os, re, json, urllib.parse, random, time, io
from typing import Optional, Tuple, Dict, List

import requests
from bs4 import BeautifulSoup
import html2text
import streamlit as st
import pandas as pd
import numpy as np

# ================== ê¸°ë³¸ ì„¤ì • ==================
st.set_page_config(page_title="íšŒì‚¬ ë§ì¶¤ ë©´ì ‘ ì½”ì¹˜ (Step2: ì§ˆë¬¸/RAG/íŒ”ë¡œì—…)", page_icon="ğŸ¯", layout="wide")
st.title("íšŒì‚¬ ë§ì¶¤ ë©´ì ‘ ì½”ì¹˜ Â· URL ì •ì œ â†’ ìì†Œì„œ â†’ (Step2) ì§ˆë¬¸/RAG/íŒ”ë¡œì—…/ì—„ê²© ì±„ì ")

# ================== OpenAI ==================
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

with st.sidebar:
    st.subheader("ëª¨ë¸ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸(ë‚´ë¶€ìš©)", ["text-embedding-3-small","text-embedding-3-large"], index=0)

# ================== HTTP ìœ í‹¸ ==================
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def http_get(url: str, timeout: int = 12) -> Optional[requests.Response]:
    try:
        r = requests.get(
            url,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                "Accept-Language": "ko, en;q=0.9",
            },
            timeout=timeout,
        )
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

# ================== ì›ë¬¸ ìˆ˜ì§‘ (Jina â†’ Web â†’ BS4) ==================
def fetch_jina_text(url: str, timeout: int = 15) -> str:
    try:
        parts = urllib.parse.urlsplit(url)
        prox = f"https://r.jina.ai/http://{parts.netloc}{parts.path}"
        if parts.query: prox += f"?{parts.query}"
        r = http_get(prox, timeout=timeout)
        return r.text.strip() if r else ""
    except Exception:
        return ""

def html_to_text(html_str: str) -> str:
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    txt = conv.handle(html_str)
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()

def fetch_webbase_text(url: str) -> str:
    r = http_get(url, timeout=12)
    if not r: return ""
    return html_to_text(r.text)

def fetch_bs4_text(url: str) -> Tuple[str, Optional[BeautifulSoup]]:
    r = http_get(url, timeout=12)
    if not r: return "", None
    soup = BeautifulSoup(r.text, "lxml")
    blocks = []
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True)
            if txt and len(txt) > 300:
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    if not blocks:
        return soup.get_text(" ", strip=True)[:120000], soup
    seen, out = set(), []
    for b in blocks:
        if b not in seen:
            seen.add(b); out.append(b)
    return ("\n\n".join(out)[:120000], soup)

def fetch_all_text(url: str):
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None
    jina = fetch_jina_text(url)
    if jina:
        _, soup = fetch_bs4_text(url)
        return jina, {"source":"jina","len":len(jina),"url_final":url}, soup
    web = fetch_webbase_text(url)
    if web:
        _, soup = fetch_bs4_text(url)
        return web, {"source":"webbase","len":len(web),"url_final":url}, soup
    bs, soup = fetch_bs4_text(url)
    return bs, {"source":"bs4","len":len(bs),"url_final":url}, soup

# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    cand = []
    og = soup.find("meta", {"property":"og:site_name"})
    if og and og.get("content"): cand.append(og["content"])
    app = soup.find("meta", {"name":"application-name"})
    if app and app.get("content"): cand.append(app["content"])
    if soup.title and soup.title.string: cand.append(soup.title.string)
    cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
    cand = [c for c in cand if 2 <= len(c) <= 40]
    meta["company_name"] = cand[0] if cand else ""
    md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
    if md and md.get("content"):
        meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
    jt = ""
    ogt = soup.find("meta", {"property":"og:title"})
    if ogt and ogt.get("content"): jt = ogt["content"]
    if not jt:
        h1 = soup.find("h1")
        if h1 and h1.get_text(): jt = h1.get_text(strip=True)
    if not jt:
        h2 = soup.find("h2")
        if h2 and h2.get_text(): jt = h2.get_text(strip=True)
    meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    return meta

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
PROMPT_SYSTEM_STRUCT = (
    "ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
    "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
    "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼."
)

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    ctx = raw_text.strip()
    if len(ctx) > 9000:
        ctx = ctx[:9000]

    user_msg = {
        "role": "user",
        "content": (
            "ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
            "--- ì›ë¬¸ ì‹œì‘ ---\n"
            f"{ctx}\n"
            "--- ì›ë¬¸ ë ---\n\n"
            "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
            "{"
            "\"company_name\": str, "
            "\"company_intro\": str, "
            "\"job_title\": str, "
            "\"responsibilities\": [str], "
            "\"qualifications\": [str], "
            "\"preferences\": [str]"
            "}"
        ),
    }

    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2,
            response_format={"type": "json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg],
        )
        data = json.loads(resp.choices[0].message.content)
        # í›„ì²˜ë¦¬
        for k in ["responsibilities","qualifications","preferences"]:
            if not isinstance(data.get(k, []), list):
                data[k] = []
            clean = []
            seen = set()
            for it in data[k]:
                t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·").strip()
                if t and t not in seen:
                    seen.add(t); clean.append(t)
            data[k] = clean[:12]
        for k in ["company_name","company_intro","job_title"]:
            if k in data and isinstance(data[k], str):
                data[k] = re.sub(r"\s+"," ", data[k]).strip()
        return data
    except Exception as e:
        return {
            "company_name": meta_hint.get("company_name",""),
            "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
            "job_title": meta_hint.get("job_title",""),
            "responsibilities": [],
            "qualifications": [],
            "preferences": [],
            "error": str(e),
        }

# ================== íŒŒì¼ ë¦¬ë” (PDF/TXT/MD/DOCX) ==================
try:
    import pypdf
except Exception:
    pypdf = None

def read_pdf(data: bytes) -> str:
    if pypdf is None:
        return ""
    try:
        reader = pypdf.PdfReader(io.BytesIO(data))
        return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
    except Exception:
        return ""

def read_docx(data: bytes) -> str:
    try:
        import docx2txt, tempfile
        with tempfile.NamedTemporaryFile(suffix=".docx", delete=True) as tmp:
            tmp.write(data); tmp.flush()
            text = docx2txt.process(tmp.name) or ""
            return text
    except Exception:
        return ""

def read_file_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md")):
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    return ""

# ================== ê°„ë‹¨ ì²­í¬/ì„ë² ë”©(ë‚´ë¶€: ìˆ¨ê¹€) ==================
def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    t = re.sub(r"\s+"," ", text).strip()
    if not t: return []
    out, start = [], 0
    while start < len(t):
        end = min(len(t), start+size)
        out.append(t[start:end])
        if end == len(t): break
        start = max(0, end-overlap)
    return out

def embed_texts(texts: List[str], model_name: str) -> np.ndarray:
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=model_name, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

def retrieve_resume_chunks(query: str, k: int = 4):
    chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
    if not chs or embs is None:
        return []
    qv = embed_texts([query], EMBED_MODEL)
    scores, idxs = cosine_topk(embs, qv, k=k)
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== ì§ˆë¬¸/ì´ˆì•ˆ/ì±„ì /íŒ”ë¡œì—… í”„ë¡¬í”„íŠ¸ ==================
PROMPT_SYSTEM_Q = (
    "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´, ê·¸ë¦¬ê³  ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ í•¨ê»˜ ê³ ë ¤í•´ "
    "ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. ì§ˆë¬¸ì€ ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , "
    "ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ ë“±ë„ ì„ì–´ë¼."
)

PROMPT_SYSTEM_DRAFT = (
    "ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ ê²°í•©í•´ "
    "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ **ì´ˆì•ˆ**ì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
    "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼."
)

PROMPT_SYSTEM_SCORE_STRICT = (
    "ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
    "ê° ê¸°ì¤€ì€ 0~20 ì •ìˆ˜ì´ë©°, ì´ì ì€ ê¸°ì¤€ í•©ê³„(ìµœëŒ€ 100)ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•œë‹¤. "
    "ê³¼ì¥/ëª¨í˜¸í•¨/ê·¼ê±° ë¶€ì¬/ìˆ«ì ì—†ëŠ” ì£¼ì¥/ì±…ì„ íšŒí”¼/ëª¨í˜¸í•œ ì£¼ì–´ ì‚¬ìš© ë“±ì„ ê°•í•˜ê²Œ ê°ì í•˜ë¼. "
    "ê° ê¸°ì¤€ì— ëŒ€í•´ ì§§ì§€ë§Œ êµ¬ì²´ì  ì½”ë©˜íŠ¸(ê°•ì /ê°ì ìš”ì¸/ê°œì„ í¬ì¸íŠ¸)ë¥¼ ì œê³µí•˜ë¼."
)

CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_questions_with_resume(clean: Dict, level: str, model: str, num: int = 8) -> List[str]:
    # RAGì—ì„œ ëŒ€í‘œ ìŠ¤ë‹ˆí« 3~4ê°œë§Œ ìš”ì•½í•´ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
    resume_snips = []
    hits = retrieve_resume_chunks("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", k=4)
    resume_snips = [t for _, t in hits]
    resume_context = "\n".join([f"- {s[:350]}" for s in resume_snips])[:1200]

    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {
        "role": "user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
            f"[ì§€ì›ì ì´ë ¥ì„œ ìš”ì•½(ë°œì·Œ)]\n{resume_context}\n\n"
            f"[ìš”ì²­]\n- ë‚œì´ë„/ì—°ì°¨: {level}\n"
            f"- ì´ {num}ê°œ, í•œ ì¤„ì”©, ì¤‘ë³µ/ìœ ì‚¬ë„ ìµœì†Œí™”\n"
            f"- íšŒì‚¬ ìš”ê±´ê³¼ ì´ë ¥ì„œì˜ êµì§‘í•©/ê³µë°±ì˜ì—­ì„ ëª¨ë‘ ê²¨ëƒ¥í•´ ì§ˆë¬¸ ìƒì„±"
        ),
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.9,
            messages=[{"role":"system","content":PROMPT_SYSTEM_Q}, user_msg],
        )
        txt = resp.choices[0].message.content.strip()
        lines = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip() for l in txt.splitlines() if l.strip()]
        lines = [l for l in lines if len(l.split()) > 2][:num]
        # ìµœê·¼ ì§ˆë¬¸ê³¼ì˜ ì¤‘ë³µ ê°„ë‹¨ í•„í„°
        if "q_hist" in st.session_state:
            hist = st.session_state.q_hist[-12:]
            def sim(a,b):
                a_set=set(a.lower().split()); b_set=set(b.lower().split())
                inter=len(a_set&b_set); denom=max(1,len(a_set|b_set))
                return inter/denom
            uniq=[]
            for q in lines:
                if all(sim(q,h)<0.35 for h in hist):
                    uniq.append(q)
            if uniq: lines = uniq
        return lines[:num]
    except Exception:
        return []

def llm_draft_answer(clean: Dict, question: str, model: str) -> str:
    # RAG ê·¼ê±° í¬í•¨ ì´ˆì•ˆ
    hits = retrieve_resume_chunks(question, k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]

    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {
        "role": "user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
            f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ STAR ê¸°ë°˜ í•œêµ­ì–´ ë‹µë³€ **ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì¤˜."
        )
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.5,
            messages=[{"role":"system","content":PROMPT_SYSTEM_DRAFT}, user_msg],
        )
        return resp.choices[0].message.content.strip()
    except Exception:
        return ""

def llm_score_and_coach_strict(clean: Dict, question: str, answer: str, model: str) -> Dict:
    # ë” ê¹ê¹í•œ ì±„ì : ê·¼ê±°/ì§€í‘œ ë¯¸ì œì‹œ ê°•ë ¥ ê°ì 
    hits = retrieve_resume_chunks(question + "\n" + answer[:800], k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]

    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {
        "role":"user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
            f"[ì§€ì›ì ì´ë ¥ì„œ ë°œì·Œ]\n{resume_text}\n\n"
            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
            f"[ì§€ì›ì ë‹µë³€]\n{answer}\n\n"
            "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
            "{"
            "\"overall_score\": 0~100 ì •ìˆ˜,"
            "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
            "\"strengths\": [\"...\", \"...\"],"
            "\"risks\": [\"...\", \"...\"],"
            "\"improvements\": [\"...\", \"...\", \"...\"],"
            "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
            "}"
        )
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2,
            response_format={"type":"json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_SCORE_STRICT}, user_msg]
        )
        data = json.loads(resp.choices[0].message.content)
        # ì •í•©í™”
        crit = data.get("criteria", [])
        fixed=[]
        for name in CRITERIA:
            found=None
            for it in crit:
                if str(it.get("name","")).strip()==name:
                    found=it; break
            if not found: found={"name":name,"score":0,"comment":""}
            sc = int(found.get("score",0)); sc=max(0,min(20,sc))
            found["score"]=sc; found["comment"]=str(found.get("comment","")).strip()
            fixed.append(found)
        total=sum(x["score"] for x in fixed)
        data["criteria"]=fixed
        data["overall_score"]=total
        for k in ["strengths","risks","improvements"]:
            arr=data.get(k,[]); 
            if not isinstance(arr,list): arr=[]
            data[k]=[str(x).strip() for x in arr if str(x).strip()][:5]
        data["revised_answer"]=str(data.get("revised_answer","")).strip()
        return data
    except Exception as e:
        return {
            "overall_score": 0,
            "criteria": [{"name": n, "score": 0, "comment": ""} for n in CRITERIA],
            "strengths": [],
            "risks": [],
            "improvements": [],
            "revised_answer": "",
            "error": str(e),
        }

# ================== ì„¸ì…˜ ìƒíƒœ ==================
if "clean_struct" not in st.session_state:
    st.session_state.clean_struct = None
if "resume_raw" not in st.session_state:
    st.session_state.resume_raw = ""
if "resume_chunks" not in st.session_state:
    st.session_state.resume_chunks = []
if "resume_embeds" not in st.session_state:
    st.session_state.resume_embeds = None
if "q_hist" not in st.session_state:
    st.session_state.q_hist = []
if "current_question" not in st.session_state:
    st.session_state.current_question = ""
if "answer_text" not in st.session_state:
    st.session_state.answer_text = ""
if "records" not in st.session_state:
    st.session_state.records = []
if "followups" not in st.session_state:
    st.session_state.followups = []
if "selected_followup" not in st.session_state:
    st.session_state.selected_followup = ""

# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ ==================
st.header("1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì˜ˆ: https://www.wanted.co.kr/wd/123456")
if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
            raw, meta, soup = fetch_all_text(url.strip())
            hint = extract_company_meta(soup)
        if not raw:
            st.error("ì›ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸/ë™ì  ë Œë”ë§/ë´‡ ì°¨ë‹¨ ê°€ëŠ¥)")
        else:
            with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
                clean = llm_structurize(raw, hint, CHAT_MODEL)
            st.session_state.clean_struct = clean
            st.success("ì •ì œ ì™„ë£Œ!")

# ================== 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ==================
st.header("2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")
clean = st.session_state.clean_struct
if clean:
    st.markdown(f"**íšŒì‚¬ëª…:** {clean.get('company_name','-')}")
    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½):** {clean.get('company_intro','-')}")
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {clean.get('job_title','-')}")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("**ì£¼ìš” ì—…ë¬´**")
        for b in clean.get("responsibilities", []): st.markdown(f"- {b}")
    with c2:
        st.markdown("**ìê²© ìš”ê±´**")
        for b in clean.get("qualifications", []): st.markdown(f"- {b}")
    with c3:
        st.markdown("**ìš°ëŒ€ ì‚¬í•­**")
        prefs = clean.get("preferences", [])
        if prefs:
            for b in prefs: st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € URLì„ ì •ì œí•´ ì£¼ì„¸ìš”.")

st.divider()

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (PDF/TXT/MD/DOCX)")
uploads = st.file_uploader(
    "ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ ê°€ëŠ¥", type=["pdf","txt","md","docx"], accept_multiple_files=True
)
# ë‚´ë¶€ ê¸°ë³¸ íŒŒë¼ë¯¸í„° (ìˆ¨ê¹€)
_RESUME_CHUNK = 600
_RESUME_OVLP  = 120
_TOPK_RAG     = 4

cols_idx = st.columns(2)
with cols_idx[0]:
    if st.button("ì´ë ¥ì„œ ì¸ë±ì‹±(ìë™)", type="secondary"):
        if not uploads:
            st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            all_text=[]
            for up in uploads:
                t = read_file_text(up)
                if t: all_text.append(t)
            resume_text = "\n\n".join(all_text)
            if not resume_text.strip():
                st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                chunks = chunk(resume_text, size=_RESUME_CHUNK, overlap=_RESUME_OVLP)
                with st.spinner("ì´ë ¥ì„œ ë²¡í„°í™” ì¤‘..."):
                    embeds = embed_texts(chunks, EMBED_MODEL)
                st.session_state.resume_raw = resume_text
                st.session_state.resume_chunks = chunks
                st.session_state.resume_embeds = embeds
                st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)")
with cols_idx[1]:
    st.caption("â€» ì²­í¬/ì˜¤ë²„ë©/Top-K íŒŒë¼ë¯¸í„°ëŠ” ë‚´ë¶€ ê¸°ë³¸ê°’ìœ¼ë¡œ ìë™ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

st.divider()

# ================== 4) ìì†Œì„œ ìƒì„± (Step1ì—ì„œ ì¶”ê°€ëœ ê¸°ëŠ¥ ìœ ì§€) ==================
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“±")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    company = json.dumps(clean_struct or {}, ensure_ascii=False)
    resume_snippet = resume_text.strip()
    if len(resume_snippet) > 9000:
        resume_snippet = resume_snippet[:9000]
    system = (
        "ë„ˆëŠ” í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì „ë¬¸ê°€ë‹¤. ì±„ìš© ê³µê³ ì˜ íšŒì‚¬/ì§ë¬´ ìš”ê±´ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•´ "
        "íšŒì‚¬ íŠ¹í™” ìì†Œì„œë¥¼ ì‘ì„±í•œë‹¤. ê³¼ì¥/í—ˆìœ„ëŠ” ê¸ˆì§€í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´í™”í•œë‹¤."
    )
    if topic_hint and topic_hint.strip():
        req = f"íšŒì‚¬ ì¸¡ ìš”ì²­ ì£¼ì œëŠ” '{topic_hint.strip()}' ì´ë‹¤. ì´ ì£¼ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•˜ë¼."
    else:
        req = "íŠ¹ì • ì£¼ì œ ìš”ì²­ì´ ì—†ìœ¼ë¯€ë¡œ, ì±„ìš© ê³µê³ ì˜ ìš”ê±´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§€ì›ë™ê¸°ì™€ ì§ë¬´ì í•©ì„±ì„ ê°•ì¡°í•˜ë¼."
    user = (
        f"[íšŒì‚¬/ì§ë¬´ ìš”ì•½(JSON)]\n{company}\n\n"
        f"[í›„ë³´ì ì´ë ¥ì„œ(ìš”ì•½ ê°€ëŠ¥)]\n{resume_snippet}\n\n"
        f"[ì‘ì„± ì§€ì‹œ]\n- {req}\n"
        "- ë¶„ëŸ‰: 600~900ì\n"
        "- êµ¬ì„±: 1) ì§€ì› ë™ê¸° 2) ì§ë¬´ ê´€ë ¨ í•µì‹¬ ì—­ëŸ‰Â·ê²½í—˜ 3) ì„±ê³¼/ì§€í‘œ 4) ì…ì‚¬ í›„ ê¸°ì—¬ ë°©ì•ˆ 5) ë§ˆë¬´ë¦¬\n"
        "- ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆëŠ” 1ì¸ì¹­ ì„œìˆ . ë¬¸ì¥ê³¼ ë¬¸ë‹¨ ê°€ë…ì„±ì„ ìœ ì§€.\n"
        "- ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬/ì¤‘ë³µ/ê´‘ê³  ë¬¸êµ¬ ì‚­ì œ."
    )
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.4,
            messages=[{"role":"system","content":system},{"role":"user","content":user}]
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"(ìì†Œì„œ ìƒì„± ì‹¤íŒ¨: {e})"

if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
    elif not st.session_state.resume_raw.strip():
        st.warning("ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  'ì´ë ¥ì„œ ì¸ë±ì‹±(ìë™)'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cover = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_raw, topic, CHAT_MODEL)
        st.subheader("ìì†Œì„œ (ìƒì„± ê²°ê³¼)")
        st.write(cover)
        st.download_button("ìì†Œì„œ TXT ë‹¤ìš´ë¡œë“œ", data=cover.encode("utf-8"),
                           file_name="cover_letter.txt", mime="text/plain")

st.divider()

# ================== 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©, ë‚´ë¶€ ì‹œë“œ/ê°œìˆ˜ ìˆ¨ê¹€) ==================
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

# ë‚´ë¶€ íŒŒë¼ë¯¸í„° (ìˆ¨ê¹€)
_Q_NUM  = 8
_SEED   = int(time.time()*1000000) % 2_147_483_647

cols_q = st.columns(2)
with cols_q[0]:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct:
            st.warning("ë¨¼ì € íšŒì‚¬ URLì„ ì •ì œí•˜ì„¸ìš”.")
        else:
            qs = llm_generate_questions_with_resume(st.session_state.clean_struct, level, CHAT_MODEL, num=_Q_NUM)
            if qs:
                st.session_state.q_hist.extend(qs)
                # ë‹¤ì–‘ì„± ìœ„í•´ ëœë¤ 1ê°œ ì„ íƒ
                st.session_state.current_question = random.choice(qs)
                st.session_state.answer_text = ""  # ì´ì „ ë‹µë³€ ì´ˆê¸°í™”
                st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
with cols_q[1]:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        else:
            draft = llm_draft_answer(st.session_state.clean_struct, st.session_state.current_question, CHAT_MODEL)
            if draft:
                st.session_state.answer_text = draft
                st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
ans = st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# ================== 6) ì±„ì  & ì½”ì¹­ (ì—„ê²© ëª¨ë“œ) + íŒ”ë¡œì—… ì¤€ë¹„ ==================
st.header("6) ì±„ì  & ì½”ì¹­ (ì—„ê²© ëª¨ë“œ)")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì±„ì /ì½”ì¹­ ì¤‘..."):
            res = llm_score_and_coach_strict(
                st.session_state.clean_struct,
                st.session_state.current_question,
                st.session_state.answer_text,
                CHAT_MODEL
            )
        st.session_state.records.append({
            "question": st.session_state.current_question,
            "answer": st.session_state.answer_text,
            "overall": res.get("overall_score", 0),
            "criteria": res.get("criteria", []),
            "strengths": res.get("strengths", []),
            "risks": res.get("risks", []),
            "improvements": res.get("improvements", []),
            "revised_answer": res.get("revised_answer","")
        })
        st.success("ì±„ì /ì½”ì¹­ ì™„ë£Œ!")

        # íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œ ì œì•ˆ ì €ì¥
        try:
            ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
            msg = {
                "role":"user",
                "content":(
                    f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
                    f"[ì§€ì›ì ë‹µë³€]\n{st.session_state.answer_text}\n\n"
                    "ë©´ì ‘ê´€ ê´€ì ì—ì„œ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ í•œ ì¤„ì”© í•œêµ­ì–´ë¡œ ì œì•ˆí•´ì¤˜. "
                    "ê¸°ì¡´ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šê²Œ, ì§€í‘œ/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„/ì˜ì‚¬ê²°ì • ê·¼ê±°ë¥¼ ì„ì–´ì¤˜."
                )
            }
            r = client.chat.completions.create(model=CHAT_MODEL, temperature=0.7,
                                               messages=[{"role":"system","content":"ë©´ì ‘ íŒ”ë¡œì—… ìƒì„±ê¸°"}, msg])
            followups = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip()
                         for l in r.choices[0].message.content.splitlines() if l.strip()]
            st.session_state.followups = followups[:3]
        except Exception:
            st.session_state.followups = []

# ================== 7) í”¼ë“œë°± ê²°ê³¼ ==================
st.header("7) í”¼ë“œë°± ê²°ê³¼")
if st.session_state.records:
    last = st.session_state.records[-1]
    left, right = st.columns([1,3])
    with left:
        st.metric("ì´ì (/100)", last["overall"])
    with right:
        st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜ & ì½”ë©˜íŠ¸**")
        for it in last["criteria"]:
            st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
        if last["strengths"]:
            st.markdown("**ê°•ì **")
            for s in last["strengths"]: st.markdown(f"- {s}")
        if last["risks"]:
            st.markdown("**ê°ì  ìš”ì¸/ë¦¬ìŠ¤í¬**")
            for r in last["risks"]: st.markdown(f"- {r}")
        if last["improvements"]:
            st.markdown("**ê°œì„  í¬ì¸íŠ¸**")
            for im in last["improvements"]: st.markdown(f"- {im}")
        if last["revised_answer"]:
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR)**")
            st.write(last["revised_answer"])
else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# ================== 8) íŒ”ë¡œì—… ì§ˆë¬¸ â–¶ ë‹µë³€ â–¶ í”¼ë“œë°± ==================
st.header("8) íŒ”ë¡œì—… ì§ˆë¬¸ â–¶ ë‹µë³€ â–¶ í”¼ë“œë°±")
if st.session_state.followups:
    st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
    for i, f in enumerate(st.session_state.followups, 1):
        st.markdown(f"- ({i}) {f}")
    st.session_state.selected_followup = st.selectbox(
        "ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0
    )
    fu_ans = st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")

    if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
        if not st.session_state.selected_followup:
            st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
        elif not fu_ans.strip():
            st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
        else:
            with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘..."):
                res_fu = llm_score_and_coach_strict(
                    st.session_state.clean_struct,
                    st.session_state.selected_followup,
                    fu_ans, CHAT_MODEL
                )
            st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
            st.metric("ì´ì (/100)", res_fu.get("overall_score", 0))
            for it in res_fu.get("criteria", []):
                st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
            if res_fu.get("revised_answer",""):
                st.markdown("**íŒ”ë¡œì—… ìˆ˜ì •ë³¸ (STAR)**")
                st.write(res_fu["revised_answer"])
else:
    st.caption("ë©”ì¸ ì§ˆë¬¸ì„ ì±„ì í•˜ë©´ íŒ”ë¡œì—… ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì œì•ˆë©ë‹ˆë‹¤.")
