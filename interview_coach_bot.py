# -*- coding: utf-8 -*-
import os, re, json, urllib.parse, random, time, io, textwrap
from typing import Optional, Tuple, Dict, List

import requests
from bs4 import BeautifulSoup
import html2text
import streamlit as st
import pandas as pd
import numpy as np

# ================== ê¸°ë³¸ ì„¤ì • ==================
st.set_page_config(page_title="íšŒì‚¬ ë§ì¶¤ ë©´ì ‘ ì½”ì¹˜ (RAG í™•ì¥íŒ)", page_icon="ğŸš€", layout="wide")
st.title("íšŒì‚¬ ë§ì¶¤ ë©´ì ‘ ì½”ì¹˜ Â· ì±„ìš© URL â†’ ì •ì œ â†’ RAG ì´ˆì•ˆ â†’ ì±„ì /ì½”ì¹­ â†’ ë ˆì´ë”/ì„¸ì…˜")

# ================== OpenAI ==================
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

with st.sidebar:
    st.subheader("ëª¨ë¸ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ì±„ì  ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["text-embedding-3-small","text-embedding-3-large"], index=0)

# ================== HTTP ìœ í‹¸ ==================
def normalize_url(u: str) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def http_get(url: str, timeout: int = 12) -> Optional[requests.Response]:
    try:
        r = requests.get(
            url,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                "Accept-Language": "ko, en;q=0.9",
            },
            timeout=timeout,
        )
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

# ================== ì›ë¬¸ ìˆ˜ì§‘ (Jina â†’ Web â†’ BS4) ==================
def fetch_jina_text(url: str, timeout: int = 15) -> str:
    try:
        parts = urllib.parse.urlsplit(url)
        prox = f"https://r.jina.ai/http://{parts.netloc}{parts.path}"
        if parts.query: prox += f"?{parts.query}"
        r = http_get(prox, timeout=timeout)
        return r.text.strip() if r else ""
    except Exception:
        return ""

def html_to_text(html_str: str) -> str:
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    txt = conv.handle(html_str)
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()

def fetch_webbase_text(url: str) -> str:
    r = http_get(url, timeout=12)
    if not r: return ""
    return html_to_text(r.text)

def fetch_bs4_text(url: str) -> Tuple[str, Optional[BeautifulSoup]]:
    r = http_get(url, timeout=12)
    if not r: return "", None
    soup = BeautifulSoup(r.text, "lxml")
    blocks = []
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True)
            if txt and len(txt) > 300:
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    if not blocks:
        return soup.get_text(" ", strip=True)[:120000], soup
    seen, out = set(), []
    for b in blocks:
        if b not in seen:
            seen.add(b); out.append(b)
    return ("\n\n".join(out)[:120000], soup)

def fetch_all_text(url: str):
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None
    jina = fetch_jina_text(url)
    if jina:
        _, soup = fetch_bs4_text(url)
        return jina, {"source":"jina","len":len(jina),"url_final":url}, soup
    web = fetch_webbase_text(url)
    if web:
        _, soup = fetch_bs4_text(url)
        return web, {"source":"webbase","len":len(web),"url_final":url}, soup
    bs, soup = fetch_bs4_text(url)
    return bs, {"source":"bs4","len":len(bs),"url_final":url}, soup

# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    cand = []
    og = soup.find("meta", {"property":"og:site_name"})
    if og and og.get("content"): cand.append(og["content"])
    app = soup.find("meta", {"name":"application-name"})
    if app and app.get("content"): cand.append(app["content"])
    if soup.title and soup.title.string: cand.append(soup.title.string)
    cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
    cand = [c for c in cand if 2 <= len(c) <= 40]
    meta["company_name"] = cand[0] if cand else ""
    md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
    if md and md.get("content"):
        meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
    jt = ""
    ogt = soup.find("meta", {"property":"og:title"})
    if ogt and ogt.get("content"): jt = ogt["content"]
    if not jt:
        h1 = soup.find("h1")
        if h1 and h1.get_text(): jt = h1.get_text(strip=True)
    if not jt:
        h2 = soup.find("h2")
        if h2 and h2.get_text(): jt = h2.get_text(strip=True)
    meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    return meta

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
PROMPT_SYSTEM_STRUCT = (
    "ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
    "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
    "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼."
)

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    ctx = raw_text.strip()
    if len(ctx) > 9000:
        ctx = ctx[:9000]

    user_msg = {
        "role": "user",
        "content": (
            "ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n"
            "--- ì›ë¬¸ ì‹œì‘ ---\n"
            f"{ctx}\n"
            "--- ì›ë¬¸ ë ---\n\n"
            "JSONìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‚¤ëŠ” ë°˜ë“œì‹œ ì•„ë˜ë§Œ í¬í•¨:\n"
            "{"
            "\"company_name\": str, "
            "\"company_intro\": str, "
            "\"job_title\": str, "
            "\"responsibilities\": [str], "
            "\"qualifications\": [str], "
            "\"preferences\": [str]"
            "}"
        ),
    }

    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2,
            response_format={"type": "json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg],
        )
        data = json.loads(resp.choices[0].message.content)
        # í›„ì²˜ë¦¬
        for k in ["responsibilities","qualifications","preferences"]:
            if not isinstance(data.get(k, []), list):
                data[k] = []
            clean = []
            seen = set()
            for it in data[k]:
                t = re.sub(r"\s+"," ", str(it)).strip(" -â€¢Â·").strip()
                if t and t not in seen:
                    seen.add(t); clean.append(t)
            data[k] = clean[:12]
        for k in ["company_name","company_intro","job_title"]:
            if k in data and isinstance(data[k], str):
                data[k] = re.sub(r"\s+"," ", data[k]).strip()
        return data
    except Exception as e:
        return {
            "company_name": meta_hint.get("company_name",""),
            "company_intro": meta_hint.get("company_intro","ì›ë¬¸ì´ ì •ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
            "job_title": meta_hint.get("job_title",""),
            "responsibilities": [],
            "qualifications": [],
            "preferences": [],
            "error": str(e),
        }

# ================== RAG: ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ ==================
try:
    import pypdf
except Exception:
    pypdf = None

def read_file_text(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md")):
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: continue
        return data.decode("utf-8", errors="ignore")
    elif name.endswith(".pdf"):
        if pypdf is None:
            return ""
        try:
            reader = pypdf.PdfReader(io.BytesIO(data))
            return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
        except Exception:
            return ""
    return ""

def chunk(text: str, size: int = 900, overlap: int = 150) -> List[str]:
    t = re.sub(r"\s+"," ", text).strip()
    if not t: return []
    out, start = [], 0
    while start < len(t):
        end = min(len(t), start+size)
        out.append(t[start:end])
        if end == len(t): break
        start = max(0, end-overlap)
    return out

def embed_texts(texts: List[str]) -> np.ndarray:
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=EMBED_MODEL, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k]
    return sims[idx], idx

def retrieve_resume_chunks(query: str, k: int = 4):
    store = st.session_state.get("rag_store", {})
    chs, embs = store.get("chunks", []), store.get("embeds")
    if not chs or embs is None:
        return []
    qv = embed_texts([query])
    scores, idxs = cosine_topk(embs, qv, k=k)
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== ì§ˆë¬¸/ì´ˆì•ˆ/ì±„ì  í”„ë¡¬í”„íŠ¸ ==================
PROMPT_SYSTEM_Q = (
    "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´ì„ ë°˜ì˜í•´ ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. "
    "ì§ˆë¬¸ì€ ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬ ë“±ë„ ì„ì–´ë¼."
)

PROMPT_SYSTEM_DRAFT = (
    "ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ìš”ì•½ì„ ê²°í•©í•´ "
    "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ **ì´ˆì•ˆ**ì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
    "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼."
)

PROMPT_SYSTEM_SCORE = (
    "ë„ˆëŠ” í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
    "ê° ê¸°ì¤€ì€ 0~20 ì •ìˆ˜, ì´ì ì€ ê¸°ì¤€ í•©ê³„(ìµœëŒ€ 100)ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•œë‹¤. "
    "ê° ê¸°ì¤€ì— ëŒ€í•´ ì§§ì€ ì½”ë©˜íŠ¸(ê°•ì /ê°ì ìš”ì¸/ê°œì„ í¬ì¸íŠ¸ í¬í•¨)ë¥¼ ì œê³µí•˜ë¼."
)

CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_questions(clean: Dict, q_type: str, level: str, model: str, num: int = 8, seed: int = 0) -> List[str]:
    ctx = json.dumps(clean, ensure_ascii=False)
    user_msg = {
        "role": "user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
            f"[ìš”ì²­]\n- ì§ˆë¬¸ ìœ í˜•: {q_type}\n- ë‚œì´ë„/ì—°ì°¨: {level}\n"
            f"- ì´ {num}ê°œ, í•œ ì¤„ì”©\n- ì¤‘ë³µ/ìœ ì‚¬ë„ ìµœì†Œí™”\n- ëœë¤ì‹œë“œ: {seed}"
        ),
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.9,
            messages=[{"role":"system","content":PROMPT_SYSTEM_Q}, user_msg],
        )
        txt = resp.choices[0].message.content.strip()
        lines = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip() for l in txt.splitlines() if l.strip()]
        lines = [l for l in lines if len(l.split()) > 2][:num]
        if "q_hist" in st.session_state:
            hist = st.session_state.q_hist[-10:]
            def sim(a,b):
                a_set=set(a.lower().split()); b_set=set(b.lower().split())
                inter=len(a_set&b_set); denom=max(1,len(a_set|b_set))
                return inter/denom
            uniq=[]
            for q in lines:
                if all(sim(q,h)<0.4 for h in hist):
                    uniq.append(q)
            if uniq: lines = uniq
        return lines[:num]
    except Exception:
        return []

def llm_draft_answer(clean: Dict, question: str, resume_snips: List[str], model: str) -> str:
    ctx = json.dumps(clean, ensure_ascii=False)
    resume_text = "\n".join([f"- {s[:400]}" for s in resume_snips])[:2000]
    user_msg = {
        "role": "user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
            f"[ì§€ì›ì ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ìš”ì•½]\n{resume_text}\n\n"
            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ STAR ê¸°ë°˜ í•œêµ­ì–´ ë‹µë³€ **ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì¤˜."
        )
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.5,
            messages=[{"role":"system","content":PROMPT_SYSTEM_DRAFT}, user_msg],
        )
        return resp.choices[0].message.content.strip()
    except Exception:
        return ""

def llm_score_and_coach(clean: Dict, question: str, answer: str, resume_snips: List[str], model: str) -> Dict:
    ctx = json.dumps(clean, ensure_ascii=False)
    resume_text = "\n".join([f"- {s[:400]}" for s in resume_snips])[:1600]
    user_msg = {
        "role":"user",
        "content": (
            f"[íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´]\n{ctx}\n\n"
            f"[ì§€ì›ì ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ìš”ì•½]\n{resume_text}\n\n"
            f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
            f"[ì§€ì›ì ë‹µë³€]\n{answer}\n\n"
            "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ í•œêµ­ì–´ ì‘ë‹µ:\n"
            "{"
            "\"overall_score\": 0~100 ì •ìˆ˜,"
            "\"criteria\": [{\"name\":\"ë¬¸ì œì •ì˜\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ë°ì´í„°/ì§€í‘œ\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ì‹¤í–‰ë ¥/ì£¼ë„ì„±\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\",\"score\":0~20,\"comment\":\"...\"},"
            "{\"name\":\"ê³ ê°ê°€ì¹˜\",\"score\":0~20,\"comment\":\"...\"}],"
            "\"strengths\": [\"...\", \"...\"],"
            "\"risks\": [\"...\", \"...\"],"
            "\"improvements\": [\"...\", \"...\", \"...\"],"
            "\"revised_answer\": \"STAR êµ¬ì¡°ë¡œ ê°„ê²°íˆ\""
            "}"
        )
    }
    try:
        resp = client.chat.completions.create(
            model=model, temperature=0.2,
            response_format={"type":"json_object"},
            messages=[{"role":"system","content":PROMPT_SYSTEM_SCORE}, user_msg]
        )
        data = json.loads(resp.choices[0].message.content)
        # ì •í•©í™”
        crit = data.get("criteria", [])
        fixed=[]
        for name in CRITERIA:
            found=None
            for it in crit:
                if str(it.get("name","")).strip()==name:
                    found=it; break
            if not found: found={"name":name,"score":0,"comment":""}
            sc = int(found.get("score",0)); sc=max(0,min(20,sc))
            found["score"]=sc; found["comment"]=str(found.get("comment","")).strip()
            fixed.append(found)
        total=sum(x["score"] for x in fixed)
        data["criteria"]=fixed
        data["overall_score"]=total
        for k in ["strengths","risks","improvements"]:
            arr=data.get(k,[]); 
            if not isinstance(arr,list): arr=[]
            data[k]=[str(x).strip() for x in arr if str(x).strip()][:5]
        data["revised_answer"]=str(data.get("revised_answer","")).strip()
        return data
    except Exception as e:
        return {
            "overall_score": 0,
            "criteria": [{"name": n, "score": 0, "comment": ""} for n in CRITERIA],
            "strengths": [],
            "risks": [],
            "improvements": [],
            "revised_answer": "",
            "error": str(e),
        }

# ================== ì„¸ì…˜ ìƒíƒœ ==================
if "clean_struct" not in st.session_state:
    st.session_state.clean_struct = None
if "q_hist" not in st.session_state:
    st.session_state.q_hist = []
if "records" not in st.session_state:
    st.session_state.records = []
if "current_question" not in st.session_state:
    st.session_state.current_question = ""
if "answer_text" not in st.session_state:
    st.session_state.answer_text = ""
if "rag_store" not in st.session_state:
    st.session_state.rag_store = {"chunks": [], "embeds": None}

# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ ==================
st.header("1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì˜ˆ: https://www.wanted.co.kr/wd/123456")
if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("ì›ë¬¸ ìˆ˜ì§‘ ì¤‘..."):
            raw, meta, soup = fetch_all_text(url.strip())
            hint = extract_company_meta(soup)
        if not raw:
            st.error("ì›ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸/ë™ì  ë Œë”ë§/ë´‡ ì°¨ë‹¨ ê°€ëŠ¥)")
        else:
            with st.spinner("LLMìœ¼ë¡œ ì •ì œ ì¤‘..."):
                clean = llm_structurize(raw, hint, CHAT_MODEL)
            st.session_state.clean_struct = clean
            st.success("ì •ì œ ì™„ë£Œ!")

# ================== 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ==================
st.header("2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")
clean = st.session_state.clean_struct
if clean:
    st.markdown(f"**íšŒì‚¬ëª…:** {clean.get('company_name','-')}")
    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½):** {clean.get('company_intro','-')}")
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {clean.get('job_title','-')}")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("**ì£¼ìš” ì—…ë¬´**")
        for b in clean.get("responsibilities", []): st.markdown(f"- {b}")
    with c2:
        st.markdown("**ìê²© ìš”ê±´**")
        for b in clean.get("qualifications", []): st.markdown(f"- {b}")
    with c3:
        st.markdown("**ìš°ëŒ€ ì‚¬í•­**")
        prefs = clean.get("preferences", [])
        if prefs:
            for b in prefs: st.markdown(f"- {b}")
        else:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € URLì„ ì •ì œí•´ ì£¼ì„¸ìš”.")

st.divider()

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ(RAG) ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (RAG)")
docs = st.file_uploader("ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì„¤ëª… íŒŒì¼ ì—…ë¡œë“œ (PDF/TXT/MD, ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf","txt","md"], accept_multiple_files=True)
rag_cols = st.columns(3)
with rag_cols[0]:
    chunk_size = st.number_input("ì²­í¬ ê¸¸ì´", value=900, min_value=300, max_value=2000, step=100)
with rag_cols[1]:
    chunk_overlap = st.number_input("ì˜¤ë²„ë©", value=150, min_value=0, max_value=500, step=10)
with rag_cols[2]:
    top_k_rag = st.number_input("ê²€ìƒ‰ ìƒìœ„ K", value=4, min_value=1, max_value=10, step=1)

if st.button("RAG ì¸ë±ì‹±", type="secondary"):
    if not docs:
        st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        chunks=[]
        for up in docs:
            t = read_file_text(up)
            if t:
                chunks += chunk(t, chunk_size, chunk_overlap)
        if not chunks:
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘..."):
                vecs = embed_texts(chunks)
            st.session_state.rag_store["chunks"] = chunks
            st.session_state.rag_store["embeds"] = vecs
            st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks)}ê°œ)")

# ================== 4) ì§ˆë¬¸ ìƒì„± & ì´ˆì•ˆ ==================
st.header("4) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ")
q_type = st.selectbox("ì§ˆë¬¸ ìœ í˜•", ["í–‰ë™(STAR)","ê¸°ìˆ  ì‹¬ì¸µ","í•µì‹¬ê°€ì¹˜ ì í•©ì„±","ì—­ì§ˆë¬¸"], index=0)
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)
seed   = st.number_input("ëœë¤ì‹œë“œ", value=int(time.time())%1_000_000, step=1)
num    = st.slider("ì§ˆë¬¸ ê°œìˆ˜", 4, 10, 8, 1)

cqa = st.columns(2)
with cqa[0]:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct:
            st.warning("ë¨¼ì € URLì„ ì •ì œí•˜ì„¸ìš”.")
        else:
            qs = llm_generate_questions(st.session_state.clean_struct, q_type, level, CHAT_MODEL, num=num, seed=int(seed))
            if qs:
                st.session_state.q_hist.extend(qs)
                st.session_state.current_question = random.choice(qs)
                st.session_state.answer_text = ""  # ì´ì „ ë‹µë³€ ì´ˆê¸°í™”
                st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
with cqa[1]:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
        else:
            snips = []
            if st.session_state.rag_store.get("embeds") is not None:
                hits = retrieve_resume_chunks(st.session_state.current_question, k=top_k_rag)
                snips = [t for _, t in hits]
            draft = llm_draft_answer(st.session_state.clean_struct, st.session_state.current_question, snips, CHAT_MODEL)
            if draft:
                st.session_state.answer_text = draft
                st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ!")
            else:
                st.error("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨(ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± ê°€ëŠ¥)")

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
ans = st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# ================== 5) ì±„ì  & ì½”ì¹­ (+ íŒ”ë¡œì—… ì§ˆë¬¸) ==================
st.header("5) ì±„ì  & ì½”ì¹­")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question:
        st.warning("ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.")
    elif not st.session_state.answer_text.strip():
        st.warning("ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    else:
        snips=[]
        if st.session_state.rag_store.get("embeds") is not None:
            hits = retrieve_resume_chunks(
                st.session_state.current_question + "\n" + st.session_state.answer_text[:800],
                k=top_k_rag
            )
            snips = [t for _, t in hits]
        with st.spinner("ì±„ì /ì½”ì¹­ ì¤‘..."):
            res = llm_score_and_coach(st.session_state.clean_struct, st.session_state.current_question, st.session_state.answer_text, snips, CHAT_MODEL)
        st.session_state.records.append({
            "question": st.session_state.current_question,
            "answer": st.session_state.answer_text,
            "overall": res.get("overall_score", 0),
            "criteria": res.get("criteria", []),
            "strengths": res.get("strengths", []),
            "risks": res.get("risks", []),
            "improvements": res.get("improvements", []),
            "revised_answer": res.get("revised_answer","")
        })
        st.success("ì±„ì /ì½”ì¹­ ì™„ë£Œ!")

        # íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œ ì¶”ê°€ ì œì•ˆ
        try:
            ctx = json.dumps(st.session_state.clean_struct, ensure_ascii=False)
            msg = {
                "role":"user",
                "content":(
                    f"[íšŒì‚¬/ì§ë¬´/ìš”ê±´]\n{ctx}\n\n"
                    f"[ì§€ì›ì ë‹µë³€]\n{st.session_state.answer_text}\n\n"
                    "ë©´ì ‘ê´€ ê´€ì ì—ì„œ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ í•œ ì¤„ì”© í•œêµ­ì–´ë¡œ ì œì•ˆí•´ì¤˜. "
                    "ê¸°ì¡´ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šê²Œ, ì§€í‘œ/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì„ì–´ì¤˜."
                )
            }
            r = client.chat.completions.create(model=CHAT_MODEL, temperature=0.7, messages=[{"role":"system","content":"ë©´ì ‘ íŒ”ë¡œì—… ìƒì„±ê¸°"}, msg])
            followups = [re.sub(r'^\s*\d+[\).\s-]*','', l).strip() for l in r.choices[0].message.content.splitlines() if l.strip()]
            st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
            for f in followups[:3]:
                st.markdown(f"- {f}")
        except Exception:
            pass

# ================== 6) í”¼ë“œë°± ê²°ê³¼ ==================
st.header("6) í”¼ë“œë°± ê²°ê³¼")
if st.session_state.records:
    last = st.session_state.records[-1]
    left, right = st.columns([1,3])
    with left:
        st.metric("ì´ì (/100)", last["overall"])
    with right:
        st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜ & ì½”ë©˜íŠ¸**")
        for it in last["criteria"]:
            st.markdown(f"- **{it['name']}**: {it['score']}/20 â€” {it.get('comment','')}")
        if last["strengths"]:
            st.markdown("**ê°•ì **")
            for s in last["strengths"]: st.markdown(f"- {s}")
        if last["risks"]:
            st.markdown("**ê°ì  ìš”ì¸/ë¦¬ìŠ¤í¬**")
            for r in last["risks"]: st.markdown(f"- {r}")
        if last["improvements"]:
            st.markdown("**ê°œì„  í¬ì¸íŠ¸**")
            for im in last["improvements"]: st.markdown(f"- {im}")
        if last["revised_answer"]:
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR)**")
            st.write(last["revised_answer"])
else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# ================== 7) ì—­ëŸ‰ ë ˆì´ë” (ëˆ„ì +í‰ê· ) ==================
st.header("7) ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")
def build_comp_table(records):
    rows=[]
    for idx, r in enumerate(records, 1):
        crit = r.get("criteria", [])
        row={"#": idx, "question": r.get("question",""), "overall": r.get("overall",0)}
        cm = {c["name"]: c["score"] for c in crit if "name" in c}
        for k in CRITERIA:
            row[k] = cm.get(k, 0)
        rows.append(row)
    return pd.DataFrame(rows) if rows else pd.DataFrame(columns=["#","question","overall"]+CRITERIA)

df = build_comp_table(st.session_state.records)
if not df.empty:
    avg = [float(df[k].mean()) for k in CRITERIA]
    cum = [int(df[k].sum()) for k in CRITERIA]
    try:
        import plotly.graph_objects as go
        radar = go.Figure()
        radar.add_trace(go.Scatterpolar(
            r=avg + [avg[0]], theta=CRITERIA + [CRITERIA[0]],
            fill='toself', name='í‰ê· (0~20)'
        ))
        radar.add_trace(go.Scatterpolar(
            r=cum + [cum[0]], theta=CRITERIA + [CRITERIA[0]],
            fill='toself', name='ëˆ„ì (í•©ê³„)'
        ))
        radar.update_layout(polar=dict(radialaxis=dict(visible=True)), showlegend=True, height=420)
        st.plotly_chart(radar, use_container_width=True)
    except Exception:
        st.bar_chart(pd.DataFrame({"í‰ê· ":avg,"ëˆ„ì ":cum}, index=CRITERIA))
    st.markdown("**ì„¸ì…˜ í‘œ(ì§ˆë¬¸ë³„ ê¸°ì¤€ ì ìˆ˜)**")
    st.dataframe(df, use_container_width=True)
else:
    st.caption("ì•„ì§ ëˆ„ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ ìƒì„±â†’ë‹µë³€â†’ì±„ì ì„ ì§„í–‰í•˜ì„¸ìš”.")

st.divider()

# ================== 8) ì„¸ì…˜ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ==================
st.header("8) ì„¸ì…˜ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°")
col_s = st.columns(2)
with col_s[0]:
    export = {
        "clean_struct": st.session_state.clean_struct,
        "q_hist": st.session_state.q_hist,
        "records": st.session_state.records,
    }
    st.download_button("ì„¸ì…˜ ì €ì¥(JSON)", data=json.dumps(export, ensure_ascii=False, indent=2).encode("utf-8"),
                       file_name="interview_session.json", mime="application/json")
with col_s[1]:
    up = st.file_uploader("ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°(JSON)", type=["json"], accept_multiple_files=False, key="sess_up")
    if st.button("ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰", type="secondary"):
        if up is None:
            st.warning("JSON íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
        else:
            try:
                data = json.loads(up.read().decode("utf-8"))
                st.session_state.clean_struct = data.get("clean_struct")
                st.session_state.q_hist = data.get("q_hist", [])
                st.session_state.records = data.get("records", [])
                st.success("ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

st.caption("ì´ì ì€ ê¸°ì¤€(5Ã—20) í•©ê³„ì™€ í•­ìƒ ì¼ì¹˜í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤. â€˜ìƒˆ ì§ˆë¬¸ ë°›ê¸°â€™ í´ë¦­ ì‹œ ë‹µë³€ë€ì€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")
