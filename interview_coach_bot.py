# filename: interview_coach_bot.py
import os, io, re, json, textwrap, time, difflib, urllib.parse, random
from typing import List, Dict, Tuple, Optional

import numpy as np
import pandas as pd
import requests
from bs4 import BeautifulSoup
import streamlit as st

# Optional deps
try:
    import pypdf
except Exception:
    pypdf = None

try:
    import plotly.graph_objects as go
    PLOTLY_OK = True
except Exception:
    PLOTLY_OK = False

# OpenAI
try:
    from openai import OpenAI
except Exception as e:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ------------------ helpers ------------------
def _clean(t:str)->str:
    return re.sub(r"\s+"," ", t or "").strip()

def _snippet(t:str, n:int=220)->str:
    t=_clean(t); return t if len(t)<=n else t[:n-1]+"â€¦"

def load_api_key()->Optional[str]:
    k=os.getenv("OPENAI_API_KEY")
    if k: return k
    try:
        return st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        return None

def read_upload(f)->str:
    name=(f.name or "").lower()
    data=f.read()
    if name.endswith((".txt",".md",".csv",".log")):
        for enc in ("utf-8","cp949","euc-kr"):
            try: return data.decode(enc)
            except Exception: pass
        return data.decode("utf-8", errors="ignore")
    if name.endswith(".pdf"):
        if pypdf is None:
            return ""
        try:
            reader=pypdf.PdfReader(io.BytesIO(data))
            return "\n\n".join([(reader.pages[i].extract_text() or "") for i in range(len(reader.pages))])
        except Exception:
            return ""
    if name.endswith(".docx"):
        # ë§¤ìš° ê²½ëŸ‰ íŒŒì„œ (python-docx ì—†ì´): ì‹¤íŒ¨ ì‹œ ì•ˆë‚´
        try:
            import zipfile, xml.etree.ElementTree as ET
            with zipfile.ZipFile(io.BytesIO(data)) as z:
                xml=z.read("word/document.xml")
            root=ET.fromstring(xml)
            ns={"w":"http://schemas.openxmlformats.org/wordprocessingml/2006/main"}
            texts=[]
            for node in root.findall(".//w:t", ns):
                texts.append(node.text or "")
            return "\n".join(texts)
        except Exception:
            return ""
    return ""

def chunk_text(t:str, size:int=800, overlap:int=120)->List[str]:
    t=re.sub(r"\s+"," ", t or "").strip()
    if not t: return []
    out=[]; i=0
    while i<len(t):
        j=min(len(t), i+size)
        out.append(t[i:j])
        if j==len(t): break
        i=max(0, j-overlap)
    return out

# ------------------ OpenAI ------------------
API_KEY=load_api_key()
if not API_KEY:
    st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. (Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY)")
    st.stop()
client=OpenAI(api_key=API_KEY)

DEFAULT_MODEL="gpt-4o-mini"
EMBED_MODEL="text-embedding-3-small"

def embed(texts:List[str])->np.ndarray:
    if not texts: return np.zeros((0,1536), dtype=np.float32)
    r=client.embeddings.create(model=EMBED_MODEL, input=texts)
    return np.array([d.embedding for d in r.data], dtype=np.float32)

def cosine_topk(matrix:np.ndarray, query:np.ndarray, k:int=4):
    if matrix.size==0: return np.array([]), np.array([], dtype=int)
    qn=query/(np.linalg.norm(query,axis=1,keepdims=True)+1e-12)
    mn=matrix/(np.linalg.norm(matrix,axis=1,keepdims=True)+1e-12)
    sims=(mn@qn.T).reshape(-1)
    idx=np.argsort(-sims)[:k]
    return sims[idx], idx

# ------------------ Company from job URL (ì •ì œìš© ìµœì†Œ í˜•íƒœ) ------------------
SECTION_HEADS=[
    ("ì£¼ìš” ì—…ë¬´", ["ì£¼ìš” ì—…ë¬´","ë‹´ë‹¹ ì—…ë¬´","ì—…ë¬´","What you will do","Responsibilities"]),
    ("ìê²© ìš”ê±´", ["ìê²© ìš”ê±´","ì§€ì› ìê²©","Requirements","Qualifications","Must have"]),
    ("ìš°ëŒ€ ì‚¬í•­", ["ìš°ëŒ€","ìš°ëŒ€ ì‚¬í•­","Preferred","Nice to have"]),
]

def fetch_html(url:str)->BeautifulSoup|None:
    try:
        r=requests.get(url, timeout=10, headers={"User-Agent":"Mozilla/5.0"})
        if r.status_code!=200 or "text/html" not in r.headers.get("content-type",""): return None
        return BeautifulSoup(r.text, "html.parser")
    except Exception:
        return None

def extract_sections_from_job(soup:BeautifulSoup)->dict:
    out={"title":None,"responsibilities":[],"qualifications":[],"preference":[]}
    if soup is None: return out
    # title
    if soup.title and soup.title.string:
        out["title"]=_clean(soup.title.string)

    # JSON-LD ìš°ì„ 
    for s in soup.find_all("script", {"type":"application/ld+json"}):
        try:
            data=json.loads(s.string or "")
            lst=data if isinstance(data,list) else [data]
            for obj in lst:
                t=obj.get("@type")
                if (isinstance(t,list) and "JobPosting" in t) or t=="JobPosting":
                    desc=_clean(obj.get("description",""))
                    if desc:
                        # ë¼ì¸ ë¶„ë¦¬
                        bullets=[x.strip(" -â€¢Â·â–ªï¸â–¶") for x in re.split(r"[â€¢\-\nâ€¢Â·â–ªï¸â–¶]+", desc) if len(x.strip())>3]
                        # ëŒ€ê°• ë¶„ë¥˜
                        for b in bullets:
                            low=b.lower()
                            if any(k in low for k in ["ìš°ëŒ€","preferred","nice to have"]):
                                out["preference"].append(b)
                            elif any(k in low for k in ["ìê²©","require","qualif"]):
                                out["qualifications"].append(b)
                            else:
                                out["responsibilities"].append(b)
        except Exception:
            pass

    # í—¤ë” ê¸°ë°˜ ì¶”ê°€ ë³´ê°•
    def harvest(keys):
        # í—¤ë”ë¶€í„° ë‹¤ìŒ í—¤ë” ì§ì „ê¹Œì§€ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        for h in soup.find_all(re.compile("^h[1-4]$")):
            head=_clean(h.get_text())
            if not head: continue
            if any(k.lower() in head.lower() for k in keys):
                texts=[]
                sib=h.find_next_sibling()
                while sib and sib.name not in {"h1","h2","h3","h4"}:
                    if sib.name in {"p","li","ul","ol","div","section"}:
                        tx=_clean(sib.get_text(" "))
                        if len(tx)>5: texts.append(tx)
                    sib=sib.find_next_sibling()
                joined=" ".join(texts)
                if joined:
                    items=[x.strip(" -â€¢Â·â–ªï¸â–¶") for x in re.split(r"[â€¢\-\nâ€¢Â·â–ªï¸â–¶]+", joined) if len(x.strip())>3]
                    return items[:20]
        return []
    if not out["responsibilities"]:
        out["responsibilities"]=harvest(SECTION_HEADS[0][1])
    if not out["qualifications"]:
        out["qualifications"]=harvest(SECTION_HEADS[1][1])
    if not out["preference"]:
        out["preference"]=harvest(SECTION_HEADS[2][1])

    # ê¸¸ì´ ì œí•œ
    out["responsibilities"]=[_snippet(x,140) for x in out["responsibilities"]][:12]
    out["qualifications"]=[_snippet(x,140) for x in out["qualifications"]][:12]
    out["preference"]=[_snippet(x,140) for x in out["preference"]][:12]
    return out

# ------------------ í˜ì´ì§€ ì„¤ì • ------------------
st.set_page_config(page_title="ì§€ì› íšŒì‚¬ íŠ¹í™” ë©´ì ‘ ì½”ì¹˜", page_icon="ğŸ¯", layout="wide")

# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ ==================
st.header("1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ")
job_url=st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="https://... (ì›í‹°ë“œ/ì‚¬ëŒì¸/ì¡ì½”ë¦¬ì•„ ë“±)")

company_state=st.session_state.setdefault("company_state", {})
if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
    soup=fetch_html(job_url) if job_url else None
    jp=extract_sections_from_job(soup) if soup else {"title":None,"responsibilities":[],"qualifications":[],"preference":[]}
    company_state["job_url"]=job_url or None
    company_state["role_title"]=jp.get("title")
    company_state["responsibilities"]=jp.get("responsibilities",[])
    company_state["qualifications"]=jp.get("qualifications",[])
    company_state["preference"]=jp.get("preference",[])
    st.success("ì •ì œ ì™„ë£Œ")

# ================== 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ==================
st.header("2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")
c = company_state
colA,colB=st.columns([2,1])
with colA:
    st.markdown(f"**íšŒì‚¬ëª…:**  {_clean(c.get('company_name') or '') or 'â€”'}")
with colB:
    st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):**  {_snippet(c.get('role_title') or '') or 'â€”'}")

st.markdown("**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½)**")
st.write(_snippet(c.get("company_intro_site") or "ì±„ìš© ê³µê³  ìƒì˜ ì†Œê°œë‚˜ ë©”íƒ€ ì„¤ëª…ì´ ì—†ìœ¼ë©´ ê³µë€ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", 500))

col1,col2,col3=st.columns(3)
with col1:
    st.subheader("ì£¼ìš” ì—…ë¬´")
    rs=c.get("responsibilities",[]) or ["(ê³µê³ ì—ì„œ ì¶”ì¶œëœ ì£¼ìš” ì—…ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.)"]
    st.markdown("\n".join([f"- {x}" for x in rs]))
with col2:
    st.subheader("ìê²© ìš”ê±´")
    qs=c.get("qualifications",[]) or ["(ê³µê³ ì—ì„œ ì¶”ì¶œëœ ìê²© ìš”ê±´ì´ ì—†ìŠµë‹ˆë‹¤.)"]
    st.markdown("\n".join([f"- {x}" for x in qs]))
with col3:
    st.subheader("ìš°ëŒ€ ì‚¬í•­")
    ps=c.get("preference",[]) or ["(ê³µê³ ì—ì„œ ì¶”ì¶œëœ ìš°ëŒ€ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.)"]
    st.markdown("\n".join([f"- {x}" for x in ps]))

with st.expander("ë””ë²„ê·¸: ê³µê³  ìš”ì•½ ìƒíƒœ"):
    lens={}
    if job_url:
        soup=fetch_html(job_url)
        if soup:
            # ë‹¨ìˆœ ê¸¸ì´ ì§€í‘œ
            bs4_len=len(_clean(soup.get_text(" ") or ""))
            lens["bs4"]=bs4_len
            lens["webbase"]=bs4_len  # ìë¦¬í‘œì‹œì
    st.json({
        "job_url": job_url,
        "lens": lens,
        "resp_cnt": len(c.get("responsibilities") or []),
        "qual_cnt": len(c.get("qualifications") or []),
        "pref_cnt": len(c.get("preference") or []),
    })

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (RAG ì¸ë±ì‹±) ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploaded=st.file_uploader("ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ íŒŒì¼ ì¶”ê°€ (PDF/TXT/MD/DOCX ê°€ëŠ¥, ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ)",
                          type=["pdf","txt","md","docx"], accept_multiple_files=True)

rag = st.session_state.setdefault("rag", {"chunks":[], "embeds":None})
if uploaded:
    texts=[]
    for f in uploaded:
        t=read_upload(f)
        if t: texts+=chunk_text(t, size=700, overlap=100)
    if texts:
        vec=embed(texts)
        if rag["embeds"] is None or rag["embeds"].size==0:
            rag["chunks"]=texts
            rag["embeds"]=vec
        else:
            rag["chunks"]+=texts
            rag["embeds"]=np.vstack([rag["embeds"], vec])
        st.success(f"ë¬¸ì„œ ì¸ë±ì‹±: ì²­í¬ {len(texts)}ê°œ ì¶”ê°€. ì´ {len(rag['chunks'])}ê°œ")

# ================== ê³µí†µ: ì§ˆë¬¸ ìƒì„±ê¸° / ì±„ì ê¸° ==================
def build_company_ctx() -> str:
    return textwrap.dedent(f"""
    [ëª¨ì§‘ ë¶„ì•¼] {c.get('role_title') or ''}
    [ì£¼ìš” ì—…ë¬´] {", ".join(c.get('responsibilities', [])[:6])}
    [ìê²© ìš”ê±´] {", ".join(c.get('qualifications', [])[:6])}
    [ìš°ëŒ€ ì‚¬í•­] {", ".join(c.get('preference', [])[:6])}
    """).strip()

def retrieve_supports(query:str, k:int=4)->List[Tuple[float,str]]:
    if rag["embeds"] is None or not rag["chunks"]:
        return []
    qv=embed([query])
    scores, idxs = cosine_topk(rag["embeds"], qv, k=k)
    return [(float(s), rag["chunks"][int(i)]) for s,i in zip(scores, idxs)]

def gen_questions(model:str, ctx:str, n:int=5)->List[str]:
    sys = ("ë„ˆëŠ” í•œêµ­ ITê¸°ì—… ë©´ì ‘ê´€ì´ë‹¤. ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜ì˜í•´ **í–‰ë™(STAR), ê¸°ìˆ  ì‹¬ì¸µ, ê°€ì¹˜ ì í•©ì„±**ì´ ì„ì´ë„ë¡ "
           f"{n}ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ë¼. ê° ë¬¸ì¥ì€ 1ì¤„.")
    user = f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}"
    r=client.chat.completions.create(model=model, temperature=0.9,
                                     messages=[{"role":"system","content":sys},
                                               {"role":"user","content":user}])
    raw=r.choices[0].message.content.strip()
    qs=[re.sub(r'^\s*\d+[.)]\s*','',x).strip() for x in raw.splitlines() if len(x.strip())>3]
    return qs[:n]

COMP_KEYS=["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def score_answer(model:str, question:str, answer:str, ctx:str, supports:List[Tuple[float,str]]):
    sup_txt="\n".join([f"- ({s:.2f}) {t[:400]}" for s,t in supports]) if supports else ""
    sys=( "ë„ˆëŠ” í˜¹ë…í•˜ì§€ë§Œ ê³µì •í•œ ë©´ì ‘ ì½”ì¹˜ë‹¤. ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ í•œêµ­ì–´ë¡œ ë‹µí•´ë¼.\n"
         "1) ì´ì : 0~100 ì •ìˆ˜ 1ê°œ\n"
         "2) ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ): ê° í•­ëª©ì— ëŒ€í•´ í•œ ì¤„ë¡œ ì—„ê²©í•˜ê²Œ\n"
         "3) ìˆ˜ì •ë³¸ ë‹µë³€(STAR)\n"
         f"4) ì—­ëŸ‰ ì ìˆ˜(0~20, ì‰¼í‘œ 5ê°œ): {', '.join(COMP_KEYS)}")
    user=(f"[ì§ˆë¬¸]\n{question}\n\n[í›„ë³´ì ë‹µë³€]\n{answer}\n\n[íšŒì‚¬/ê³µê³  ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n"
          f"[ì§€ì› ë¬¸ì„œ ë°œì·Œ]\n{sup_txt}")
    r=client.chat.completions.create(model=model, temperature=0.3,
                                     messages=[{"role":"system","content":sys},
                                               {"role":"user","content":user}])
    text=r.choices[0].message.content.strip()

    # ì´ì 
    score=None
    m=re.search(r'(\d{1,3})\s*(?:/100|ì |$)', text)
    if m: score=max(0,min(100,int(m.group(1))))
    # ì—­ëŸ‰
    nums=re.findall(r'\b(\d{1,2})\b', text.splitlines()[-1])
    comps=None
    if len(nums)>=5:
        cand=[int(x) for x in nums[:5]]
        if all(0<=x<=5 for x in cand): cand=[x*4 for x in cand]
        if all(0<=x<=10 for x in cand) and any(x>5 for x in cand): cand=[x*2 for x in cand]
        comps=[max(0,min(20,x)) for x in cand]
    return {"raw":text,"score":score,"competencies":comps}

# ================== 4) ì§ˆë¬¸ ìƒì„± Â· ë‹µë³€ Â· í”¼ë“œë°± (ì˜ˆì „ êµ¬ì¡° ë³µêµ¬) ==================
st.header("4) ì§ˆë¬¸ ìƒì„± Â· ë‹µë³€ Â· í”¼ë“œë°±")
MODEL=DEFAULT_MODEL

if "questions" not in st.session_state:
    st.session_state.questions=[]

colq1,colq2=st.columns([1,1])
with colq1:
    if st.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
        ctx=build_company_ctx()
        st.session_state.questions=gen_questions(MODEL, ctx, n=5)
with colq2:
    if st.button("ì§ˆë¬¸ ë¹„ìš°ê¸°"):
        st.session_state.questions=[]

if st.session_state.questions:
    st.markdown("**ìƒì„±ëœ ì§ˆë¬¸:**")
    for i,q in enumerate(st.session_state.questions,1):
        st.markdown(f"{i}. {q}")

sel_q = st.selectbox("ì±„ì í•  ì§ˆë¬¸ ì„ íƒ", st.session_state.questions, index=0 if st.session_state.questions else None)
user_ans = st.text_area("ë‹µë³€ ì…ë ¥", height=160, key="main_answer")

if "history" not in st.session_state:
    st.session_state.history=[]

if st.button("ì±„ì  ì‹¤í–‰", type="primary"):
    if not sel_q or not user_ans.strip():
        st.warning("ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    else:
        ctx=build_company_ctx()
        supports=retrieve_supports(sel_q + "\n" + user_ans, k=4)
        res=score_answer(MODEL, sel_q, user_ans, ctx, supports)
        st.session_state.history.append({
            "ts": pd.Timestamp.now(),
            "question": sel_q,
            "answer": user_ans,
            "score": res["score"],
            "competencies": res["competencies"],
            "feedback": res["raw"],
            "supports": supports,
        })

# ----- ê²°ê³¼ í‘œì‹œ -----
st.subheader("í”¼ë“œë°± ê²°ê³¼")
if st.session_state.history:
    last=st.session_state.history[-1]
    c1,c2=st.columns([1,3])
    with c1:
        st.metric("ì´ì (/100)", last.get("score","â€”"))
    with c2:
        st.markdown(last.get("feedback",""))

# ================== 5) íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°± (ë™ì¼ êµ¬ì¡°) ==================
st.header("5) íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")

# íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ (ìë™)
if "followup_pool" not in st.session_state:
    st.session_state.followup_pool=[]
if st.button("íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ ê°±ì‹ "):
    # ìµœê·¼ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒ”ë¡œì—… 3ê°œ ì œì•ˆ
    base_q = (st.session_state.history[-1]["question"] if st.session_state.history else "") or ""
    base_ans= (st.session_state.history[-1]["answer"] if st.session_state.history else "") or ""
    ctx=build_company_ctx()
    sys=("ë„ˆëŠ” ê¹Œë‹¤ë¡œìš´ ë©´ì ‘ê´€ì´ë‹¤. ì•„ë˜ ì§ˆë¬¸/ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ **ì‹¬ì¸µ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œ**ë¥¼ 1ì¤„ì”© ì œì•ˆí•˜ë¼. ëª¨í˜¸í•˜ë©´ ì•ˆ ëœë‹¤.")
    user=f"[ì›ì§ˆë¬¸]\n{base_q}\n\n[ê¸°ì¡´ë‹µë³€]\n{base_ans}\n\n[íšŒì‚¬/ê³µê³  ì»¨í…ìŠ¤íŠ¸]\n{ctx}"
    r=client.chat.completions.create(model=MODEL, temperature=0.7,
                                     messages=[{"role":"system","content":sys},
                                               {"role":"user","content":user}])
    lines=[re.sub(r'^\s*\d+[.)]\s*','',x).strip() for x in r.choices[0].message.content.strip().splitlines() if len(x.strip())>3]
    st.session_state.followup_pool=lines[:3]
if st.session_state.followup_pool:
    st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
    for i,q in enumerate(st.session_state.followup_pool,1):
        st.markdown(f"{i}) {q}")

followup_q = st.selectbox("ì±„ì í•  íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followup_pool, index=0 if st.session_state.followup_pool else None, key="followup_select")
followup_ans = st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=140, key="followup_answer")

if "followup_history" not in st.session_state:
    st.session_state.followup_history=[]

if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="primary"):
    if not followup_q or not followup_ans.strip():
        st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        ctx=build_company_ctx()
        supports=retrieve_supports(followup_q + "\n" + followup_ans, k=4)
        res=score_answer(MODEL, followup_q, followup_ans, ctx, supports)
        st.session_state.followup_history.append({
            "ts": pd.Timestamp.now(),
            "question": followup_q,
            "answer": followup_ans,
            "score": res["score"],
            "competencies": res["competencies"],
            "feedback": res["raw"],
            "supports": supports,
        })

# íŒ”ë¡œì—… ê²°ê³¼
if st.session_state.followup_history:
    st.subheader("íŒ”ë¡œì—… ê²°ê³¼")
    last=st.session_state.followup_history[-1]
    c1,c2=st.columns([1,3])
    with c1:
        st.metric("ì´ì (/100)", last.get("score","â€”"))
    with c2:
        st.markdown(last.get("feedback",""))

# ================== 6) ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì ) ==================
st.header("6) ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")
def to_df(hist):
    rows=[h["competencies"] for h in hist if h.get("competencies") and len(h["competencies"])==5]
    return pd.DataFrame(rows, columns=COMP_KEYS) if rows else None

main_df = to_df(st.session_state.history) or pd.DataFrame(columns=COMP_KEYS)
fup_df  = to_df(st.session_state.followup_history) or pd.DataFrame(columns=COMP_KEYS)

avg = (pd.concat([main_df, fup_df]).mean() if not pd.concat([main_df, fup_df]).empty else pd.Series([0]*5, index=COMP_KEYS)).values.tolist()
latest = (main_df.tail(1).values.tolist()[0] if len(main_df)>0 else [0]*5)

if PLOTLY_OK:
    fig=go.Figure()
    fig.add_trace(go.Scatterpolar(r=latest+[latest[0]], theta=COMP_KEYS+[COMP_KEYS[0]], fill='toself', name="ìµœì‹ (ë³¸ ì§ˆë¬¸)"))
    fig.add_trace(go.Scatterpolar(r=avg+[avg[0]], theta=COMP_KEYS+[COMP_KEYS[0]], fill='toself', name="ì„¸ì…˜ í‰ê· "))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,20])), showlegend=True, height=420)
    st.plotly_chart(fig, use_container_width=True)
else:
    st.bar_chart(pd.DataFrame({"ìµœì‹ ":latest,"í‰ê· ":avg}, index=COMP_KEYS))

# í‘œë¡œë„ í™•ì¸
tab1, tab2 = st.tabs(["ë³¸ ì§ˆë¬¸ ëˆ„ì ", "íŒ”ë¡œì—… ëˆ„ì "])
with tab1:
    if not main_df.empty:
        main_df["í•©ê³„"]=main_df.sum(axis=1)
        st.dataframe(main_df, use_container_width=True)
    else:
        st.caption("ë³¸ ì§ˆë¬¸ ì±„ì  ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
with tab2:
    if not fup_df.empty:
        fup_df["í•©ê³„"]=fup_df.sum(axis=1)
        st.dataframe(fup_df, use_container_width=True)
    else:
        st.caption("íŒ”ë¡œì—… ì±„ì  ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

st.caption("â€» â€˜ìš°ëŒ€ ì‚¬í•­â€™ì€ ì‚¬ì´íŠ¸ë³„ ë§ˆí¬ì—… ì°¨ì´ë¡œ ëˆ„ë½ ê°€ëŠ¥â€”ë³„ë„ ì²˜ë¦¬ ì˜ˆì •.")
