import os, io, re, json, textwrap, time, random
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

# ---------- Optional deps ----------
try:
    import pypdf
except Exception:
    pypdf = None

try:
    import docx2txt
except Exception:
    docx2txt = None

try:
    import plotly.graph_objects as go
    PLOTLY_OK = True
except Exception:
    PLOTLY_OK = False

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

import requests
from bs4 import BeautifulSoup

# (ì„ íƒ) WebBaseLoader â€“ ì‹¤íŒ¨í•´ë„ ì•±ì´ ë™ì‘í•˜ë„ë¡ try-import
try:
    from langchain_community.document_loaders import WebBaseLoader
    HAS_WEBBASE = True
except Exception:
    HAS_WEBBASE = False

# -------------------------------------------------
# Page
# -------------------------------------------------
st.set_page_config(page_title="íšŒì‚¬ íŠ¹í™” ì·¨ì—… ì¤€ë¹„ ì½”ì¹˜", page_icon="ğŸ¯", layout="wide")

# -------------------------------------------------
# Utils
# -------------------------------------------------
def _clean(t: str) -> str:
    t = re.sub(r"\s+", " ", t or "").strip()
    return t

def read_pdf_to_text(data: bytes) -> str:
    if pypdf is None:
        return ""
    try:
        reader = pypdf.PdfReader(io.BytesIO(data))
        pages = []
        for i in range(len(reader.pages)):
            pages.append(reader.pages[i].extract_text() or "")
        return "\n".join(pages)
    except Exception:
        return ""

def read_docx_to_text(data: bytes) -> str:
    """docx2txtëŠ” íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ì´ë¼ ì„ì‹œ íŒŒì¼ ì‚¬ìš©"""
    if docx2txt is None:
        return ""
    try:
        tmp = "/tmp/_upload.docx"
        with open(tmp, "wb") as f:
            f.write(data)
        txt = docx2txt.process(tmp) or ""
        return txt
    except Exception:
        return ""

def read_text_upload(uploaded) -> str:
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith((".txt",".md",".csv",".log")):
        for enc in ("utf-8","cp949","euc-kr","utf-16"):
            try:
                return data.decode(enc)
            except Exception:
                continue
        return data.decode("utf-8", errors="ignore")
    if name.endswith(".pdf"):
        return read_pdf_to_text(data)
    if name.endswith(".docx"):
        return read_docx_to_text(data)
    return ""

def get_api_key() -> Optional[str]:
    k = os.getenv("OPENAI_API_KEY")
    if k:
        return k
    try:
        return st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        return None

def chunk_text(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    text = re.sub(r"\s+", " ", text).strip()
    if not text: return []
    out, start = [], 0
    while start < len(text):
        end = min(len(text), start + size)
        out.append(text[start:end])
        if end == len(text): break
        start = max(0, end - overlap)
    return out

# -------------------------------------------------
# Raw page text fetchers
# -------------------------------------------------
def fetch_all_text_bs4(url: str, timeout: int = 12) -> str:
    """ê°€ëŠ¥í•œ ëª¨ë“  í…ìŠ¤íŠ¸(ë³´ì´ëŠ” ì˜ì—­ ìœ„ì£¼). ë™ì  ì˜ì—­ì€ í•œê³„."""
    try:
        if not url.startswith("http"):
            url = "https://" + url
        r = requests.get(url, timeout=timeout, headers={"User-Agent":"Mozilla/5.0"})
        if r.status_code != 200: return ""
        soup = BeautifulSoup(r.text, "html.parser")
        # ë¶ˆí•„ìš”í•œ script/style ì œê±°
        for tag in soup(["script","style","noscript"]):
            tag.decompose()
        # aria-hidden ì œì™¸
        for tag in soup.find_all(attrs={"aria-hidden":"true"}):
            tag.decompose()
        txt = soup.get_text("\n")
        # ë„ˆë¬´ ê¸´ ê³µë°± ì •ë¦¬
        txt = re.sub(r"\n{2,}", "\n", txt)
        txt = re.sub(r"[ \t]+", " ", txt)
        return txt.strip()
    except Exception:
        return ""

def fetch_all_text_webbase(url: str, timeout: int = 15) -> str:
    """WebBaseLoaderê°€ ìˆìœ¼ë©´ ì‚¬ìš© (ë‚´ë¶€ì ìœ¼ë¡œ newspaper/bs4 ë“± ì‚¬ìš©)"""
    if not HAS_WEBBASE:
        return ""
    try:
        loader = WebBaseLoader(url)
        docs = loader.load()
        body = "\n".join([d.page_content for d in docs if d and getattr(d,"page_content",None)])
        return body.strip()
    except Exception:
        return ""

def fetch_jobpage_text(url: str) -> Tuple[str, Dict[str,int], str]:
    """
    ì›ë¬¸ í…ìŠ¤íŠ¸, ì‚¬ìš©í•œ ë Œì¦ˆë³„ ê¸¸ì´, ìµœì¢… URL ë°˜í™˜
    ìš°ì„  bs4 -> webbase ìˆœìœ¼ë¡œ ì‹œë„(ë‘˜ ë‹¤ ì„±ê³µí•˜ë©´ ë” ê¸´ í…ìŠ¤íŠ¸ ì„ íƒ)
    """
    urlf = url.strip()
    lens_count = {"bs4":0, "webbase":0}
    t1 = fetch_all_text_bs4(urlf)
    lens_count["bs4"] = len(t1)
    t2 = fetch_all_text_webbase(urlf)
    lens_count["webbase"] = len(t2)
    if len(t2) > len(t1):
        return t2, lens_count, urlf
    return t1, lens_count, urlf

# -------------------------------------------------
# OpenAI
# -------------------------------------------------
API_KEY = get_api_key()
if OpenAI is None:
    st.error("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()
if not API_KEY:
    st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. (Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY)")
    st.stop()

client = OpenAI(api_key=API_KEY, timeout=30.0)
CHAT_MODEL = "gpt-4o-mini"

def call_json_completion(prompt_sys: str, prompt_user: str, max_retries: int = 2) -> dict:
    """LLMì— JSONìœ¼ë¡œ íŒŒì‹± ê°•ì œ. ì‹¤íŒ¨ì‹œ ì¬ì‹œë„."""
    schema = {
        "type": "object",
        "properties": {
            "company_name": {"type":"string"},
            "company_intro": {"type":"string"},
            "role_title": {"type":"string"},
            "responsibilities": {"type":"array", "items":{"type":"string"}},
            "qualifications": {"type":"array", "items":{"type":"string"}},
            "preferences": {"type":"array", "items":{"type":"string"}}
        },
        "required": ["company_name","company_intro","role_title","responsibilities","qualifications","preferences"]
    }
    sys = prompt_sys + "\n\në°˜ë“œì‹œ ìœ„ ìŠ¤í‚¤ë§ˆì— ë§ëŠ” **JSONë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€."
    for _ in range(max_retries+1):
        resp = client.chat.completions.create(
            model=CHAT_MODEL,
            temperature=0.2,
            messages=[{"role":"system","content":sys},
                      {"role":"user","content":prompt_user}]
        )
        txt = resp.choices[0].message.content.strip()
        # ì½”ë“œë¸”ë¡ ì œê±°
        txt = re.sub(r"^```json\s*|\s*```$", "", txt, flags=re.S)
        try:
            data = json.loads(txt)
            # í•„ìˆ˜í‚¤ ëˆ„ë½ ë³´ì •
            for k in ["responsibilities","qualifications","preferences"]:
                if not isinstance(data.get(k), list):
                    data[k] = [str(data.get(k,""))] if data.get(k) else []
            return data
        except Exception:
            continue
    return {}

# -------------------------------------------------
# Sidebar (ë””ë²„ê·¸)
# -------------------------------------------------
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    st.caption("í•„ìš” ìµœì†Œ ì„¤ì •ë§Œ ë…¸ì¶œí•©ë‹ˆë‹¤.")
    with st.expander("ë²„ì „/ìƒíƒœ (ë””ë²„ê·¸)"):
        ver_openai = None
        try:
            import openai as _op; ver_openai = getattr(_op,"__version__",None)
        except Exception: pass
        st.write({
            "openai_version": ver_openai,
            "HAS_WEBBASE": HAS_WEBBASE,
        })

# -------------------------------------------------
# 1) ì±„ìš© ê³µê³  URL â†’ ì›ë¬¸ ìˆ˜ì§‘ Â· ì •ì œ
# -------------------------------------------------
st.header("1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ")

job_url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="https://...")

colb = st.columns([1,1,1])
with colb[0]:
    if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
        if not job_url.strip():
            st.warning("ì±„ìš© ê³µê³  URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì›ë¬¸ ìˆ˜ì§‘ ì¤‘ ..."):
                raw_text, lens, final_url = fetch_jobpage_text(job_url.strip())
                st.session_state["raw_job_text"] = raw_text
                st.session_state["raw_job_lens"] = lens
                st.session_state["raw_job_urlf"] = final_url

            if not st.session_state.get("raw_job_text"):
                st.warning("ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸/ë™ì ë Œë”ë§/ë´‡ì°¨ë‹¨ ê°€ëŠ¥)")

            # -------- LLM ì •ì œ (ìš”ì•½/ì •í˜•í™”) --------
            base = st.session_state.get("raw_job_text","")
            chunked = chunk_text(base, size=1600, overlap=150)
            # ë„ˆë¬´ ê¸´ ê²½ìš° ì¼ë¶€ë§Œ (ê³¼ë„í•œ í† í° ë°©ì§€)
            material = "\n\n".join(chunked[:4]) if chunked else base

            sys = (
                "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” ì±„ìš© ê³µê³  ì›ë¬¸ì´ë‹¤. "
                "ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ì •í™•íˆ ì •ë¦¬í•˜ë¼. ì„ì˜ ìƒì„± ê¸ˆì§€:\n"
                "- company_name: íšŒì‚¬ëª…(ì—†ìœ¼ë©´ ì‚¬ì´íŠ¸/ë¸Œëœë“œëª…ì„ ì¶”ì¶œ)\n"
                "- company_intro: íšŒì‚¬ ì†Œê°œ(2~3ë¬¸ì¥)\n"
                "- role_title: ëª¨ì§‘ ë¶„ì•¼/ì§ë¬´ëª…(ì—†ìœ¼ë©´ ê³µê³  ì œëª©ì—ì„œ ì¶”ì¶œ)\n"
                "- responsibilities: ì£¼ìš”ì—…ë¬´ ë¶ˆë¦¿ 5~10ê°œ\n"
                "- qualifications: ìê²©ìš”ê±´ ë¶ˆë¦¿ 5~10ê°œ\n"
                "- preferences: ìš°ëŒ€ì‚¬í•­ ë¶ˆë¦¿ 3~10ê°œ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)\n"
            )
            user = f"[ì›ë¬¸ ì¼ë¶€]\n{material}\n\n[ì „ì²´ ê¸¸ì´] {len(base)}ì"

            data = call_json_completion(sys, user)
            st.session_state["clean_struct"] = data

# -------------------------------------------------
# 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)
# -------------------------------------------------
st.header("2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼)")

cdata = st.session_state.get("clean_struct", {})
if cdata:
    c1,c2,c3 = st.columns(3)
    with c1: st.markdown(f"**íšŒì‚¬ëª…:** {cdata.get('company_name','-')}")
    with c2: st.markdown(f"**ëª¨ì§‘ ë¶„ì•¼(ì§ë¬´ëª…):** {cdata.get('role_title','-')}")
    with c3:
        if st.session_state.get("raw_job_urlf"):
            st.link_button("ì±„ìš© ê³µê³  ì—´ê¸°", st.session_state["raw_job_urlf"])

    st.markdown(f"**ê°„ë‹¨í•œ íšŒì‚¬ ì†Œê°œ(ìš”ì•½)**\n\n{cdata.get('company_intro','-')}")
    cc = st.columns(3)
    with cc[0]:
        st.subheader("ì£¼ìš” ì—…ë¬´")
        for b in cdata.get("responsibilities",[]) or ["(ì—†ìŒ)"]:
            st.markdown(f"- {b}")
    with cc[1]:
        st.subheader("ìê²© ìš”ê±´")
        for b in cdata.get("qualifications",[]) or ["(ì—†ìŒ)"]:
            st.markdown(f"- {b}")
    with cc[2]:
        st.subheader("ìš°ëŒ€ ì‚¬í•­")
        prefs = cdata.get("preferences", [])
        if not prefs:
            st.caption("ìš°ëŒ€ ì‚¬í•­ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        for b in prefs:
            st.markdown(f"- {b}")

    with st.expander("ë””ë²„ê·¸: ê³µê³  ìš”ì•½ ìƒíƒœ"):
        st.json({
            "job_url": st.session_state.get("raw_job_urlf"),
            "lens": st.session_state.get("raw_job_lens"),
            "resp_cnt": len(cdata.get("responsibilities") or []),
            "qual_cnt": len(cdata.get("qualifications") or []),
            "pref_cnt": len(cdata.get("preferences") or []),
        })
else:
    st.info("ìƒë‹¨ì—ì„œ URLì„ ì…ë ¥í•˜ê³  â€˜ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œâ€™ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

# -------------------------------------------------
# 3) ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ â†’ ë‚´ë¶€ RAG ì¸ë±ì‹±(ìˆ¨ê¹€)
# -------------------------------------------------
st.header("3) ë‚´ ì´ë ¥ì„œ / í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
st.caption("pdf/txt/md/docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë‚´ë¶€ì ìœ¼ë¡œ ìë™ ì¸ë±ì‹±ë©ë‹ˆë‹¤. (ì˜µì…˜/ìˆ¨ê¹€ íŒŒë¼ë¯¸í„° ì‚¬ìš©)")

if "rag_chunks" not in st.session_state:
    st.session_state.rag_chunks = []

resume_files = st.file_uploader("ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ íŒŒì¼ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf","txt","md","docx"], accept_multiple_files=True)
if resume_files:
    with st.spinner("íŒŒì¼ ì¸ë±ì‹± ì¤‘..."):
        added = 0
        for up in resume_files:
            raw = read_text_upload(up)
            if raw:
                # ë‚´ë¶€ì ìœ¼ë¡œ ì‘ì€ ì²­í¬(ì´ë ¥ì„œë¼ ì§§ê¸° ë•Œë¬¸)
                chs = chunk_text(raw, size=400, overlap=80)
                st.session_state.rag_chunks.extend(chs)
                added += len(chs)
        st.success(f"ì¶”ê°€ ì²­í¬ {added}ê°œ")

# -------------------------------------------------
# 4) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ
# -------------------------------------------------
st.header("4) ì§ˆë¬¸ ìƒì„± Â· ë‹µë³€ Â· í”¼ë“œë°±")

# ë‚´ë¶€ ê³ ì • íŒŒë¼ë¯¸í„°(ë…¸ì¶œ ì œê±°)
NUM_QUESTIONS = 5
TEMPERATURE_Q = 0.9

if "generated_questions" not in st.session_state:
    st.session_state.generated_questions = []

def summarize_resume(snippets: List[str], cap: int = 1200) -> str:
    if not snippets:
        return ""
    joined = " ".join(snippets)
    return joined[:cap]

def generate_questions(clean_struct: dict, resume_snippets: List[str]) -> List[str]:
    resume_sum = summarize_resume(resume_snippets)
    ctx = textwrap.dedent(f"""
    [íšŒì‚¬ëª…] {clean_struct.get('company_name','')}
    [ì§ë¬´] {clean_struct.get('role_title','')}
    [ì£¼ìš”ì—…ë¬´] {", ".join(clean_struct.get('responsibilities',[])[:6])}
    [ìê²©ìš”ê±´] {", ".join(clean_struct.get('qualifications',[])[:6])}
    [ìš°ëŒ€ì‚¬í•­] {", ".join(clean_struct.get('preferences',[])[:6])}
    [ì§€ì›ì ì´ë ¥ì„œ ìš”ì•½] {resume_sum or '(ì—†ìŒ)'}
    """).strip()

    sys = (
        "ë„ˆëŠ” ë©´ì ‘ê´€ì´ë‹¤. íšŒì‚¬/ì§ë¬´/ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ ë°˜ì˜í•˜ì—¬ ì„œë¡œ ê´€ì ì´ ë‹¤ë¥¸ ì§ˆë¬¸ 5ê°œë¥¼ ìƒì„±í•˜ë¼. "
        "í˜•íƒœ: í•œ ì¤„ ì§ˆë¬¸. ì¤‘ë³µ/ìœ ì‚¬ ê¸ˆì§€. STAR ë‹µë³€ì„ ìœ ë„í•˜ë„ë¡ ìƒí™©Â·ì§€í‘œÂ·ê²°ì •Â·ë¦¬ìŠ¤í¬ ë“±ì„ ì„ì–´ë¼."
    )
    resp = client.chat.completions.create(
        model=CHAT_MODEL,
        temperature=TEMPERATURE_Q,
        messages=[{"role":"system","content":sys},
                  {"role":"user","content":ctx}]
    )
    raw = resp.choices[0].message.content.strip()
    qs = [re.sub(r'^\s*\d+\)\s*','',l).strip() for l in raw.splitlines() if len(l.strip())>0]
    if len(qs) > NUM_QUESTIONS:
        qs = qs[:NUM_QUESTIONS]
    return qs

qcols = st.columns([1,1,2])
with qcols[0]:
    if st.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
        if not st.session_state.get("clean_struct"):
            st.warning("ë¨¼ì € 1)~2) ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì§ˆë¬¸ ìƒì„± ì¤‘..."):
                st.session_state.generated_questions = generate_questions(
                    st.session_state["clean_struct"],
                    st.session_state.get("rag_chunks", [])
                )
                # ìƒˆ ì§ˆë¬¸ ìƒì„±ì‹œ íŒ”ë¡œì—… ì…ë ¥ ì´ˆê¸°í™”
                st.session_state["selected_followup"] = ""
                st.session_state["followup_answer"] = ""
                st.session_state["last_followup_result"] = None

with qcols[1]:
    if st.button("ì§ˆë¬¸ ë¹„ìš°ê¸°"):
        st.session_state.generated_questions = []

st.write("**ìƒì„±ëœ ì§ˆë¬¸:**")
if st.session_state.generated_questions:
    for i,q in enumerate(st.session_state.generated_questions,1):
        st.markdown(f"{i}. {q}")
else:
    st.caption("ì•„ì§ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

# ë‹µë³€ ì…ë ¥ & ì±„ì 
st.subheader("ë‹µë³€ ì…ë ¥")
answer = st.text_area("ì—¬ê¸°ì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš” (STAR ê¶Œì¥: ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)", height=180, key="main_answer")

def llm_score_and_coach_strict(clean_struct: dict, question: str, answer: str, model: str) -> dict:
    """100ì  ë§Œì  + 10ê°œ í•­ëª©(0~10â†’*10=100), ê¸°ì¤€ë³„ ì½”ë©˜íŠ¸, ìˆ˜ì •ë³¸(STAR)"""
    criteria = [
        "ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜",
        "ì‹œìŠ¤í…œì„¤ê³„","íŠ¸ë ˆì´ë“œì˜¤í”„","ì„±ëŠ¥/ë¹„ìš©","í’ˆì§ˆ/ì‹ ë¢°ì„±","ë¦¬ìŠ¤í¬ê´€ë¦¬"
    ]
    ctx = textwrap.dedent(f"""
    [íšŒì‚¬ëª…] {clean_struct.get('company_name','')}
    [ì§ë¬´] {clean_struct.get('role_title','')}
    [ì£¼ìš”ì—…ë¬´] {", ".join(clean_struct.get('responsibilities',[])[:6])}
    [ìê²©ìš”ê±´] {", ".join(clean_struct.get('qualifications',[])[:6])}
    [ìš°ëŒ€ì‚¬í•­] {", ".join(clean_struct.get('preferences',[])[:6])}
    """).strip()
    sys = (
        f"ë„ˆëŠ” í˜¹ë…í•˜ì§€ë§Œ ê³µì •í•œ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ 10ê°œ ê¸°ì¤€ì— ëŒ€í•´ 0~10ì ìœ¼ë¡œ ì±„ì í•˜ê³ , ê° ê¸°ì¤€ë³„ ì½”ë©˜íŠ¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•˜ë¼.\n"
        f"- ê¸°ì¤€: {', '.join(criteria)}\n"
        "ì´ì ì€ ê¸°ì¤€ ì ìˆ˜ë¥¼ ëª¨ë‘ í•©ì‚°í•´ 10ë°°ìˆ˜(=0~100)ë¡œ í™˜ì‚°í•˜ë¼. "
        "ë§ˆì§€ë§‰ì— STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼) í˜•ì‹ì˜ â€˜ìˆ˜ì •ë³¸ ë‹µë³€â€™ì„ ì œì‹œí•˜ë¼."
    )
    user = f"[ì§ˆë¬¸]\n{question}\n\n[ë‹µë³€]\n{answer}\n\n[íšŒì‚¬/ì§ë¬´ ì»¨í…ìŠ¤íŠ¸]\n{ctx}"
    resp = client.chat.completions.create(
        model=model, temperature=0.2,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    content = resp.choices[0].message.content.strip()
    # ì´ì  ì¶”ì¶œ
    m = re.search(r'(\d{1,3})\s*(?:/100|ì |$)', content)
    overall = int(m.group(1)) if m else None
    # ê¸°ì¤€ë³„ íŒŒì‹±
    crit_scores = {}
    for line in content.splitlines():
        # ì˜ˆ) ë¬¸ì œì •ì˜: 8/10 â€” ì½”ë©˜íŠ¸....
        mm = re.match(r'\s*([ê°€-í£A-Za-z/]+)\s*[:ï¼š]\s*(\d{1,2})\s*/\s*10', line)
        if mm:
            k = mm.group(1).strip()
            v = int(mm.group(2))
            crit_scores[k] = v*10  # 0~100í™˜ì‚°
    # ì½”ë©˜íŠ¸ ìˆ˜ì§‘
    comments = []
    for c in criteria:
        m2 = re.search(rf"{re.escape(c)}\s*[:ï¼š].*", content)
        if m2:
            comments.append(m2.group(0))
    # ìˆ˜ì •ë³¸
    revised = ""
    m3 = re.search(r"(ìˆ˜ì •ë³¸ ë‹µë³€[:ï¼š].*?$)", content, flags=re.S)
    if not m3:
        # ë‹¤ë¥¸ í˜•ì‹ ëŒ€ë¹„
        parts = content.split("\n")
        for i,ln in enumerate(parts):
            if "ìˆ˜ì •ë³¸" in ln and "ë‹µë³€" in ln:
                revised = "\n".join(parts[i+1:]).strip()
                break
    else:
        revised = m3.group(1)
    return {
        "overall_score": overall if overall is not None else sum(crit_scores.values())//10,
        "criteria_scores": crit_scores,
        "criteria_comment_lines": comments,
        "revised_answer": revised or ""
    }

# ì§ˆë¬¸ ì„ íƒ & ì±„ì 
st.subheader("ì±„ì  & ì½”ì¹­")
if st.session_state.generated_questions:
    choice = st.selectbox("ì±„ì í•  ì§ˆë¬¸ ì„ íƒ", st.session_state.generated_questions, index=0, key="selected_question_for_scoring")
    if st.button("ì±„ì  ì‹¤í–‰", type="primary"):
        if not st.session_state.get("main_answer","").strip():
            st.warning("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì±„ì  ì¤‘ ..."):
                res = llm_score_and_coach_strict(st.session_state["clean_struct"], choice, st.session_state["main_answer"], CHAT_MODEL)
                st.session_state["last_score"] = res

# ê²°ê³¼ í‘œì‹œ
st.subheader("í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.get("last_score")
if last:
    lc1, lc2 = st.columns([1,3])
    with lc1: st.metric("ì´ì (/100)", last.get("overall_score",0))
    with lc2:
        st.markdown("**ê¸°ì¤€ë³„ ê·¼ê±°(ì ìˆ˜/ê°ì /ê°œì„ ):**")
        for line in last.get("criteria_comment_lines",[]):
            st.markdown(f"- {line}")
        if last.get("revised_answer"):
            st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€(STAR)**")
            st.write(last["revised_answer"])

# -------------------------------------------------
# 5) íŒ”ë¡œì—…: ì œì•ˆ â†’ ì„ íƒ â†’ ë‹µë³€ â†’ í”¼ë“œë°±
# -------------------------------------------------
st.header("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")

def propose_followups(clean_struct: dict, question: str, answer: str) -> List[str]:
    ctx = textwrap.dedent(f"""
    [íšŒì‚¬] {clean_struct.get('company_name','')}
    [ì§ë¬´] {clean_struct.get('role_title','')}
    """)
    sys = "ë©´ì ‘ê´€ìœ¼ë¡œì„œ ìœ„ ë‹µë³€ì„ ë” ê¹Šê²Œ ê²€ì¦í•˜ê¸° ìœ„í•œ íŒ”ë¡œì—… ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•˜ë¼. í•œ ì¤„ì”©."
    user = f"{ctx}\n[ê¸°ì¡´ ì§ˆë¬¸]\n{question}\n\n[ê¸°ì¡´ ë‹µë³€]\n{answer}"
    resp = client.chat.completions.create(
        model=CHAT_MODEL, temperature=0.8,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    txt = resp.choices[0].message.content.strip()
    qs = [re.sub(r'^\s*\d+\)\s*','',l).strip() for l in txt.splitlines() if len(l.strip())>0]
    return qs[:3] if len(qs)>3 else qs

if "followups" not in st.session_state:
    st.session_state.followups = []

# íŒ”ë¡œì—… ì œì•ˆ
cols_fu = st.columns([1,1])
with cols_fu[0]:
    if st.button("íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ"):
        if not st.session_state.get("selected_question_for_scoring") or not st.session_state.get("main_answer","").strip():
            st.warning("ë¨¼ì € ì§ˆë¬¸ ì„ íƒê³¼ ë‹µë³€ ì…ë ¥/ì±„ì ì„ ì§„í–‰í•˜ì„¸ìš”.")
        else:
            st.session_state.followups = propose_followups(
                st.session_state["clean_struct"],
                st.session_state["selected_question_for_scoring"],
                st.session_state["main_answer"]
            )

# íŒ”ë¡œì—… ì„ íƒ + ë‹µë³€ ì…ë ¥ (ìœ„ì ¯ keyë§Œ ì‚¬ìš©, ëŒ€ì… ê¸ˆì§€)
st.write("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
if st.session_state.followups:
    for i,q in enumerate(st.session_state.followups,1):
        st.markdown(f"({i}) {q}")

st.selectbox(
    "ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ",
    st.session_state.followups if st.session_state.followups else ["(íŒ”ë¡œì—… ì—†ìŒ)"],
    index=0,
    key="selected_followup"
)

st.text_area(
    "íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€",
    height=160,
    key="followup_answer"
)

def score_followup(clean_struct: dict, fu_question: str, fu_answer: str) -> dict:
    # ê¸°ì¡´ ê¸°ì¤€ ì¶•ì†Œ(5ê°œ)ë¡œ ë¹ ë¥´ê²Œ
    criteria = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]
    sys = (
        f"ì•„ë˜ íŒ”ë¡œì—… ë‹µë³€ì„ 0~100ì ìœ¼ë¡œ ì±„ì í•˜ê³ , 5ê°œ ê¸°ì¤€(ê° 0~20) ì ìˆ˜ì™€ í•œì¤„ ì½”ë©˜íŠ¸ë¥¼ ì œê³µí•˜ë¼. "
        f"ê¸°ì¤€: {', '.join(criteria)}. ë§ˆì§€ë§‰ì— STAR í˜•ì‹ì˜ ì§§ì€ ë³´ì™„ë¬¸ë‹¨ì„ ì œì‹œí•˜ë¼."
    )
    user = f"[íŒ”ë¡œì—… ì§ˆë¬¸]\n{fu_question}\n\n[íŒ”ë¡œì—… ë‹µë³€]\n{fu_answer}"
    resp = client.chat.completions.create(
        model=CHAT_MODEL, temperature=0.2,
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    txt = resp.choices[0].message.content.strip()
    m = re.search(r'(\d{1,3})\s*(?:/100|ì |$)', txt)
    score = int(m.group(1)) if m else None
    # ê¸°ì¤€ ì ìˆ˜ íŒŒì‹±
    comp = []
    for line in txt.splitlines():
        mm = re.match(r'\s*([ê°€-í£A-Za-z/]+)\s*[:ï¼š]\s*(\d{1,2})\s*/\s*20', line)
        if mm:
            comp.append((mm.group(1), int(mm.group(2))))
    m3 = re.search(r"(STAR.*?$)", txt, flags=re.S)
    rev = m3.group(1) if m3 else ""
    return {"overall": score, "comp": comp, "revised": rev, "raw": txt}

if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
    fu_q = st.session_state.get("selected_followup","")
    fu_ans = st.session_state.get("followup_answer","")
    if not fu_q or fu_q == "(íŒ”ë¡œì—… ì—†ìŒ)":
        st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
    elif not fu_ans.strip():
        st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
    else:
        with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘ ..."):
            res_fu = score_followup(st.session_state.get("clean_struct",{}), fu_q, fu_ans)
        st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
        st.metric("ì´ì (/100)", res_fu.get("overall",0))
        if res_fu.get("comp"):
            st.markdown("**ê¸°ì¤€ë³„ ì ìˆ˜**")
            for k,v in res_fu["comp"]:
                st.markdown(f"- {k}: {v}/20")
        if res_fu.get("revised"):
            st.markdown("**ë³´ì™„ ì œì•ˆ(STAR)**")
            st.write(res_fu["revised"])

# -------------------------------------------------
# 6) ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )
# -------------------------------------------------
st.header("ì—­ëŸ‰ ë ˆì´ë” (ì„¸ì…˜ ëˆ„ì )")

# íˆìŠ¤í† ë¦¬ ëˆ„ì 
if "history" not in st.session_state:
    st.session_state.history = []

# ì±„ì  ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥(ë²„íŠ¼ ì§í›„ ì €ì¥í•˜ë„ë¡ ì„¤ê³„í•  ìˆ˜ë„ ìˆìŒ)
if st.session_state.get("last_score") and st.session_state.get("selected_question_for_scoring"):
    # ì¤‘ë³µ ì €ì¥ ë°©ì§€ ê°„ë‹¨ ì²˜ë¦¬: ìµœê·¼ ì§ˆë¬¸/ë‹µë³€ í•´ì‹œ
    key_sig = st.session_state["selected_question_for_scoring"] + "::" + st.session_state.get("main_answer","")[:80]
    prev = st.session_state.history[-1]["sig"] if st.session_state.history else ""
    if prev != key_sig:
        st.session_state.history.append({
            "ts": pd.Timestamp.now(),
            "question": st.session_state["selected_question_for_scoring"],
            "answer": st.session_state.get("main_answer",""),
            "score": st.session_state["last_score"].get("overall_score",0),
            "criteria_scores": st.session_state["last_score"].get("criteria_scores",{}),
            "sig": key_sig
        })

competencies = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜",
                "ì‹œìŠ¤í…œì„¤ê³„","íŠ¸ë ˆì´ë“œì˜¤í”„","ì„±ëŠ¥/ë¹„ìš©","í’ˆì§ˆ/ì‹ ë¢°ì„±","ë¦¬ìŠ¤í¬ê´€ë¦¬"]

def build_cdf(hist):
    rows = []
    for h in hist:
        row = {k: np.nan for k in competencies}
        for k,v in (h.get("criteria_scores") or {}).items():
            if k in row:
                row[k] = v//10  # 0~100 â†’ 0~10 ìŠ¤ì¼€ì¼ë¡œ í‘œì‹œ í¸ì˜
        rows.append(row)
    return pd.DataFrame(rows) if rows else None

cdf = build_cdf(st.session_state.history)
if cdf is not None and not cdf.empty:
    # í‰ê· 
    avg = cdf.mean(skipna=True).fillna(0).tolist()
    if PLOTLY_OK:
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=avg+[avg[0]], theta=competencies+[competencies[0]],
                                      fill='toself', name="ì„¸ì…˜ í‰ê· "))
        # ìµœì‹  ì ìˆ˜
        last_row = cdf.iloc[-1].fillna(0).tolist()
        fig.add_trace(go.Scatterpolar(r=last_row+[last_row[0]], theta=competencies+[competencies[0]],
                                      fill='toself', name="ìµœì‹ "))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,10])), showlegend=True, height=420)
        st.plotly_chart(fig, use_container_width=True)
    st.dataframe(cdf.fillna("-").assign(í•©ê³„=cdf.fillna(0).sum(axis=1)), use_container_width=True)
    st.caption("íŒŒë€ìƒ‰: ìµœì‹  / ì´ˆë¡ìƒ‰: ì„¸ì…˜ í‰ê· . í‘œëŠ” ê° ë‹µë³€ì˜ ìµœì‹  ì ìˆ˜(NAëŠ” '-')ì™€ ì„¸ì…˜ ëˆ„ì í•©Â·ì‹œë„íšŸìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
else:
    st.caption("ì•„ì§ ëˆ„ì  ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì±„ì ê¹Œì§€ ì™„ë£Œí•´ ë³´ì„¸ìš”.")
