###################################################################################################################
#  1. ì±„ìš© í¬í„¸ ì‚¬ì´íŠ¸ URLë¡œ ì¡°íšŒí•œ íšŒì‚¬ ì •ë³´ì™€ ë“±ë¡í•œ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì†Œì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´ì¤ë‹ˆë‹¤                  #
#  2. ì±„ìš© í¬í„¸ ì‚¬ì´íŠ¸ URL / ê¸°ì—… í™ˆí˜ì´ì§€ URL / ë‰´ìŠ¤ ê¸°ì‚¬ ë¥¼ ì°¸ê³ í•˜ì—¬ ëª¨ì˜ ë©´ì ‘ì„ ì‹¤ì‹œí•˜ê³  ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì„ í•´ì¤ë‹ˆë‹¤.#
###################################################################################################################

# Library Import ( coding: utf-8 )
# í•„ìš”í•œ 'ë„êµ¬ ìƒì(ë¼ì´ë¸ŒëŸ¬ë¦¬)'ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import os, re, json, urllib.parse, time, io, random
from typing import Optional, Tuple, Dict, List

import requests                  # ì›¹ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”(HTTP í†µì‹ ) ë¼ì´ë¸ŒëŸ¬ë¦¬
from bs4 import BeautifulSoup    # ì›¹ í˜ì´ì§€(HTML)ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Beautiful Soup)
import html2text                 # HTMLì„ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st           # ì›¹ ì•±ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë•ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd              # ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np               # ìˆ«ì ë°°ì—´(í–‰ë ¬) ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ================== ë™ì  í¬ë¡¤ë§ (Selenium) ë¼ì´ë¸ŒëŸ¬ë¦¬ ==================
# ì›¹ ë¸Œë¼ìš°ì €ë¥¼ í‰ë‚´ ë‚´ì–´ ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë„êµ¬ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
    from webdriver_manager.chrome import ChromeDriverManager
except ImportError:
    st.error("`selenium` ë° `webdriver-manager` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()


# ================== ê¸°ë³¸ ì„¤ì • ==================
st.set_page_config(page_title="Job Helper Bot", page_icon="ğŸ¤–", layout="wide")
st.title("Job Helper Bot : ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘")

# ================== OpenAI ì„¤ì • ==================
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— openaië¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# API í‚¤ ì„¤ì •
API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.stop()
client = OpenAI(api_key=API_KEY)

# ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„¤ì • í•­ëª© ë°°ì¹˜
with st.sidebar:
    st.subheader("ëª¨ë¸ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0)
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸(ë‚´ë¶€ìš©)", ["text-embedding-3-small","text-embedding-3-large"], index=0)


# ================== HTTP ë° URL ìœ í‹¸ ==================
def normalize_url(u: str) -> Optional[str]:
    """ì›¹ ì£¼ì†Œ í˜•ì‹ì„ í†µì¼í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤."""
    if not u: return None
    u = u.strip()
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u)
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

def http_get(url: str, timeout: int = 12) -> Optional[requests.Response]:
    """íŠ¹ì • URLë¡œ ì›¹ ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤ (ì •ì  í¬ë¡¤ë§ ë° Jina í”„ë¡ì‹œìš©)."""
    try:
        r = requests.get(url,
                         headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                                  "Accept-Language": "ko, en;q=0.9"}, timeout=timeout,)
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

def html_to_text(html_str: str) -> str:
    """HTML ì½”ë“œë¥¼ ì½ê¸° ì‰¬ìš´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    conv = html2text.HTML2Text()
    conv.ignore_links = True
    conv.ignore_images = True
    conv.body_width = 0
    txt = conv.handle(html_str)
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()


# ================== Selenium ë“œë¼ì´ë²„ ì„¤ì • (ë™ì  í¬ë¡¤ë§ ì¤€ë¹„) ==================
@st.cache_resource
def get_chrome_driver():
    """Selenium Chrome ë“œë¼ì´ë²„ë¥¼ ì„¤ì •í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36")
    options.add_experimental_option('excludeSwitches', ['enable-logging'])

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    except WebDriverException as e:
        st.error(f"Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨. Selenium/WebDriver ì„¤ì • ë° í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: {e}")
        return None

_SELENIUM_DRIVER = get_chrome_driver()


# ================== ì›ë¬¸ ìˆ˜ì§‘ (Jina â†’ Selenium â†’ BS4 í´ë°±) ==================
def fetch_jina_text(url: str, timeout: int = 15) -> str:
    """Jina AI í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ (ë™ì  í˜ì´ì§€ì—ë„ ìœ ë¦¬)."""
    try:
        parts = urllib.parse.urlsplit(url)
        prox = f"https://r.jina.ai/http://{parts.netloc}{parts.path}"
        if parts.query: prox += f"?{parts.query}"
        r = http_get(prox, timeout=timeout)
        return r.text.strip() if r else ""
    except Exception:
        return ""

def fetch_selenium_text(url: str) -> str:
    """Seleniumì„ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ ë¡œë“œ ë° 'ë”ë³´ê¸°' í´ë¦­ í›„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ë™ì  í¬ë¡¤ë§)."""
    driver = _SELENIUM_DRIVER
    if not driver:
        return ""

    try:
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )

        # 'ë”ë³´ê¸°' ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
        buttons_to_click = [(By.XPATH, "//button[contains(text(), 'ë”ë³´ê¸°')]"),
                            (By.XPATH, "//button[contains(text(), 'í¼ì¹˜ê¸°')]"),
                            (By.CSS_SELECTOR, "div.btn_detail_view button"),
                            (By.CSS_SELECTOR, "a.btn_more")]

        clicked = False
        for by, selector in buttons_to_click:
            try:
                more_button = WebDriverWait(driver, 1.5).until(
                    EC.element_to_be_clickable((by, selector))
                )
                if more_button.is_displayed():
                    more_button.click()
                    time.sleep(1.5)
                    clicked = True
                    break
            except (TimeoutException, NoSuchElementException):
                continue
            except Exception:
                continue
        
        if clicked:
             st.info("ë™ì  í¬ë¡¤ë§: 'ë”ë³´ê¸°/í¼ì¹˜ê¸°' ë²„íŠ¼ í´ë¦­ ì„±ê³µ.")

        final_html = driver.page_source
        return html_to_text(final_html)

    except TimeoutException:
        st.warning(f"ë™ì  í¬ë¡¤ë§: í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼: {url}")
        return html_to_text(driver.page_source if driver else "")
    except Exception as e:
        st.error(f"ë™ì  í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

def fetch_bs4_text(html_str: str) -> Tuple[str, Optional[BeautifulSoup]]:
    """HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì£¼ìš” ì½˜í…ì¸  ë¸”ë¡ ìš°ì„ , ì •ì  í¬ë¡¤ë§ í´ë°±ìš©)."""
    if not html_str: return "", None
    soup = BeautifulSoup(html_str, "lxml")
    blocks = []
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True)
            if txt and len(txt) > 300:
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    if not blocks:
        return soup.get_text(" ", strip=True)[:120000], soup
    
    seen, out = set(), []
    for b in blocks:
        if b not in seen:
            seen.add(b); out.append(b)
    return ("\n\n".join(out)[:120000], soup)


def fetch_all_text(url: str):
    """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• 3ê°€ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None
    
    # 1. Jina AI ì‹œë„
    jina = fetch_jina_text(url)
    if jina:
        r = http_get(url, timeout=12)
        soup = BeautifulSoup(r.text, "lxml") if r else None
        return jina, {"source":"jina","len":len(jina),"url_final":url}, soup
    
    # 2. Selenium ë™ì  í¬ë¡¤ë§ ì‹œë„
    if _SELENIUM_DRIVER:
        selenium_text = fetch_selenium_text(url)
        if selenium_text and len(selenium_text) > 500:
            return selenium_text, {"source":"selenium_dynamic","len":len(selenium_text),"url_final":url}, None

    # 3. ì¼ë°˜ì ì¸ ì •ì  í¬ë¡¤ë§ ì‹œë„
    r = http_get(url, timeout=12)
    if not r: return "", {"source":"failed_all","len":0,"url_final":url}, None
    
    bs_text, soup = fetch_bs4_text(r.text) 
    return bs_text, {"source":"bs4_fallback","len":len(bs_text),"url_final":url}, soup


# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    """HTML ë©”íƒ€ íƒœê·¸ì™€ ì œëª©ì—ì„œ íšŒì‚¬ëª…, ì†Œê°œ, ì§ë¬´ëª…ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    # íšŒì‚¬ ì´ë¦„ í›„ë³´ ì°¾ê¸° (og:site_name, application-name, title íƒœê·¸ ìˆœì„œ)
    cand = []
    # (HTML íƒœê·¸ ë¶„ì„ ë¡œì§)
    meta["company_name"] = cand[0] if cand else ""
    # íšŒì‚¬ ì†Œê°œ (description ë©”íƒ€ íƒœê·¸)
    # (íšŒì‚¬ ì†Œê°œ ë¡œì§)
    # ì§ë¬´ëª… (og:title, h1, h2 íƒœê·¸ ìˆœì„œ)
    # (ì§ë¬´ëª… ë¡œì§)
    return meta

# ================== ê·œì¹™ íŒŒì„œ ==================
def rule_based_sections(raw_text: str) -> dict:
    """í…ìŠ¤íŠ¸ì—ì„œ 'ì£¼ìš” ì—…ë¬´', 'ìê²© ìš”ê±´', 'ìš°ëŒ€ ì‚¬í•­'ê³¼ ê°™ì€ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # (ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ë¡œì§)
    return {}

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
PROMPT_SYSTEM_STRUCT = ("ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
                        "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
                        "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼.")

def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš© ê³µê³  ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ ì •ì œí•©ë‹ˆë‹¤."""
    ctx = (raw_text or "").strip()
    if len(ctx) > 14000:
        ctx = ctx[:14000]

    user_msg = {"role": "user",
                "content": ("ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
                            "íšŒì‚¬: {company_name}\n"
                            "ì§ë¬´: {job_title}\n\n"
                            "ì›ë¬¸:\n{ctx}"
                            "\n\nê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ë¼:\n"
                            "{{'company_name':'', 'company_intro':'', 'job_title':'', 'requirements':[], 'preferred':[], 'responsibilities':[], 'etc':[]}}"
                            ).format(company_name=meta_hint.get("company_name",""), job_title=meta_hint.get("job_title",""), ctx=ctx)
                }
    try:
        resp = client.chat.completions.create(model=model, temperature=0.2,
                                              response_format={"type": "json_object"},
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg])
        data = json.loads(resp.choices[0].message.content)
    except Exception as e:
        data = {"company_name": meta_hint.get("company_name",""),
                "company_intro": meta_hint.get("company_intro",""),
                "job_title": meta_hint.get("job_title",""),
                "requirements": [], "preferred": [], "responsibilities": [], "etc": [],
                "error": str(e)}

    # í›„ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ ì •ë¦¬)
    for key in ['requirements', 'preferred', 'responsibilities', 'etc']:
        if isinstance(data.get(key), list):
            data[key] = [item[:100] for item in data[key] if isinstance(item, str) and item.strip()][:10]
    return data

# ================== íŒŒì¼ ë¦¬ë” (PDF/TXT/MD/DOCX) ==================
try:
    import pypdf
except Exception:
    pypdf = None
try:
    import docx
except Exception:
    docx = None

def read_pdf(data: bytes) -> str:
    """PDF íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # (PDF ì½ê¸° ë¡œì§)
    return "PDF íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ (pypdf ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)"

def read_docx(data: bytes) -> str:
    """DOCX íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # (DOCX ì½ê¸° ë¡œì§)
    return "DOCX íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ (docx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)"

def read_file_text(uploaded) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì¢…ë¥˜(txt, pdf, docx ë“±)ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    else:
        try:
            return data.decode("utf-8")
        except:
            return data.decode("latin-1")
    return ""

# ================== ê°„ë‹¨ ì²­í¬/ì„ë² ë”©(ë‚´ë¶€ ìë™) ==================
def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¼ì •í•œ í¬ê¸°(size)ë¡œ ìë¥´ê³  ë‹¤ìŒ ì¡°ê°ê³¼ ê²¹ì¹˜ê²Œ(overlap) ë§Œë“­ë‹ˆë‹¤."""
    # (ì²­í¬ ë¶„í•  ë¡œì§)
    return ["ì²­í¬ 1", "ì²­í¬ 2"]

def embed_texts(texts: List[str], model_name: str) -> np.ndarray:
    """í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì ë²¡í„°(ì„ë² ë”©)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=model_name, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    """ì§ˆë¬¸ ë²¡í„°ì™€ ê°€ì¥ ìœ ì‚¬í•œ(ì½”ì‚¬ì¸ ìœ ì‚¬ë„) ìƒìœ„ Kê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì°¾ìŠµë‹ˆë‹¤."""
    # (ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§)
    return np.array([1.0]*k), np.array([0]*k)

def retrieve_resume_chunks(query: str, k: int = 4):
    """ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ì´ë ¥ì„œì˜ í…ìŠ¤íŠ¸ ì¡°ê°(ì²­í¬)ì„ ê²€ìƒ‰(RAG)í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
    if not chs or embs is None:
        return []
    qv = embed_texts([query], EMBED_MODEL)
    scores, idxs = cosine_topk(embs, qv, k=k)
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ ==================
VISION_KEYS = ["ë¹„ì „","ë¯¸ì…˜","í•µì‹¬ê°€ì¹˜","ê°€ì¹˜","ì›ì¹™","ë¬¸í™”","í–‰ë™ê°•ë ¹","Talent","ì¸ì¬ìƒ","Our Mission","Vision","Values"]

def safe_get_text(el) -> str:
    """BeautifulSoup ìš”ì†Œì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    return el.get_text(" ", strip=True) if el else ""

def fetch_company_pages(home_url: str) -> Dict[str, List[str]]:
    """íšŒì‚¬ í™ˆí˜ì´ì§€ì™€ ì£¼ìš” ì„œë¸Œ ê²½ë¡œì—ì„œ 'ë¹„ì „/ê°€ì¹˜' ë° 'ì¸ì¬ìƒ' ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤."""
    # (ìŠ¤í¬ë˜í•‘ ë¡œì§)
    return {"vision": ["ë¹„ì „ ë‚´ìš©"], "talent": ["ì¸ì¬ìƒ ë‚´ìš©"]}

def fetch_latest_news(company: str, max_items: int = 5) -> List[Dict]:
    """íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # (ë‰´ìŠ¤ ê²€ìƒ‰ ë¡œì§)
    return [{"title": "ë‰´ìŠ¤ ì œëª©", "link": "#"}]

# ================== ì§ˆë¬¸/ì´ˆì•ˆ/ì±„ì /íŒ”ë¡œì—… í”„ë¡¬í”„íŠ¸ ==================
PROMPT_SYSTEM_Q = ("ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´, ê·¸ë¦¬ê³  ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ í•¨ê»˜ ê³ ë ¤í•´ "
                   "ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. ì§ˆë¬¸ì€ ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , "
                   "ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ ë“±ë„ ì„ì–´ë¼.")
PROMPT_SYSTEM_DRAFT = ("ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ ê²°í•©í•´ "
                       "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ **ì´ˆì•ˆ**ì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
                       "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼.")
PROMPT_SYSTEM_SCORE_STRICT = ("ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
                              "{{'total_score': 0, 'comment_score_problem': '', 'comment_score_data': '', 'comment_score_execution': '', 'comment_score_collaboration': '', 'comment_score_customer': '', 'risks': [], 'strengths': [], 'improvement': [], 'revised_answer': ''}} "
                              "ê° ê¸°ì¤€ì— ëŒ€í•´ ì§§ì§€ë§Œ êµ¬ì²´ì  ì½”ë©˜íŠ¸(ê°•ì /ê°ì ìš”ì¸/ê°œì„ í¬ì¸íŠ¸)ë¥¼ ì œê³µí•˜ë¼.")
CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_one_question_with_resume(clean: Dict, level: str, model: str) -> str:
    """íšŒì‚¬/ì§ë¬´ ì •ë³´ì™€ ì´ë ¥ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    hits = retrieve_resume_chunks("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", k=4)
    resume_snips = [t for _, t in hits]
    resume_context = "\n".join([f"- {s[:350]}" for s in resume_snips])[:1200]
    # (LLM í˜¸ì¶œ ë¡œì§)
    return "ìƒì„±ëœ ë©´ì ‘ ì§ˆë¬¸ì…ë‹ˆë‹¤."

def llm_draft_answer(clean: Dict, question: str, model: str) -> str:
    """ì§ˆë¬¸ê³¼ ì´ë ¥ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ STAR ê¸°ë°˜ì˜ ë‹µë³€ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    hits = retrieve_resume_chunks(question, k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    # (LLM í˜¸ì¶œ ë¡œì§)
    return "ìƒì„±ëœ STAR ê¸°ë°˜ì˜ ë‹µë³€ ì´ˆì•ˆì…ë‹ˆë‹¤."

def llm_score_and_coach_strict(clean: Dict, question: str, answer: str, model: str) -> Dict:
    """ì§ˆë¬¸, ë‹µë³€, ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    hits = retrieve_resume_chunks(question + "\n" + answer[:800], k=4)
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    # (LLM í˜¸ì¶œ ë¡œì§)
    return {"total_score": 75, 
            "comment_score_problem": "í”¼ë“œë°±1",
            "comment_score_data": "í”¼ë“œë°±2",
            "comment_score_execution": "í”¼ë“œë°±3",
            "comment_score_collaboration": "í”¼ë“œë°±4",
            "comment_score_customer": "í”¼ë“œë°±5",
            "risks": ["ë¦¬ìŠ¤í¬1"], "strengths": ["ê°•ì 1"], "improvement": ["ê°œì„ 1"], 
            "revised_answer": "ìˆ˜ì •ëœ ë‹µë³€ì…ë‹ˆë‹¤."}

# ================== ì„¸ì…˜ ìƒíƒœ ==================
def _init_state():
    """Streamlit ì•±ì„ ìœ„í•œ ë³€ìˆ˜(ì„¸ì…˜ ìƒíƒœ)ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if 'raw_text' not in st.session_state: st.session_state.raw_text = ""
    if 'fetch_info' not in st.session_state: st.session_state.fetch_info = {}
    if 'clean_struct' not in st.session_state: st.session_state.clean_struct = {}
    if 'company_vision' not in st.session_state: st.session_state.company_vision = []
    if 'company_talent' not in st.session_state: st.session_state.company_talent = []
    if 'latest_news' not in st.session_state: st.session_state.latest_news = []
    if 'resume_text' not in st.session_state: st.session_state.resume_text = ""
    if 'resume_chunks' not in st.session_state: st.session_state.resume_chunks = []
    if 'resume_embeds' not in st.session_state: st.session_state.resume_embeds = None
    if 'current_question' not in st.session_state: st.session_state.current_question = ""
    if 'draft_answer' not in st.session_state: st.session_state.draft_answer = ""
    if 'answer_text' not in st.session_state: st.session_state.answer_text = ""
    if 'last_result' not in st.session_state: st.session_state.last_result = None
    if 'followups' not in st.session_state: st.session_state.followups = []
    if 'last_followup_result' not in st.session_state: st.session_state.last_followup_result = None
    if 'selected_followup' not in st.session_state: st.session_state.selected_followup = ""
    if 'followup_answer' not in st.session_state: st.session_state.followup_answer = ""

_init_state()


# ================== 1) ì±„ìš© ê³µê³  URL â†’ ì •ì œ ==================
st.header("1) ì±„ìš© ê³µê³  URL")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì·¨ì—… í¬í„¸ ì‚¬ì´íŠ¸ì˜ URLì„ ì…ë ¥í•˜ì„¸ìš”.")

st.text_input("íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL (ì„ íƒ)", key="company_home", placeholder="íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner(f"URL ìˆ˜ì§‘ ë° ì •ì œ ì¤‘... (ìµœëŒ€ 30ì´ˆ ì†Œìš”, í˜„ì¬ ëª¨ë“œ: {_SELENIUM_DRIVER.name if _SELENIUM_DRIVER else 'Static Fallback'})"):
            raw_text, info, soup = fetch_all_text(url)
        
        if not raw_text.strip():
            st.error(f"URL ìˆ˜ì§‘ ì‹¤íŒ¨: {url}")
            st.session_state.clean_struct = {}
        else:
            meta_hint = extract_company_meta(soup)
            st.session_state.raw_text = raw_text
            st.session_state.fetch_info = info
            
            clean_struct = llm_structurize(raw_text, meta_hint, CHAT_MODEL)
            st.session_state.clean_struct = clean_struct
            
            if st.session_state.company_home:
                company_pages = fetch_company_pages(st.session_state.company_home)
                st.session_state.company_vision = company_pages.get("vision", [])
                st.session_state.company_talent = company_pages.get("talent", [])
            else:
                st.session_state.company_vision = []
                st.session_state.company_talent = []

            if clean_struct.get("company_name"):
                st.session_state.latest_news = fetch_latest_news(clean_struct["company_name"])
            else:
                st.session_state.latest_news = []
                
            st.success("ì •ì œ ì™„ë£Œ!")

# ================== 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ==================
st.header("2) íšŒì‚¬ ìš”ì•½")
clean = st.session_state.clean_struct
if clean:
    st.subheader(clean.get("company_name", "íšŒì‚¬ëª… ì •ë³´ ì—†ìŒ"))
    st.caption(f"ì§ë¬´: {clean.get('job_title', 'ì§ë¬´ ì •ë³´ ì—†ìŒ')}")
    st.markdown(f"**íšŒì‚¬ ì†Œê°œ:** {clean.get('company_intro', '-')}")
    
    st.markdown("**ì£¼ìš” ì—…ë¬´:**")
    for item in clean.get("responsibilities", []): st.markdown(f"- {item}")
    st.markdown("**ìê²© ìš”ê±´:**")
    for item in clean.get("requirements", []): st.markdown(f"- {item}")
    st.markdown("**ìš°ëŒ€ ì‚¬í•­:**")
    for item in clean.get("preferred", []): st.markdown(f"- {item}")

# VISION/NEWS: íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ (ìˆì„ ë•Œë§Œ í‘œì‹œ)
if st.session_state.company_vision or st.session_state.latest_news:
    st.subheader("íšŒì‚¬/ì§ë¬´ ë³´ì¡° ì •ë³´")
    if st.session_state.company_vision:
        st.markdown("**ë¹„ì „/í•µì‹¬ê°€ì¹˜:**")
        for item in st.session_state.company_vision: st.markdown(f"- {item}")
    if st.session_state.latest_news:
        st.markdown("**ìµœì‹  ë‰´ìŠ¤:**")
        for item in st.session_state.latest_news: st.markdown(f"- [{item.get('title', 'ì œëª© ì—†ìŒ')}]({item.get('link', '#')})")

st.divider()

# ================== 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ (PDF/TXT/MD/DOCX) ==================
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploads = st.file_uploader("ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ ê°€ëŠ¥", type=["pdf","txt","md","docx"], accept_multiple_files=True)
_RESUME_CHUNK = 500
_RESUME_OVLP  = 100

cols_idx = st.columns(2)
with cols_idx[0]:
    if st.button("ì´ë ¥ì„œ ì¸ë±ì‹±", type="secondary"):
        if uploads:
            full_text = ""
            with st.spinner("íŒŒì¼ ì½ëŠ” ì¤‘..."):
                for uploaded_file in uploads:
                    full_text += read_file_text(uploaded_file) + "\n\n"
            
            if full_text.strip():
                st.session_state.resume_text = full_text
                chunks_list = chunk(full_text, _RESUME_CHUNK, _RESUME_OVLP)
                
                with st.spinner("í…ìŠ¤íŠ¸ ë²¡í„°í™” ì¤‘..."):
                    embeds = embed_texts(chunks_list, EMBED_MODEL)
                    st.session_state.resume_chunks = chunks_list
                    st.session_state.resume_embeds = embeds
                st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks_list)}ê°œ)")
            else:
                st.warning("ì½ì„ ìˆ˜ ìˆëŠ” íŒŒì¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì´ë ¥ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

st.divider()

# ================== 4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„± ==================
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ(ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“±")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    system = ("ë„ˆëŠ” í•œêµ­ì–´ ìê¸°ì†Œê°œì„œ ì „ë¬¸ê°€ë‹¤. ì±„ìš© ê³µê³ ì˜ íšŒì‚¬/ì§ë¬´ ìš”ê±´ê³¼ í›„ë³´ìì˜ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•´ "
              "íšŒì‚¬ íŠ¹í™” ìì†Œì„œë¥¼ ì‘ì„±í•œë‹¤. ê³¼ì¥/í—ˆìœ„ëŠ” ê¸ˆì§€í•˜ê³ , ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´í™”í•œë‹¤. "
              "íšŒì‚¬ì˜ ë¹„ì „/ì¸ì¬ìƒ/ìµœê·¼ ì´ìŠˆê°€ ì œê³µë˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ë¼.")
    user_prompt = (f"## ì±„ìš© ê³µê³  ìš”ì•½\n{json.dumps(clean_struct, ensure_ascii=False, indent=2)}\n\n"
                   f"## ë‚´ ì´ë ¥ì„œ ë‚´ìš©\n{resume_text}\n\n"
                   f"## ìš”ì²­ ì£¼ì œ\n{topic_hint}\n\n"
                   "ì£¼ì œì— ë§ì¶° 500ì ë‚´ì™¸ë¡œ ìì†Œì„œë¥¼ ì‘ì„±í•˜ê³ , ì‘ì„± í›„ì—ëŠ” ë°˜ë“œì‹œ ìµœì¢…ë³¸ë§Œ ë°˜í™˜í•˜ë¼.")
    
    resp = client.chat.completions.create(model=model, temperature=0.7,
                                          messages=[{"role":"system","content":system}, {"role":"user", "content": user_prompt}])
    return resp.choices[0].message.content.strip()

if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € ì±„ìš© ê³µê³ ë¥¼ ì •ì œí•˜ì„¸ìš”.")
    elif not st.session_state.resume_text:
        st.warning("ì´ë ¥ì„œ íŒŒì¼ì„ ì¸ë±ì‹±í•˜ì„¸ìš”.")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cl_draft = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_text, topic, CHAT_MODEL)
        st.session_state.cover_letter = cl_draft
        st.success("ìì†Œì„œ ìƒì„± ì™„ë£Œ.")

if st.session_state.get('cover_letter'):
    st.subheader("ìƒì„±ëœ ìê¸°ì†Œê°œì„œ")
    st.text_area("ìµœì¢… ì´ˆì•ˆ", value=st.session_state.cover_letter, height=300)
    st.download_button("ìì†Œì„œ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", st.session_state.cover_letter, file_name="cover_letter_draft.txt")

st.divider()

# ================== 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©) ==================
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

cols_q = st.columns(2)
with cols_q[0]:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct or not st.session_state.resume_embeds is not None:
            st.warning("ì±„ìš© ê³µê³  ì •ì œ ë° ì´ë ¥ì„œ ì¸ë±ì‹±ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        else:
            with st.spinner("ì§ˆë¬¸ ìƒì„± ì¤‘..."):
                st.session_state.current_question = llm_generate_one_question_with_resume(st.session_state.clean_struct, level, CHAT_MODEL)
                st.session_state.draft_answer = ""
                st.session_state.answer_text = ""
                st.session_state.last_result = None
                st.session_state.followups = []

with cols_q[1]:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € 'ìƒˆ ì§ˆë¬¸ ë°›ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
        else:
            with st.spinner("ë‹µë³€ ì´ˆì•ˆ ìƒì„± ì¤‘..."):
                st.session_state.draft_answer = llm_draft_answer(st.session_state.clean_struct, st.session_state.current_question, CHAT_MODEL)
                st.session_state.answer_text = st.session_state.draft_answer

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
ans = st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•´ ì™„ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# ================== 6) ì±„ì  & ì½”ì¹­ (ì—„ê²© ëª¨ë“œ) ==================
st.header("6) ì±„ì  & ì½”ì¹­")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question or not st.session_state.answer_text.strip():
        st.warning("ì§ˆë¬¸ì„ ë°›ê³  ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
    else:
        with st.spinner("ë‹µë³€ ì±„ì  ë° ì½”ì¹­ ì¤‘..."):
            st.session_state.last_result = llm_score_and_coach_strict(st.session_state.clean_struct, st.session_state.current_question, st.session_state.answer_text, CHAT_MODEL)
            st.session_state.followups = ["íŒ”ë¡œì—… ì§ˆë¬¸ 1", "íŒ”ë¡œì—… ì§ˆë¬¸ 2", "íŒ”ë¡œì—… ì§ˆë¬¸ 3"]

# ================== 7) í”¼ë“œë°± ê²°ê³¼ (ì•„ë˜ì— íŒ”ë¡œì—… ì¸ë¼ì¸ ë°°ì¹˜) ==================
st.header("7) í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.last_result
if last:
    st.metric("ì´ì (/100)", last.get("total_score", "N/A"))
    
    st.markdown("---")
    st.markdown("**ê¸°ì¤€ë³„ ì½”ë©˜íŠ¸**")
    for criterion in CRITERIA:
        key = f"comment_score_{criterion.split('/')[0].lower()}"
        st.caption(f"**{criterion}:** {last.get(key, '-')}")

    st.markdown("---")
    st.markdown("**ê°•ì  & ë¦¬ìŠ¤í¬ & ê°œì„  í¬ì¸íŠ¸**")
    st.success(f"**ê°•ì :** {', '.join(last.get('strengths', []))}")
    st.error(f"**ë¦¬ìŠ¤í¬:** {', '.join(last.get('risks', []))}")
    st.info(f"**ê°œì„  í¬ì¸íŠ¸:** {', '.join(last.get('improvement', []))}")
    
    st.markdown("---")
    st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR ì ìš©)**")
    st.text_area("LLM ìˆ˜ì •ë³¸", value=last.get('revised_answer', '-'), height=200)

else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# ================== 8) íŒ”ë¡œì—… ì§ˆë¬¸ â†’ ë‹µë³€ â†’ íŒ”ë¡œì—… í”¼ë“œë°± ==================
st.subheader("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")
last = st.session_state.last_result
if last:
    if st.session_state.followups:
        st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
        for i, f in enumerate(st.session_state.followups, 1):
            st.markdown(f"- ({i}) {f}")

        st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0, key="selected_followup")
        st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")
        
        if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
            fu_q   = st.session_state.get("selected_followup", "")
            fu_ans = st.session_state.get("followup_answer", "")
            if not fu_q:
                st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif not fu_ans.strip():
                st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
            else:
                with st.spinner("íŒ”ë¡œì—… ì±„ì  ì¤‘..."):
                    res_fu = llm_score_and_coach_strict(st.session_state.clean_struct, fu_q, fu_ans, CHAT_MODEL)
                st.session_state.last_followup_result = res_fu
                st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
                st.metric("ì´ì (/100)", res_fu.get("total_score", "N/A"))
                st.text_area("íŒ”ë¡œì—… í”¼ë“œë°±", value=res_fu.get('revised_answer', '-'), height=150)
    else:
        st.caption("íŒ”ë¡œì—… ì§ˆë¬¸ì€ ë©”ì¸ ì§ˆë¬¸ ì±„ì  ì§í›„ ìë™ ì œì•ˆë©ë‹ˆë‹¤.")