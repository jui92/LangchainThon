###################################################################################################################
#  [Job Helper Bot] : ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ìê¸°ì†Œê°œì„œ ìƒì„± ë° ëª¨ì˜ ë©´ì ‘ ì½”ì¹­ ì‹œìŠ¤í…œ                                          #
#  1. ì±„ìš© í¬í„¸ URLê³¼ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì†Œì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.                                                     #
#  2. íšŒì‚¬ ì •ë³´ì™€ ì´ë ¥ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë©´ì ‘ ì§ˆë¬¸ì„ ë§Œë“¤ê³  ë‹µë³€ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.                                       #
###################################################################################################################

# Library Import ( coding: utf-8 )
# í•„ìš”í•œ 'ë„êµ¬ ìƒì(ë¼ì´ë¸ŒëŸ¬ë¦¬)'ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import os, re, json, urllib.parse, time, io, random
from typing import Optional, Tuple, Dict, List # íŒŒì´ì¬ ì½”ë“œì˜ ìë£Œí˜•(íƒ€ì…)ì„ ëª…í™•í•˜ê²Œ í‘œì‹œí•˜ê¸° ìœ„í•œ ë„êµ¬

# ì›¹ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„ ë„êµ¬
import requests # ì›¹ ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” 'ì¸í„°ë„· ì—°ê²°' ë„êµ¬
from bs4 import BeautifulSoup # ì›¹ í˜ì´ì§€(HTML)ë¥¼ ë¶„ì„í•˜ê³  ì •ë³´ë¥¼ ë½‘ì•„ë‚´ëŠ” 'HTML ë¶„ì„' ë„êµ¬
import html2text # HTML ì½”ë“œë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ëŠ” ë„êµ¬

# ì›¹ ì•± êµ¬ì¶• ë° ë°ì´í„° ì²˜ë¦¬ ë„êµ¬
import streamlit as st # ì›¹ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê¹”ë”í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI)ë¥¼ ì‰½ê²Œ ë§Œë“œëŠ” ë„êµ¬
import pandas as pd # ë°ì´í„°ë¥¼ í‘œ(í…Œì´ë¸”) í˜•íƒœë¡œ ë‹¤ë£¨ê¸° ìœ„í•œ ë„êµ¬ (ê¸°ë³¸ ê¸°ëŠ¥ ì œê³µ)
import numpy as np # ìˆ«ì ë°°ì—´(ë²¡í„°)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ìœ„í•œ ë„êµ¬ (AI ê²€ìƒ‰ì— í•„ìˆ˜)

# íŒŒì¼ ì²˜ë¦¬ ë„êµ¬ (ì´ë ¥ì„œ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤)
try:
    import pypdf # PDF íŒŒì¼ ì½ê¸°ìš©
except ImportError:
    pypdf = None
try:
    from docx import Document as DocxDocument # DOCX íŒŒì¼ ì½ê¸°ìš©
except ImportError:
    DocxDocument = None

# ================== ê¸°ë³¸ ì„¤ì • ==================
st.set_page_config(page_title="Job Helper Bot", page_icon="ğŸ¤–", layout="wide")
st.title("Job Helper Bot : ìì†Œì„œ ìƒì„± / ëª¨ì˜ ë©´ì ‘")

# ================== OpenAI (AI ë‘ë‡Œ) ì„¤ì • ==================
try:
    from openai import OpenAI
except ImportError:
    st.error("`openai` íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install openai`ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    st.stop()

# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë‚˜ Streamlitì˜ ë¹„ë°€ ì €ì¥ì†Œì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
API_KEY = os.getenv("OPENAI_API_KEY") or (st.secrets.get("OPENAI_API_KEY", None) if hasattr(st, "secrets") else None)
if not API_KEY:
    # í‚¤ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì…ë ¥ë°›ì•„ ë³´ì•ˆ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    API_KEY = st.text_input("OPENAI_API_KEY ì…ë ¥", type="password")
if not API_KEY:
    st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ì•±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()
client = OpenAI(api_key=API_KEY) # OpenAI í´ë¼ì´ì–¸íŠ¸(í†µì‹  ë‹´ë‹¹ ê°ì²´)ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

# ì‚¬ì´ë“œë°”(ì™¼ìª½ íŒ¨ë„)ì— AI ëª¨ë¸ ì„¤ì •ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.
with st.sidebar:
    st.subheader("ëª¨ë¸ ì„¤ì •")
    CHAT_MODEL = st.selectbox("ëŒ€í™”/ìƒì„± ëª¨ë¸", ["gpt-4o-mini","gpt-4o"], index=0) # ëŒ€í™”ì™€ í…ìŠ¤íŠ¸ ìƒì„±ì— ì‚¬ìš©í•  AI ëª¨ë¸ ì„ íƒ
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸(ë‚´ë¶€ ê²€ìƒ‰ìš©)", ["text-embedding-3-small","text-embedding-3-large"], index=0) # í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸ ì„ íƒ

# ================== HTTP ë° URL ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==================
@st.cache_data
def normalize_url(u: str) -> Optional[str]:
    """ì›¹ ì£¼ì†Œ(URL) í˜•ì‹ì„ í†µì¼í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤. (ì˜ˆ: http://ê°€ ì—†ìœ¼ë©´ ë¶™ì—¬ì¤ë‹ˆë‹¤)"""
    if not u: return None
    u = u.strip() 
    if not re.match(r"^https?://", u): u = "https://" + u
    parts = urllib.parse.urlsplit(u) 
    return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ""))

@st.cache_data
def http_get(url: str, timeout: int = 12) -> Optional[requests.Response]:
    """íŠ¹ì • URLë¡œ ì›¹ ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤ (ì¸í„°ë„· ì ‘ì†)."""
    try:
        r = requests.get(url,
                         headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
                                  "Accept-Language": "ko, en;q=0.9"}, timeout=timeout,)
        if r.status_code == 200 and "text/html" in r.headers.get("content-type",""):
            return r
    except Exception:
        pass
    return None

def html_to_text(html_str: str) -> str:
    """HTML ì½”ë“œë¥¼ ì½ê¸° ì‰¬ìš´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    conv = html2text.HTML2Text()
    conv.ignore_links = True # ë§í¬ ì •ë³´ ë¬´ì‹œ
    conv.ignore_images = True # ì´ë¯¸ì§€ ì •ë³´ ë¬´ì‹œ
    conv.body_width = 0 # ì¤„ ë°”ê¿ˆ ì œí•œ ì—†ìŒ
    txt = conv.handle(html_str)
    txt = re.sub(r"\n{3,}", "\n\n", txt)
    return txt.strip()

# ================== ì›ë¬¸ ìˆ˜ì§‘ (Jina â†’ Web â†’ BS4 ìˆœì„œë¡œ ì‹œë„) ==================
def fetch_jina_text(url: str, timeout: int = 15) -> str:
    """Jina AI í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ë™ì  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë„ ë¹„êµì  ì˜ ê°€ì ¸ì˜´)"""
    try:
        parts = urllib.parse.urlsplit(url)
        # Jina AI í”„ë¡ì‹œ URLì„ ë§Œë“­ë‹ˆë‹¤. (Jinaì—ê²Œ ì´ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë‹¬ë¼ê³  ìš”ì²­)
        prox = f"https://r.jina.ai/http://{parts.netloc}{parts.path}"
        if parts.query: prox += f"?{parts.query}"
        r = http_get(prox, timeout=timeout)
        return r.text.strip() if r else "" 
    except Exception:
        return ""

def fetch_webbase_text(url: str) -> str:
    """ì¼ë°˜ì ì¸ ì •ì  í¬ë¡¤ë§ ë°©ì‹ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    r = http_get(url, timeout=12)
    if not r: return ""
    return html_to_text(r.text)

def fetch_bs4_text(url: str) -> Tuple[str, Optional[BeautifulSoup]]:
    """HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ì •ë³´ ë¸”ë¡ ìœ„ì£¼ë¡œ ì •ë¦¬)"""
    r = http_get(url, timeout=12)
    if not r: return "", None
    soup = BeautifulSoup(r.text, "lxml") 
    blocks = []
    # ì›¹ í˜ì´ì§€ì—ì„œ 'ê¸°ì‚¬', 'ì„¹ì…˜', 'ë³¸ë¬¸' ë“± ì¤‘ìš”í•œ ë‚´ìš©ì„ ë‹´ì„ ë²•í•œ íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    for sel in ["article","section","main","div","ul","ol"]:
        for el in soup.select(sel):
            txt = el.get_text(" ", strip=True) 
            if txt and len(txt) > 300: # í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ 300ì ì´ìƒì¸ ë¸”ë¡ë§Œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
                txt = re.sub(r"\s+"," ", txt)
                blocks.append(txt)
    if not blocks:
        return soup.get_text(" ", strip=True)[:120000], soup
    
    seen, out = set(), []
    for b in blocks:
        if b not in seen:
            seen.add(b); out.append(b)
    return ("\n\n".join(out)[:120000], soup)

@st.cache_data(show_spinner=False)
def fetch_all_text(url: str):
    """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• 3ê°€ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    url = normalize_url(url)
    if not url: return "", {"error":"invalid_url"}, None
    
    # 1. Jina AI ì‹œë„ (ê°€ì¥ ìµœì‹  ê¸°ìˆ ì´ë©° ë™ì  í˜ì´ì§€ì— ê°•í•©ë‹ˆë‹¤)
    jina = fetch_jina_text(url)
    if jina and len(jina) > 500:
        r = http_get(url, timeout=12)
        soup = BeautifulSoup(r.text, "lxml") if r else None
        return jina, {"source":"jina","len":len(jina),"url_final":url}, soup
    
    # 2. BS4 ìƒì„¸ íŒŒì‹± ì‹œë„ (ë³¸ë¬¸ ë¸”ë¡ ìœ„ì£¼)
    bs, soup = fetch_bs4_text(url)
    if bs and len(bs) > 500:
        return bs, {"source":"bs4","len":len(bs),"url_final":url}, soup

    # 3. Webbase ì¼ë°˜ í…ìŠ¤íŠ¸ ì‹œë„ (ìµœí›„ì˜ ìˆ˜ë‹¨)
    web = fetch_webbase_text(url)
    if web:
        r = http_get(url, timeout=12)
        soup = BeautifulSoup(r.text, "lxml") if r else None
        return web, {"source":"webbase_fallback","len":len(web),"url_final":url}, soup
        
    return "", {"source":"failed_all","len":0,"url_final":url}, None

# ================== ë©”íƒ€/ì„¹ì…˜ ë³´ì¡° ì¶”ì¶œ ==================
def extract_company_meta(soup: Optional[BeautifulSoup]) -> Dict[str,str]:
    """HTML ë©”íƒ€ íƒœê·¸ì™€ ì œëª©ì—ì„œ íšŒì‚¬ëª…, ì†Œê°œ, ì§ë¬´ëª…ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
    meta = {"company_name":"","company_intro":"","job_title":""}
    if not soup: return meta
    
    cand = []
    og = soup.find("meta", {"property":"og:site_name"});
    if og and og.get("content"): cand.append(og["content"])
    app = soup.find("meta", {"name":"application-name"})
    if app and app.get("content"): cand.append(app["content"])
    if soup.title and soup.title.string: cand.append(soup.title.string)
    
    cand = [re.split(r"[\-\|\Â·\â€”]", c)[0].strip() for c in cand if c]
    cand = [c for c in cand if 2 <= len(c) <= 40]
    meta["company_name"] = cand[0] if cand else ""
    
    md = soup.find("meta", {"name":"description"}) or soup.find("meta", {"property":"og:description"})
    if md and md.get("content"):
        meta["company_intro"] = re.sub(r"\s+"," ", md["content"]).strip()[:500]
        
    jt = ""
    ogt = soup.find("meta", {"property":"og:title"});
    if ogt and ogt.get("content"): jt = ogt["content"]
    if not jt:
        h1 = soup.find("h1")
        if h1 and h1.get_text(): jt = h1.get_text(strip=True)
    
    meta["job_title"] = re.sub(r"\s+"," ", jt).strip()[:120]
    return meta

# ================== LLM ì •ì œ (ì±„ìš© ê³µê³  â†’ êµ¬ì¡° JSON) ==================
PROMPT_SYSTEM_STRUCT = ("ë„ˆëŠ” ì±„ìš© ê³µê³ ë¥¼ ê¹”ë”í•˜ê²Œ êµ¬ì¡°í™”í•˜ëŠ” ë³´ì¡°ì›ì´ë‹¤. "
                        "ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” í¬í„¸ ê´‘ê³  ë¬¸êµ¬, UIì”ì¬, ë³µìˆ˜ ì§ë¬´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆë‹¤. "
                        "í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¤‘ë³µì—†ì´ ì •ì œí•˜ë¼. íšŒì‚¬/ì§ë¬´/ìš”ê±´/ìš°ëŒ€ì‚¬í•­ì„ ì¶”ì¶œí•˜ë¼.")

@st.cache_data(show_spinner=False)
def llm_structurize(raw_text: str, meta_hint: Dict[str,str], model: str) -> Dict:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš© ê³µê³  ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ ì •ì œí•©ë‹ˆë‹¤."""
    ctx = (raw_text or "").strip()
    if len(ctx) > 14000: # AI ëª¨ë¸ì˜ ì…ë ¥ ê¸¸ì´ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ…ë‹ˆë‹¤.
        ctx = ctx[:14000]

    user_msg = {"role": "user",
                "content": (f"ë‹¤ìŒ ì±„ìš© ê³µê³  ì›ë¬¸ì„ êµ¬ì¡°í™”í•´ì¤˜.\n\n"
                            f"[íŒíŠ¸] íšŒì‚¬ëª… í›„ë³´: {meta_hint.get('company_name','')}\n"
                            f"[íŒíŠ¸] ì§ë¬´ëª… í›„ë³´: {meta_hint.get('job_title','')}\n\n"
                            f"[ì›ë¬¸]\n{ctx}\n\n"
                            f"ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆì— ë”°ë¼ì•¼ í•˜ë©°, ê°’ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸/ë¬¸ìì—´ì„ ì‚¬ìš©í•´ì¤˜.\n"
                            f"{{ \"company_name\": \"íšŒì‚¬ëª…\", \"job_title\": \"ì§ë¬´ëª…\", \"company_intro\": \"íšŒì‚¬ ì†Œê°œ\", "
                            f"\"responsibilities\": [\"ì£¼ìš” ì—…ë¬´ 1\", ...], "
                            f"\"requirements\": [\"í•„ìˆ˜ ìê²© ìš”ê±´ 1\", ...], "
                            f"\"preferred\": [\"ìš°ëŒ€ ì‚¬í•­ 1\", ...] }}"
                            )}

    try:
        # OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
        resp = client.chat.completions.create(model=model, temperature=0.2, 
                                              response_format={"type": "json_object"}, 
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_STRUCT}, user_msg])
        data = json.loads(resp.choices[0].message.content) # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ íŒíŠ¸ ì •ë³´ë¥¼ í¬í•¨í•œ ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        data = {"company_name": meta_hint.get("company_name", "ì •ì œ ì‹¤íŒ¨"),
                "job_title": meta_hint.get("job_title", "ì •ì œ ì‹¤íŒ¨"),
                "company_intro": "AI ì •ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ë¬¸ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.",
                "responsibilities": [], "requirements": [], "preferred": [], "error": str(e)}

    return data

# ================== íŒŒì¼ ë¦¬ë” (PDF/TXT/MD/DOCX) ==================
def read_pdf(data: bytes) -> str:
    """PDF íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. (pypdf ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)"""
    if pypdf is None: return "PDF íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: pypdf ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    try:
        from pypdf import PdfReader # pypdf ë™ì  ì„í¬íŠ¸
        reader = PdfReader(io.BytesIO(data)) 
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text
    except Exception as e:
        return f"PDF íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def read_docx(data: bytes) -> str:
    """DOCX íŒŒì¼ì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. (python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)"""
    if DocxDocument is None: return "DOCX íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    try:
        document = DocxDocument(io.BytesIO(data)) # ë©”ëª¨ë¦¬ì— ìˆëŠ” DOCX ë°ì´í„°ë¥¼ ì½ìŒ
        return "\n".join([p.text for p in document.paragraphs]) # ëª¨ë“  ë¬¸ë‹¨ì„ í•©ì³ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    except Exception as e:
        return f"DOCX íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def read_file_text(uploaded) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì¢…ë¥˜(txt, pdf, docx ë“±)ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    name = uploaded.name.lower()
    data = uploaded.read()
    if name.endswith(".pdf"):
        return read_pdf(data)
    elif name.endswith(".docx"):
        return read_docx(data)
    else:
        # ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼(txt, md) ì²˜ë¦¬
        try:
            return data.decode("utf-8")
        except:
            return data.decode("latin-1")
    return ""

# ================== ê°„ë‹¨ ì²­í¬/ì„ë² ë”© (RAG, ê²€ìƒ‰ ì¦ê°• ìƒì„±) ==================
def chunk(text: str, size: int = 600, overlap: int = 120) -> List[str]:
    """ê¸´ í…ìŠ¤íŠ¸(ì´ë ¥ì„œ)ë¥¼ ì¼ì •í•œ í¬ê¸°(size)ë¡œ ìë¥´ê³  ë‹¤ìŒ ì¡°ê°ê³¼ ê²¹ì¹˜ê²Œ(overlap) ë§Œë“­ë‹ˆë‹¤."""
    t = re.sub(r"\s+"," ", text).strip()
    if not t: return []
    out, start = [], 0
    while start < len(t):
        end = min(len(t), start+size)
        out.append(t[start:end])
        if end == len(t): break
        start = max(0, end-overlap)
    return out

@st.cache_data(show_spinner=False)
def embed_texts(texts: List[str], model_name: str) -> np.ndarray:
    """í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ìˆ«ì ë²¡í„°(ì„ë² ë”©)'ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not texts:
        return np.zeros((0, 1536), dtype=np.float32) # ì„ë² ë”© ì°¨ì›(í¬ê¸°)ì„ 1536ìœ¼ë¡œ ê°€ì • (text-embedding-3-small ê¸°ì¤€)
    resp = client.embeddings.create(model=model_name, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_topk(matrix: np.ndarray, query_vec: np.ndarray, k: int = 4):
    """ì§ˆë¬¸ ë²¡í„°ì™€ ê°€ì¥ ìœ ì‚¬í•œ(ì½”ì‚¬ì¸ ìœ ì‚¬ë„) ìƒìœ„ Kê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì°¾ìŠµë‹ˆë‹¤."""
    if matrix.size == 0:
        return np.array([]), np.array([], dtype=int)
    qn = query_vec / (np.linalg.norm(query_vec, axis=1, keepdims=True) + 1e-12)
    mn = matrix / (np.linalg.norm(matrix, axis=1, keepdims=True) + 1e-12)
    sims = mn @ qn.T # í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°
    sims = sims.reshape(-1)
    idx = np.argsort(-sims)[:k] # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìƒìœ„ kê°œì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŒ
    return sims[idx], idx

def retrieve_resume_chunks(query: str, k: int = 4):
    """ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ì´ë ¥ì„œì˜ í…ìŠ¤íŠ¸ ì¡°ê°(ì²­í¬)ì„ ê²€ìƒ‰(RAG)í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    chs, embs = st.session_state.get("resume_chunks", []), st.session_state.get("resume_embeds", None)
    if not chs or embs is None:
        return []
    qv = embed_texts([query], EMBED_MODEL) # ì§ˆë¬¸ì„ ìˆ«ìë¡œ ë³€í™˜
    scores, idxs = cosine_topk(embs, qv, k=k) # ì§ˆë¬¸ê³¼ ì´ë ¥ì„œ ì¡°ê° ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë¹„êµ
    # ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•´ë‹¹ ì´ë ¥ì„œ ì¡°ê°ì„ ë¬¶ì–´ ë°˜í™˜í•©ë‹ˆë‹¤.
    return [(float(s), chs[int(i)]) for s, i in zip(scores, idxs)]

# ================== íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ ìˆ˜ì§‘ (ê°„ì†Œí™”) ==================
# ì´ ë¶€ë¶„ì€ ì™¸ë¶€ API ì—°ë™ì´ë‚˜ ì‹¬ì¸µ í¬ë¡¤ë§ì´ í•„ìš”í•˜ì—¬ í˜„ì¬ëŠ” ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.

def fetch_company_pages(home_url: str) -> Dict[str, List[str]]:
    """íšŒì‚¬ í™ˆí˜ì´ì§€ì™€ ì£¼ìš” ì„œë¸Œ ê²½ë¡œì—ì„œ 'ë¹„ì „/ê°€ì¹˜' ë° 'ì¸ì¬ìƒ' ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤."""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ home_url ë° í•˜ìœ„ ê²½ë¡œë¥¼ í¬ë¡¤ë§í•˜ì—¬ 'ë¹„ì „', 'ì¸ì¬ìƒ' í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    # í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return {"vision": ["ê³ ê° ì¤‘ì‹¬ì˜ í˜ì‹ ì„ í†µí•œ ë¯¸ë˜ ê¸°ìˆ  ì„ ë„", "ë°ì´í„° ê¸°ë°˜ì˜ ì˜ì‚¬ê²°ì • ë¬¸í™” í™•ë¦½"], 
            "talent": ["ëŠì„ì—†ì´ ë°°ìš°ëŠ” ìì„¸", "í˜‘ë ¥ê³¼ ìƒìƒì˜ ê°€ì¹˜ ì‹¤í˜„", "ë„ì „ ì •ì‹ ê³¼ ê¸ì •ì  íƒœë„"]}

def fetch_latest_news(company: str, max_items: int = 5) -> List[Dict]:
    """íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì‹¤ì œ ë‰´ìŠ¤ API ì—°ë™ í•„ìš”)"""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ NAVER ë‰´ìŠ¤ ê²€ìƒ‰ APIë‚˜ Google Custom Search APIë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    # í˜„ì¬ëŠ” íšŒì‚¬ ì´ë¦„ì´ í¬í•¨ëœ êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    query = f"{company} ìµœì‹  ë‰´ìŠ¤"
    return [{"title": f"{company} ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼", "link": f"https://www.google.com/search?q={urllib.parse.quote(query)}&tbm=nws"}, 
            {"title": "ë‹¤ë¥¸ ë‰´ìŠ¤ ê¸°ì‚¬ ì˜ˆì‹œ", "link": f"https://www.google.com/search?q={urllib.parse.quote(company)}&tbm=nws"}]

# ================== LLM ì§ˆë¬¸/ë‹µë³€/ì±„ì  ê´€ë ¨ í•¨ìˆ˜ ==================
# AIì—ê²Œ ë¶€ì—¬í•  ì—­í• (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
PROMPT_SYSTEM_Q = ("ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. íšŒì‚¬/ì§ë¬´ ë§¥ë½ê³¼ ì±„ìš©ìš”ê±´, ê·¸ë¦¬ê³  ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ í•¨ê»˜ ê³ ë ¤í•´ "
                   "ë©´ì ‘ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•œë‹¤. ì§ˆë¬¸ì€ ì„œë¡œ í˜•íƒœÂ·ê´€ì Â·í‚¤ì›Œë“œê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ ë‹¤ì–‘í™”í•˜ê³ , "
                   "ìˆ˜ì¹˜/ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë¦¬ìŠ¤í¬/íŠ¸ë ˆì´ë“œì˜¤í”„ ë“±ë„ ì„ì–´ë¼.")
PROMPT_SYSTEM_DRAFT = ("ë„ˆëŠ” ë©´ì ‘ ë‹µë³€ ì½”ì¹˜ë‹¤. íšŒì‚¬/ì§ë¬´/ì±„ìš©ìš”ê±´ê³¼ ì§€ì›ìì˜ ì´ë ¥ì„œ ìš”ì•½ì„ ê²°í•©í•´ "
                       "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ **ì´ˆì•ˆ**ì„ STAR(ìƒí™©-ê³¼ì œ-í–‰ë™-ì„±ê³¼)ë¡œ 8~12ë¬¸ì¥, í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. "
                       "ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì§€í‘œ/ìˆ˜ì¹˜/ê¸°ê°„/ì„íŒ©íŠ¸ë¥¼ í¬í•¨í•˜ë¼.")
PROMPT_SYSTEM_SCORE_STRICT = ("ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ í†±í‹°ì–´ ë©´ì ‘ ì½”ì¹˜ë‹¤. ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ë¼. "
                              "ê° ê¸°ì¤€ì€ 0~20 ì •ìˆ˜ì´ë©°, ì´ì ì€ ê¸°ì¤€ í•©ê³„(ìµœëŒ€ 100)ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•œë‹¤. "
                              "ê³¼ì¥/ëª¨í˜¸í•¨/ê·¼ê±° ë¶€ì¬/ìˆ«ì ì—†ëŠ” ì£¼ì¥/ì±…ì„ íšŒí”¼/ëª¨í˜¸í•œ ì£¼ì–´ ì‚¬ìš© ë“±ì„ ê°•í•˜ê²Œ ê°ì í•˜ë¼. "
                              "ê° ê¸°ì¤€ì— ëŒ€í•´ ì§§ì§€ë§Œ êµ¬ì²´ì  ì½”ë©˜íŠ¸(ê°•ì /ê°ì ìš”ì¸/ê°œì„ í¬ì¸íŠ¸)ë¥¼ ì œê³µí•˜ë¼.")
CRITERIA = ["ë¬¸ì œì •ì˜","ë°ì´í„°/ì§€í‘œ","ì‹¤í–‰ë ¥/ì£¼ë„ì„±","í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜","ê³ ê°ê°€ì¹˜"]

def llm_generate_one_question_with_resume(clean: Dict, level: str, model: str) -> str:
    """íšŒì‚¬/ì§ë¬´ ì •ë³´ì™€ ì´ë ¥ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # RAG: ì´ë ¥ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ ë°œì·Œ (ì§ˆë¬¸ ìƒì„±ì˜ ê·¼ê±°ë¡œ ì‚¬ìš©)
    hits = retrieve_resume_chunks("í•µì‹¬ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½", k=4) 
    resume_context = "\n".join([f"- {t[:350]}" for _, t in hits])[:1200]

    user_msg = (f"[íšŒì‚¬/ì§ë¬´ ì •ë³´]\n{json.dumps(clean, ensure_ascii=False, indent=2)}\n\n"
                f"[ì§€ì›ì ì´ë ¥ì„œ í•µì‹¬ ë‚´ìš©]\n{resume_context}\n\n"
                f"ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ë‚œì´ë„: {level}'ì— ë§ëŠ” ê°€ì¥ í•µì‹¬ì ì¸ ì§ˆë¬¸ 1ê°œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì¤˜.")
    
    try:
        resp = client.chat.completions.create(model=model, temperature=0.7, 
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_Q}, 
                                                        {"role":"user","content":user_msg}])
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}"

def llm_draft_answer(clean: Dict, question: str, model: str) -> str:
    """ì§ˆë¬¸ê³¼ ì´ë ¥ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ STAR ê¸°ë°˜ì˜ ë‹µë³€ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # RAG: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì´ë ¥ì„œ ë¶€ë¶„ ë°œì·Œ (ë‹µë³€ì˜ ê·¼ê±°ë¡œ ì‚¬ìš©)
    hits = retrieve_resume_chunks(question, k=4) 
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]

    user_msg = (f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
                f"[íšŒì‚¬/ì§ë¬´ ì •ë³´]\n{json.dumps(clean, ensure_ascii=False, indent=2)}\n\n"
                f"[ì§€ì›ì ì´ë ¥ì„œ ê´€ë ¨ ë‚´ìš©]\n{resume_text}\n\n"
                f"ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 'ë©´ì ‘ ì§ˆë¬¸'ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ STAR êµ¬ì¡°ë¡œ ì‘ì„±í•´ì¤˜.")
    
    try:
        resp = client.chat.completions.create(model=model, temperature=0.6, 
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_DRAFT}, 
                                                        {"role":"user","content":user_msg}])
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"ë‹µë³€ ì´ˆì•ˆ ìƒì„± ì˜¤ë¥˜: {e}"

def llm_score_and_coach_strict(clean: Dict, question: str, answer: str, model: str) -> Dict:
    """ì§ˆë¬¸, ë‹µë³€, ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    # RAG: ì§ˆë¬¸, ë‹µë³€, ì´ë ¥ì„œ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë°œì·Œ
    hits = retrieve_resume_chunks(question + "\n" + answer[:800], k=4) 
    resume_text = "\n".join([f"- {t[:400]}" for _, t in hits])[:1600]
    
    # JSON ìŠ¤í‚¤ë§ˆë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±
    json_schema = {
        "total_score": "ì´ì  (0~100)",
        "comment_score_ë¬¸ì œì •ì˜": "ë¬¸ì œì •ì˜ ê¸°ì¤€ì˜ ì ìˆ˜(0~20)ì™€ ì½”ë©˜íŠ¸",
        "comment_score_ë°ì´í„°/ì§€í‘œ": "ë°ì´í„°/ì§€í‘œ ê¸°ì¤€ì˜ ì ìˆ˜(0~20)ì™€ ì½”ë©˜íŠ¸",
        "comment_score_ì‹¤í–‰ë ¥/ì£¼ë„ì„±": "ì‹¤í–‰ë ¥/ì£¼ë„ì„± ê¸°ì¤€ì˜ ì ìˆ˜(0~20)ì™€ ì½”ë©˜íŠ¸",
        "comment_score_í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": "í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê¸°ì¤€ì˜ ì ìˆ˜(0~20)ì™€ ì½”ë©˜íŠ¸",
        "comment_score_ê³ ê°ê°€ì¹˜": "ê³ ê°ê°€ì¹˜ ê¸°ì¤€ì˜ ì ìˆ˜(0~20)ì™€ ì½”ë©˜íŠ¸",
        "strengths": ["ê°•ì  1", "ê°•ì  2"],
        "risks": ["ë¦¬ìŠ¤í¬ 1", "ë¦¬ìŠ¤í¬ 2"],
        "improvement": ["ê°œì„  í¬ì¸íŠ¸ 1", "ê°œì„  í¬ì¸íŠ¸ 2"],
        "revised_answer": "STAR êµ¬ì¡°ë¥¼ ì ìš©í•˜ì—¬ ê°œì„ ëœ ë‹µë³€ (ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ì‘ë‹µ í¬í•¨)"
    }

    user_msg = (f"[ë©´ì ‘ ì§ˆë¬¸]\n{question}\n\n"
                f"[ì§€ì›ì ë‹µë³€]\n{answer}\n\n"
                f"[ì§€ì›ì ì´ë ¥ì„œ ê´€ë ¨ ë‚´ìš©]\n{resume_text}\n\n"
                f"ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ë‹µë³€ì„ ì—„ê²©í•˜ê²Œ ì±„ì í•˜ê³ , ì½”ë©˜íŠ¸ ë° ê°œì„ ëœ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì¤˜.")
    
    try:
        resp = client.chat.completions.create(model=model, temperature=0.2,
                                              response_format={"type": "json_object"}, 
                                              messages=[{"role":"system","content":PROMPT_SYSTEM_SCORE_STRICT}, 
                                                        {"role":"user","content":user_msg}])
        data = json.loads(resp.choices[0].message.content)
        # LLMì˜ JSON ì¶œë ¥ í‚¤ ì´ë¦„ì„ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
        result = {"total_score": data.get("total_score", 0)}
        for key in data:
            if key.startswith("comment_score_"):
                result[key] = data[key]
        result["strengths"] = data.get("strengths", [])
        result["risks"] = data.get("risks", [])
        result["improvement"] = data.get("improvement", [])
        result["revised_answer"] = data.get("revised_answer", "ìˆ˜ì •ëœ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return result
    except Exception as e:
        return {"total_score": "N/A", "error": f"ì±„ì  ì˜¤ë¥˜: {e}", "revised_answer": "ì±„ì  ì˜¤ë¥˜ë¡œ ë‹µë³€ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


# ================== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ==================
def _init_state():
    """Streamlit ì•±ì„ ìœ„í•œ ë³€ìˆ˜(ì„¸ì…˜ ìƒíƒœ)ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if 'raw_text' not in st.session_state: st.session_state.raw_text = ""
    if 'fetch_info' not in st.session_state: st.session_state.fetch_info = {}
    if 'clean_struct' not in st.session_state: st.session_state.clean_struct = {}
    if 'company_vision' not in st.session_state: st.session_state.company_vision = []
    if 'company_talent' not in st.session_state: st.session_state.company_talent = []
    if 'latest_news' not in st.session_state: st.session_state.latest_news = []
    if 'resume_text' not in st.session_state: st.session_state.resume_text = ""
    if 'resume_chunks' not in st.session_state: st.session_state.resume_chunks = []
    if 'resume_embeds' not in st.session_state: st.session_state.resume_embeds = None
    if 'current_question' not in st.session_state: st.session_state.current_question = ""
    if 'draft_answer' not in st.session_state: st.session_state.draft_answer = ""
    if 'answer_text' not in st.session_state: st.session_state.answer_text = ""
    if 'last_result' not in st.session_state: st.session_state.last_result = None
    if 'followups' not in st.session_state: st.session_state.followups = []
    if 'last_followup_result' not in st.session_state: st.session_state.last_followup_result = None
    if 'selected_followup' not in st.session_state: st.session_state.selected_followup = ""
    if 'followup_answer' not in st.session_state: st.session_state.followup_answer = ""

_init_state()


# =================================================================================================================
#                                           Streamlit ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (UI) ì˜ì—­
# =================================================================================================================
# 1) ì±„ìš© ê³µê³  URL ì…ë ¥ ë° ì •ì œ ì„¹ì…˜
st.header("1) ì±„ìš© ê³µê³  URL")
url = st.text_input("ì±„ìš© ê³µê³  ìƒì„¸ URL", placeholder="ì·¨ì—… í¬í„¸ ì‚¬ì´íŠ¸ì˜ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
st.text_input("íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URL (ì„ íƒ)", key="company_home", placeholder="íšŒì‚¬ ê³µì‹ í™ˆí˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”. (ë¹„ì „/ì¸ì¬ìƒ ìˆ˜ì§‘ìš©)")

if st.button("ì›ë¬¸ ìˆ˜ì§‘ â†’ ì •ì œ", type="primary"):
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("URL ìˆ˜ì§‘ ë° ì •ì œ ì¤‘... (Jina/ì •ì  í¬ë¡¤ë§ ì‹œë„)"):
            raw_text, info, soup = fetch_all_text(url)
        
        if not raw_text.strip():
            st.error(f"URL ìˆ˜ì§‘ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±: {url}")
            st.session_state.clean_struct = {}
        else:
            meta_hint = extract_company_meta(soup)
            st.session_state.raw_text = raw_text
            st.session_state.fetch_info = info
            
            clean_struct = llm_structurize(raw_text, meta_hint, CHAT_MODEL)
            st.session_state.clean_struct = clean_struct
            
            if st.session_state.company_home:
                company_pages = fetch_company_pages(st.session_state.company_home)
                st.session_state.company_vision = company_pages.get("vision", [])
                st.session_state.company_talent = company_pages.get("talent", [])
            else:
                st.session_state.company_vision = []
                st.session_state.company_talent = []

            if clean_struct.get("company_name"):
                st.session_state.latest_news = fetch_latest_news(clean_struct["company_name"])
            else:
                st.session_state.latest_news = []
                
            st.success("ì •ì œ ì™„ë£Œ!")

# 2) íšŒì‚¬ ìš”ì•½ (ì •ì œ ê²°ê³¼) ì„¹ì…˜
st.header("2) íšŒì‚¬ ìš”ì•½")
clean = st.session_state.clean_struct
if clean:
    st.subheader(clean.get("company_name", "íšŒì‚¬ëª… ì •ë³´ ì—†ìŒ"))
    st.caption(f"ì§ë¬´: {clean.get('job_title', 'ì§ë¬´ ì •ë³´ ì—†ìŒ')}")
    st.markdown(f"**íšŒì‚¬ ì†Œê°œ:** {clean.get('company_intro', '-')}")
    
    # ì£¼ìš” ì±„ìš© ì¡°ê±´ ì¶œë ¥
    st.markdown("**ì£¼ìš” ì—…ë¬´:**")
    for item in clean.get("responsibilities", []): st.markdown(f"- {item}")
    st.markdown("**ìê²© ìš”ê±´:**")
    for item in clean.get("requirements", []): st.markdown(f"- {item}")
    st.markdown("**ìš°ëŒ€ ì‚¬í•­:**")
    for item in clean.get("preferred", []): st.markdown(f"- {item}")

# VISION/NEWS: íšŒì‚¬ ë¹„ì „/ì¸ì¬ìƒ/ë‰´ìŠ¤ (ìˆì„ ë•Œë§Œ í‘œì‹œ)
if st.session_state.company_vision or st.session_state.latest_news:
    st.subheader("íšŒì‚¬/ì§ë¬´ ë³´ì¡° ì •ë³´")
    if st.session_state.company_vision:
        st.markdown("**ë¹„ì „/í•µì‹¬ê°€ì¹˜:**")
        for item in st.session_state.company_vision: st.markdown(f"- {item}")
    if st.session_state.latest_news:
        st.markdown("**ìµœì‹  ë‰´ìŠ¤:**")
        for item in st.session_state.latest_news: st.markdown(f"- [{item.get('title', 'ì œëª© ì—†ìŒ')}]({item.get('link', '#')})")

st.divider()

# 3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ ì„¹ì…˜
st.header("3) ë‚´ ì´ë ¥ì„œ/í”„ë¡œì íŠ¸ ì—…ë¡œë“œ")
uploads = st.file_uploader("ì´ë ¥ì„œ íŒŒì¼ ì—…ë¡œë“œ (PDF, TXT, MD, DOCX ê°€ëŠ¥)", type=["pdf","txt","md","docx"], accept_multiple_files=True)
_RESUME_CHUNK = 500
_RESUME_OVLP  = 100

cols_idx = st.columns(2)
with cols_idx[0]:
    if st.button("ì´ë ¥ì„œ ì¸ë±ì‹± (AI ê²€ìƒ‰ ì¤€ë¹„)", type="secondary"):
        if uploads:
            full_text = ""
            with st.spinner("íŒŒì¼ ì½ëŠ” ì¤‘..."):
                for uploaded_file in uploads:
                    full_text += read_file_text(uploaded_file) + "\n\n"
            
            if full_text.strip():
                st.session_state.resume_text = full_text
                # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬(ì¡°ê°)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
                chunks_list = chunk(full_text, _RESUME_CHUNK, _RESUME_OVLP)
                
                with st.spinner("í…ìŠ¤íŠ¸ ë²¡í„°í™” ì¤‘... (LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ìë¡œ ë³€í™˜)"):
                    # ì²­í¬ë“¤ì„ ì„ë² ë”©(ìˆ«ì ë²¡í„°)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì´ RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±)ì˜ í•µì‹¬ì…ë‹ˆë‹¤.
                    embeds = embed_texts(chunks_list, EMBED_MODEL)
                    st.session_state.resume_chunks = chunks_list
                    st.session_state.resume_embeds = embeds
                st.success(f"ì¸ë±ì‹± ì™„ë£Œ (ì²­í¬ {len(chunks_list)}ê°œ)")
            else:
                st.warning("ì½ì„ ìˆ˜ ìˆëŠ” íŒŒì¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.warning("ì´ë ¥ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

st.divider()

# 4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„± ì„¹ì…˜
st.header("4) ì´ë ¥ì„œ ê¸°ë°˜ ìì†Œì„œ ìƒì„±")
topic = st.text_input("íšŒì‚¬ ìš”ì²­ ì£¼ì œ (ì„ íƒ)", placeholder="ì˜ˆ: ì§ë¬´ ì§€ì›ë™ê¸° / í˜‘ì—… ê²½í—˜ / ë¬¸ì œí•´ê²° ì‚¬ë¡€ ë“± (ì—†ìœ¼ë©´ 'ììœ  ì–‘ì‹'ìœ¼ë¡œ ì‘ì„±)")

def build_cover_letter(clean_struct: Dict, resume_text: str, topic_hint: str, model: str) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš© ê³µê³ ì™€ ì´ë ¥ì„œë¥¼ ê²°í•©í•œ ìì†Œì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # LLMì„ í˜¸ì¶œí•˜ì—¬ ìì†Œì„œë¥¼ ìƒì„±í•˜ëŠ” ë¡œì§ì„ ì—¬ê¸°ì— êµ¬í˜„í•©ë‹ˆë‹¤.
    system_prompt = "ë„ˆëŠ” ë›°ì–´ë‚œ í—¤ë“œí—Œí„°ì´ì ì „ë¬¸ ìê¸°ì†Œê°œì„œ ì‘ì„± ì½”ì¹˜ë‹¤. ì±„ìš© ê³µê³ ì™€ ì§€ì›ìì˜ ê²½í—˜ì„ ì™„ë²½íˆ ë§¤ì¹­í•˜ì—¬ í•µì‹¬ ê²½í—˜ì„ STAR ê¸°ë²• ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚¸ ìì†Œì„œë¥¼ ì‘ì„±í•´ì•¼ í•œë‹¤. ë¶„ëŸ‰ì€ 1000ì ë‚´ì™¸ë¡œ í•œë‹¤."
    user_msg = (f"[ì±„ìš© ê³µê³  ì •ë³´]\n{json.dumps(clean_struct, ensure_ascii=False, indent=2)}\n\n"
                f"[ì§€ì›ì ì´ë ¥ì„œ ì›ë¬¸]\n{resume_text}\n\n"
                f"ìš”ì²­ ì£¼ì œ: {topic_hint if topic_hint else 'ììœ  ì–‘ì‹'}\n\n"
                f"ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ìš”ì²­ ì£¼ì œ'ì— ë§ëŠ” ìê¸°ì†Œê°œì„œ ì´ˆì•ˆì„ ì‘ì„±í•´ì¤˜.")
                
    try:
        resp = client.chat.completions.create(model=model, temperature=0.7, 
                                              messages=[{"role":"system","content":system_prompt}, 
                                                        {"role":"user","content":user_msg}])
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"ìì†Œì„œ ìƒì„± ì˜¤ë¥˜: {e}"

if st.button("ìì†Œì„œ ìƒì„±", type="primary"):
    if not st.session_state.clean_struct:
        st.warning("ë¨¼ì € ì±„ìš© ê³µê³ ë¥¼ ì •ì œí•˜ì„¸ìš”. (1ë‹¨ê³„)")
    elif st.session_state.resume_embeds is None:
        st.warning("ì´ë ¥ì„œ íŒŒì¼ì„ ì¸ë±ì‹±í•˜ì„¸ìš”. (3ë‹¨ê³„)")
    else:
        with st.spinner("ìì†Œì„œ ìƒì„± ì¤‘..."):
            cl_draft = build_cover_letter(st.session_state.clean_struct, st.session_state.resume_text, topic, CHAT_MODEL)
        st.session_state.cover_letter = cl_draft
        st.success("ìì†Œì„œ ìƒì„± ì™„ë£Œ.")

if st.session_state.get('cover_letter'):
    st.subheader("ìƒì„±ëœ ìê¸°ì†Œê°œì„œ")
    st.text_area("ìµœì¢… ì´ˆì•ˆ", value=st.session_state.cover_letter, height=300)
    st.download_button("ìì†Œì„œ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", st.session_state.cover_letter, file_name="cover_letter_draft.txt")

st.divider()

# 5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ ì„¹ì…˜
st.header("5) ì§ˆë¬¸ ìƒì„± & ë‹µë³€ ì´ˆì•ˆ (RAG ê²°í•©)")
level  = st.selectbox("ë‚œì´ë„/ì—°ì°¨", ["ì£¼ë‹ˆì–´","ë¯¸ë“¤","ì‹œë‹ˆì–´"], index=0)

cols_q = st.columns(2)
with cols_q[0]:
    if st.button("ìƒˆ ì§ˆë¬¸ ë°›ê¸°", type="primary"):
        if not st.session_state.clean_struct or st.session_state.resume_embeds is None:
            st.warning("ì±„ìš© ê³µê³  ì •ì œ ë° ì´ë ¥ì„œ ì¸ë±ì‹±ì„ ì™„ë£Œí•˜ì„¸ìš”. (1, 3ë‹¨ê³„)")
        else:
            with st.spinner("ì±„ìš© ê³µê³ ì™€ ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ ìƒì„± ì¤‘..."):
                st.session_state.current_question = llm_generate_one_question_with_resume(st.session_state.clean_struct, level, CHAT_MODEL)
                st.session_state.draft_answer = ""
                st.session_state.answer_text = ""
                st.session_state.last_result = None
                # íŒ”ë¡œì—… ì§ˆë¬¸ì€ ë©”ì¸ ì±„ì  í›„ ìƒì„±ë©ë‹ˆë‹¤.
                st.session_state.followups = [] 

with cols_q[1]:
    if st.button("RAGë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±", type="secondary"):
        if not st.session_state.current_question:
            st.warning("ë¨¼ì € 'ìƒˆ ì§ˆë¬¸ ë°›ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì§ˆë¬¸ê³¼ ê°€ì¥ ì—°ê´€ëœ ì´ë ¥ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ì—¬ ì´ˆì•ˆ ìƒì„± ì¤‘..."):
                st.session_state.draft_answer = llm_draft_answer(st.session_state.clean_struct, st.session_state.current_question, CHAT_MODEL)
                st.session_state.answer_text = st.session_state.draft_answer # ë‹µë³€ í…ìŠ¤íŠ¸ ì˜ì—­ì— ìë™ìœ¼ë¡œ ì±„ì›Œì¤Œ

st.text_area("ì§ˆë¬¸", value=st.session_state.current_question, height=100)
st.text_area("ë‚˜ì˜ ë‹µë³€ (ì´ˆì•ˆì„ í¸ì§‘í•˜ê±°ë‚˜ ì§ì ‘ ì‘ì„±í•˜ì„¸ìš”)", height=200, key="answer_text")

# 6) ì±„ì  & ì½”ì¹­ (ì—„ê²© ëª¨ë“œ) ì„¹ì…˜
st.header("6) ì±„ì  & ì½”ì¹­")
if st.button("ì±„ì  & ì½”ì¹­ ì‹¤í–‰", type="primary"):
    if not st.session_state.current_question or not st.session_state.answer_text.strip():
        st.warning("ì§ˆë¬¸ì„ ë°›ê³  ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
    else:
        with st.spinner("AI ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ì—„ê²©í•˜ê²Œ ì±„ì  ë° ì½”ì¹­ ì¤‘..."):
            st.session_state.last_result = llm_score_and_coach_strict(st.session_state.clean_struct, st.session_state.current_question, st.session_state.answer_text, CHAT_MODEL)
            # ì±„ì  í›„, ë‹µë³€ì˜ ë¦¬ìŠ¤í¬ì™€ ì•½ì ì„ ë°”íƒ•ìœ¼ë¡œ íŒ”ë¡œì—… ì§ˆë¬¸ ëª©ë¡ì„ ìƒì„±í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. (ë”ë¯¸ ë°ì´í„°)
            st.session_state.followups = ["ë‹µë³€ì—ì„œ ì œì‹œí•œ ìˆ˜ì¹˜/ì§€í‘œì˜ êµ¬ì²´ì  ì‚°ì¶œ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", 
                                          "í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ë°œìƒí•œ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì™€ ê·¸ í•´ê²°ì±…ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?", 
                                          "ì´ ê²½í—˜ì´ ìš°ë¦¬ íšŒì‚¬ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê´€ì ì—ì„œ ë‹¤ì‹œ ì„¤ëª…í•´ ë³´ì„¸ìš”."]
        st.success("ì±„ì  ë° ì½”ì¹­ ì™„ë£Œ.")

# 7) í”¼ë“œë°± ê²°ê³¼ ì„¹ì…˜
st.header("7) í”¼ë“œë°± ê²°ê³¼")
last = st.session_state.last_result
if last:
    st.metric("ì´ì (/100)", last.get("total_score", "N/A"))
    
    st.markdown("---")
    st.markdown("**ê¸°ì¤€ë³„ ì½”ë©˜íŠ¸**")
    for criterion in CRITERIA:
        # LLMì´ ë°˜í™˜í•œ JSON í‚¤ì— ë§ì¶° ë™ì ìœ¼ë¡œ ì½”ë©˜íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        key = f"comment_score_{criterion}"
        st.caption(f"**{criterion}:** {last.get(key, '-')}")

    st.markdown("---")
    st.markdown("**ê°•ì  & ë¦¬ìŠ¤í¬ & ê°œì„  í¬ì¸íŠ¸ ìš”ì•½**")
    st.success(f"**ê°•ì :** {', '.join(last.get('strengths', []))}")
    st.error(f"**ë¦¬ìŠ¤í¬:** {', '.join(last.get('risks', []))}")
    st.info(f"**ê°œì„  í¬ì¸íŠ¸:** {', '.join(last.get('improvement', []))}")
    
    st.markdown("---")
    st.markdown("**ìˆ˜ì •ë³¸ ë‹µë³€ (STAR êµ¬ì¡° ì ìš©)**")
    st.text_area("LLM ìˆ˜ì •ë³¸", value=last.get('revised_answer', '-'), height=200)

else:
    st.info("ì•„ì§ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 6ë‹¨ê³„ì—ì„œ 'ì±„ì  & ì½”ì¹­ ì‹¤í–‰'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.divider()

# 8) íŒ”ë¡œì—… ì§ˆë¬¸ â†’ ë‹µë³€ â†’ í”¼ë“œë°± ì„¹ì…˜
st.subheader("íŒ”ë¡œì—… ì§ˆë¬¸ Â· ë‹µë³€ Â· í”¼ë“œë°±")
last = st.session_state.last_result
if last:
    if st.session_state.followups:
        st.markdown("**íŒ”ë¡œì—… ì§ˆë¬¸ ì œì•ˆ**")
        # ì œì•ˆëœ ì§ˆë¬¸ ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        for i, f in enumerate(st.session_state.followups, 1):
            st.markdown(f"- ({i}) {f}")

        st.selectbox("ì±„ì  ë°›ì„ íŒ”ë¡œì—… ì§ˆë¬¸ ì„ íƒ", st.session_state.followups, index=0, key="selected_followup")
        st.text_area("íŒ”ë¡œì—… ì§ˆë¬¸ì— ëŒ€í•œ ë‚˜ì˜ ë‹µë³€", height=160, key="followup_answer")
        
        if st.button("íŒ”ë¡œì—… ì±„ì  & í”¼ë“œë°±", type="secondary"):
            fu_q   = st.session_state.get("selected_followup", "")
            fu_ans = st.session_state.get("followup_answer", "")
            if not fu_q:
                st.warning("íŒ”ë¡œì—… ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif not fu_ans.strip():
                st.warning("íŒ”ë¡œì—… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.")
            else:
                with st.spinner("íŒ”ë¡œì—… ë‹µë³€ ì±„ì  ì¤‘..."):
                    res_fu = llm_score_and_coach_strict(st.session_state.clean_struct, fu_q, fu_ans, CHAT_MODEL)
                st.session_state.last_followup_result = res_fu
                st.markdown("**íŒ”ë¡œì—… ê²°ê³¼**")
                st.metric("ì´ì (/100)", res_fu.get("total_score", "N/A"))
                st.text_area("íŒ”ë¡œì—… í”¼ë“œë°±", value=res_fu.get('revised_answer', 'í”¼ë“œë°± ë‚´ìš©'), height=150)
    else:
        st.caption("íŒ”ë¡œì—… ì§ˆë¬¸ì€ ë©”ì¸ ì§ˆë¬¸ ì±„ì  ì§í›„ ìë™ìœ¼ë¡œ ì œì•ˆë©ë‹ˆë‹¤.")